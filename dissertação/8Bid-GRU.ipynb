{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n",
      "(2000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classesQ8 = base.iloc[:1400000, 20:28].values\n",
    "classesQ8 = np.reshape(classesQ8, (2000, 700, 8))\n",
    "print(classesQ8.shape)\n",
    "\n",
    "classesQ3 = base.iloc[:1400000, 28:31].values\n",
    "classesQ3 = np.reshape(classesQ3, (2000, 700, 3))\n",
    "print(classesQ3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNGRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede(saida):\n",
    "    model = Sequential()\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(saida, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test, saida):\n",
    "    model.fit(x_train, y_train, epochs = 100, verbose = 1)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], saida))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], saida))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "    \n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 09:24:54.509188 11592 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 09:24:54.514174 11592 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 09:24:54.516168 11592 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 09:24:54.517167 11592 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    2    3 ... 1996 1997 1999] TEST: [   1    7    8    9   10   17   20   25   27   29   37   43   45   48\n",
      "   61   77   80   84   89   90   92   95   97   98  102  111  114  123\n",
      "  125  129  137  139  142  146  153  164  165  168  176  189  193  194\n",
      "  207  208  209  215  217  219  221  222  239  249  250  255  258  259\n",
      "  263  269  271  275  278  279  281  282  297  298  313  335  339  340\n",
      "  344  347  348  351  352  358  360  369  373  375  383  393  398  399\n",
      "  404  405  406  409  410  425  426  440  444  446  470  474  477  482\n",
      "  490  497  499  506  507  512  513  516  518  522  529  534  535  536\n",
      "  550  553  559  569  570  573  574  579  582  596  598  600  606  611\n",
      "  616  617  622  631  635  636  639  641  643  649  652  656  661  662\n",
      "  669  670  672  675  687  688  690  696  711  712  723  729  740  742\n",
      "  745  747  754  772  788  789  791  799  809  814  817  818  827  838\n",
      "  839  840  841  853  855  862  869  870  872  875  877  884  893  895\n",
      "  898  904  905  907  911  918  919  922  923  926  930  940  944  946\n",
      "  948  949  960  967  968  974  977  980  982  984  988  994  996 1006\n",
      " 1010 1015 1016 1021 1033 1035 1047 1048 1060 1061 1066 1102 1103 1107\n",
      " 1117 1124 1129 1141 1146 1148 1163 1166 1171 1174 1177 1179 1185 1191\n",
      " 1193 1207 1209 1215 1219 1220 1222 1224 1225 1233 1242 1245 1246 1250\n",
      " 1253 1274 1278 1279 1284 1285 1286 1293 1298 1301 1303 1304 1306 1314\n",
      " 1316 1319 1322 1323 1324 1337 1340 1345 1347 1356 1358 1391 1397 1399\n",
      " 1401 1407 1408 1424 1426 1427 1428 1444 1448 1450 1456 1462 1463 1471\n",
      " 1472 1474 1480 1481 1485 1493 1499 1504 1516 1521 1536 1544 1546 1554\n",
      " 1559 1563 1564 1567 1576 1577 1584 1588 1590 1592 1593 1594 1595 1599\n",
      " 1602 1606 1616 1622 1637 1638 1639 1644 1645 1653 1665 1667 1670 1681\n",
      " 1685 1687 1703 1720 1726 1729 1734 1736 1737 1743 1746 1749 1750 1761\n",
      " 1764 1767 1773 1779 1783 1796 1803 1806 1811 1814 1818 1825 1829 1836\n",
      " 1838 1842 1843 1851 1852 1870 1875 1884 1897 1899 1901 1902 1903 1908\n",
      " 1909 1911 1912 1917 1921 1922 1926 1928 1929 1939 1942 1943 1956 1958\n",
      " 1959 1963 1968 1969 1984 1988 1995 1998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 09:24:56.470973 11592 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 23s 15ms/sample - loss: 0.5858 - acc: 0.1597\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5354 - acc: 0.1714\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5244 - acc: 0.1767\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5197 - acc: 0.1787\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5140 - acc: 0.1815\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5110 - acc: 0.1827\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5054 - acc: 0.1850\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5018 - acc: 0.1866\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4968 - acc: 0.1885\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4938 - acc: 0.1901\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4889 - acc: 0.1922\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4862 - acc: 0.1935\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4822 - acc: 0.1949\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4869 - acc: 0.1924\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4775 - acc: 0.1969\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4736 - acc: 0.1982\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4750 - acc: 0.1975\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4683 - acc: 0.2009\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4650 - acc: 0.2017\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4580 - acc: 0.2046\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4530 - acc: 0.2062\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4453 - acc: 0.2092\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4396 - acc: 0.2114\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4349 - acc: 0.2127\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4301 - acc: 0.2144\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4249 - acc: 0.2164\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4215 - acc: 0.2174\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4166 - acc: 0.2191\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4134 - acc: 0.2202\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4083 - acc: 0.2220\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4028 - acc: 0.2236\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3999 - acc: 0.2245\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3976 - acc: 0.2253\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3945 - acc: 0.2264\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3895 - acc: 0.2279\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3866 - acc: 0.2288\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3841 - acc: 0.2297\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3788 - acc: 0.2314\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3757 - acc: 0.2321\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3742 - acc: 0.2328\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3701 - acc: 0.2339\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3659 - acc: 0.2355\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3626 - acc: 0.2365\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3593 - acc: 0.2376\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3578 - acc: 0.2379\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3559 - acc: 0.2385\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3540 - acc: 0.2391\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3520 - acc: 0.2395\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3478 - acc: 0.2413\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3455 - acc: 0.2418\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3432 - acc: 0.2426\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3407 - acc: 0.2434\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3384 - acc: 0.2443\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3365 - acc: 0.2450\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3344 - acc: 0.2455\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3338 - acc: 0.2459\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3316 - acc: 0.2463\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3296 - acc: 0.2470\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3269 - acc: 0.2480\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3254 - acc: 0.2485\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3241 - acc: 0.2490\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3241 - acc: 0.2489\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3210 - acc: 0.2498\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3197 - acc: 0.2503\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3169 - acc: 0.2513\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3156 - acc: 0.2519\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3143 - acc: 0.2524\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3113 - acc: 0.2534\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3102 - acc: 0.2533\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3093 - acc: 0.2539\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3070 - acc: 0.2545\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3065 - acc: 0.2546\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3056 - acc: 0.2549\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3050 - acc: 0.2554\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3041 - acc: 0.2555\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3016 - acc: 0.2563\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3009 - acc: 0.2568\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2988 - acc: 0.2575\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2986 - acc: 0.2572\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2984 - acc: 0.2576\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2965 - acc: 0.2583\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2943 - acc: 0.2588\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2940 - acc: 0.2588\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2938 - acc: 0.2589\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2915 - acc: 0.2599\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2897 - acc: 0.2604\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2892 - acc: 0.2605\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2893 - acc: 0.2605\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2870 - acc: 0.2616\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2857 - acc: 0.2618\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2856 - acc: 0.2617\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2875 - acc: 0.2614\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2828 - acc: 0.2632\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2815 - acc: 0.2632\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2808 - acc: 0.2633\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2806 - acc: 0.2634\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2805 - acc: 0.2641\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2778 - acc: 0.2645\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2767 - acc: 0.2647\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2773 - acc: 0.2646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.02      0.03      1261\n",
      "           1       0.62      0.72      0.67     21703\n",
      "           2       0.33      0.29      0.31      3823\n",
      "           3       0.76      0.80      0.78     33816\n",
      "           4       0.47      0.26      0.33       690\n",
      "           5       0.47      0.54      0.50     20818\n",
      "           6       0.38      0.13      0.20      8851\n",
      "           7       0.44      0.43      0.43     11461\n",
      "\n",
      "    accuracy                           0.60    102423\n",
      "   macro avg       0.52      0.40      0.41    102423\n",
      "weighted avg       0.58      0.60      0.58    102423\n",
      "\n",
      "Acur√°cia\n",
      "0.3971256100494075\n",
      "Precisao\n",
      "0.5836254568227557\n",
      "Recall\n",
      "0.5970143424816692\n",
      "F1\n",
      "0.5798848993790338\n",
      "[[   19   283    42   143     1   598    50   125]\n",
      " [    0 15682   278  1813    18  2914   218   780]\n",
      " [    0   489  1109   827     6   781    67   544]\n",
      " [    0  2129   582 26904   139  2351   196  1515]\n",
      " [    0    73    14   317   177    53    11    45]\n",
      " [    6  3878   530  2342    13 11194   920  1935]\n",
      " [    2  1395   295  1154    13  3416  1183  1393]\n",
      " [    1  1171   545  1993    10  2352   509  4880]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   5   11   13   19   22   23   34   39   49   54   59   62   63   79\n",
      "   81   83   87   88   91   93  105  107  108  112  133  144  147  150\n",
      "  152  163  167  169  177  184  186  188  190  201  206  210  213  214\n",
      "  218  223  230  236  244  247  251  261  262  264  267  283  287  290\n",
      "  302  308  309  320  323  324  326  327  329  337  341  345  349  355\n",
      "  356  361  362  365  385  386  388  395  396  403  407  417  423  427\n",
      "  430  431  438  439  448  449  450  457  459  460  462  464  465  469\n",
      "  473  478  479  481  483  491  495  496  505  520  532  539  540  543\n",
      "  547  549  551  555  580  591  593  594  597  599  601  610  614  624\n",
      "  626  627  629  634  637  638  642  650  658  659  660  667  668  676\n",
      "  680  682  691  698  700  702  704  710  714  716  735  741  743  750\n",
      "  760  762  768  769  771  774  775  780  787  790  795  798  800  801\n",
      "  803  810  811  819  822  824  825  826  828  829  831  832  833  836\n",
      "  837  848  851  852  856  859  863  873  882  891  892  903  906  908\n",
      "  909  910  913  917  924  927  929  932  935  952  953  969  972  979\n",
      "  983  987  999 1001 1002 1003 1009 1018 1019 1020 1037 1039 1042 1045\n",
      " 1054 1057 1059 1072 1078 1092 1097 1101 1108 1109 1116 1122 1123 1126\n",
      " 1136 1138 1149 1150 1153 1158 1161 1162 1170 1178 1183 1187 1195 1196\n",
      " 1197 1204 1210 1214 1227 1232 1236 1248 1249 1261 1268 1270 1291 1299\n",
      " 1300 1302 1312 1313 1318 1320 1329 1333 1335 1352 1353 1354 1363 1364\n",
      " 1369 1370 1375 1392 1406 1409 1421 1423 1432 1433 1435 1436 1437 1441\n",
      " 1454 1464 1468 1470 1476 1479 1484 1486 1487 1490 1497 1498 1502 1513\n",
      " 1520 1524 1526 1527 1534 1538 1542 1543 1549 1550 1551 1574 1575 1608\n",
      " 1612 1617 1621 1625 1630 1632 1635 1640 1643 1646 1647 1649 1651 1655\n",
      " 1656 1657 1661 1663 1672 1680 1683 1684 1689 1691 1698 1701 1702 1708\n",
      " 1711 1721 1723 1725 1735 1742 1759 1768 1769 1771 1774 1777 1778 1781\n",
      " 1792 1794 1801 1805 1819 1821 1822 1824 1828 1841 1854 1856 1864 1867\n",
      " 1868 1876 1879 1883 1888 1894 1898 1918 1925 1938 1940 1944 1946 1947\n",
      " 1950 1951 1962 1972 1979 1982 1983 1989]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.5877 - acc: 0.1614\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5372 - acc: 0.1731\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5265 - acc: 0.1780\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5197 - acc: 0.1807\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5164 - acc: 0.1825\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5122 - acc: 0.1842\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5093 - acc: 0.1853\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5026 - acc: 0.1881\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5009 - acc: 0.1893\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4977 - acc: 0.1906\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4981 - acc: 0.1904\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4920 - acc: 0.1929\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4862 - acc: 0.1955\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4837 - acc: 0.1965\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4802 - acc: 0.1975\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4815 - acc: 0.1971\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4794 - acc: 0.1982\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4648 - acc: 0.2036\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4576 - acc: 0.2065\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4512 - acc: 0.2088\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4493 - acc: 0.2093\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4417 - acc: 0.2127\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4394 - acc: 0.2133\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4355 - acc: 0.2144\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4295 - acc: 0.2169\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4240 - acc: 0.2188\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4210 - acc: 0.2196\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4171 - acc: 0.2210\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4132 - acc: 0.2224\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4092 - acc: 0.2237\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4035 - acc: 0.2260\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4026 - acc: 0.2256\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3971 - acc: 0.2276\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3921 - acc: 0.2298\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3887 - acc: 0.2305\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3861 - acc: 0.2312\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3812 - acc: 0.2330\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3780 - acc: 0.2339\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3758 - acc: 0.2345\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3735 - acc: 0.2352\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3698 - acc: 0.2365\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3660 - acc: 0.2377\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3631 - acc: 0.2385\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3609 - acc: 0.2394\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3588 - acc: 0.2400\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3573 - acc: 0.2406\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3525 - acc: 0.2421\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3514 - acc: 0.2424\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3509 - acc: 0.2426\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3457 - acc: 0.2443\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3435 - acc: 0.2450\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3423 - acc: 0.2452\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3383 - acc: 0.2467\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3372 - acc: 0.2472\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3348 - acc: 0.2478\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3325 - acc: 0.2483\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3325 - acc: 0.2483\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3296 - acc: 0.2490\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3267 - acc: 0.2502\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3244 - acc: 0.2510\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3231 - acc: 0.2516\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3222 - acc: 0.2515\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3207 - acc: 0.2526\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3201 - acc: 0.2527\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3173 - acc: 0.2537\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3171 - acc: 0.2534\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3151 - acc: 0.2540\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3122 - acc: 0.2551\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3115 - acc: 0.2552\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3098 - acc: 0.2559\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3076 - acc: 0.2569\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3067 - acc: 0.2570\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3050 - acc: 0.2575\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3043 - acc: 0.2578\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3029 - acc: 0.2583\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3023 - acc: 0.2587\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3009 - acc: 0.2587\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2992 - acc: 0.2594\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2983 - acc: 0.2600\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2977 - acc: 0.2598\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2954 - acc: 0.2605\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2942 - acc: 0.2611\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2928 - acc: 0.2618\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2927 - acc: 0.2614\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2914 - acc: 0.2621\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2909 - acc: 0.2623\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2891 - acc: 0.2628\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2879 - acc: 0.2632\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2878 - acc: 0.2631\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2868 - acc: 0.2637\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2873 - acc: 0.2633\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2855 - acc: 0.2642\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2842 - acc: 0.2644\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2823 - acc: 0.2653\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2822 - acc: 0.2652\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2807 - acc: 0.2657\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2797 - acc: 0.2658\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2788 - acc: 0.2665\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2790 - acc: 0.2665\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2776 - acc: 0.2668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.01      0.03      1140\n",
      "           1       0.63      0.72      0.67     21702\n",
      "           2       0.35      0.31      0.33      3863\n",
      "           3       0.75      0.81      0.78     32918\n",
      "           4       0.45      0.26      0.33       653\n",
      "           5       0.49      0.52      0.50     19968\n",
      "           6       0.37      0.15      0.21      8876\n",
      "           7       0.42      0.42      0.42     11455\n",
      "\n",
      "    accuracy                           0.60    100575\n",
      "   macro avg       0.52      0.40      0.41    100575\n",
      "weighted avg       0.58      0.60      0.58    100575\n",
      "\n",
      "Acur√°cia\n",
      "0.4008522625130785\n",
      "Precisao\n",
      "0.5828602929588377\n",
      "Recall\n",
      "0.5987571464081531\n",
      "F1\n",
      "0.5812737375933678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   16   291    42   146     0   469    50   126]\n",
      " [    2 15677   248  1940    14  2723   237   861]\n",
      " [    0   469  1215   818    15   677   132   537]\n",
      " [    0  2041   529 26661   139  1890   210  1448]\n",
      " [    0    45    16   319   169    51    12    41]\n",
      " [    4  3756   542  2324    18 10330   997  1997]\n",
      " [    0  1400   291  1145     6  3174  1292  1568]\n",
      " [    0  1184   568  2292    17  1958   576  4860]]\n",
      "TRAIN: [   0    1    3 ... 1996 1998 1999] TEST: [   2    4    6   15   28   33   38   40   44   50   58   70   74   78\n",
      "   82   99  106  113  115  120  122  127  128  130  132  135  138  143\n",
      "  149  158  173  181  187  195  196  199  205  212  226  227  228  229\n",
      "  233  234  238  241  242  243  257  265  266  272  273  280  288  291\n",
      "  305  307  317  319  321  322  325  330  332  333  338  346  353  363\n",
      "  364  366  374  380  381  384  390  392  401  402  411  414  415  419\n",
      "  435  436  443  445  447  453  454  456  458  461  466  485  486  488\n",
      "  494  504  509  510  511  514  526  537  538  556  558  561  563  572\n",
      "  577  588  592  595  602  603  605  609  613  619  621  623  633  647\n",
      "  654  655  663  665  673  677  678  683  695  705  706  718  720  722\n",
      "  724  727  728  731  732  734  746  753  755  766  776  778  779  782\n",
      "  804  807  812  813  815  820  844  847  857  866  871  878  879  880\n",
      "  883  885  888  890  896  899  902  914  925  939  942  945  950  951\n",
      "  955  957  959  961  963  965  966  970  975  978  981  985  990  992\n",
      "  993  995 1000 1007 1024 1028 1032 1036 1038 1043 1046 1050 1063 1068\n",
      " 1069 1070 1071 1073 1077 1081 1082 1084 1085 1086 1089 1106 1114 1120\n",
      " 1125 1130 1131 1134 1135 1142 1159 1165 1172 1176 1188 1190 1192 1199\n",
      " 1205 1206 1208 1223 1226 1228 1230 1231 1238 1239 1243 1244 1258 1259\n",
      " 1263 1272 1287 1307 1309 1310 1325 1331 1334 1338 1343 1348 1350 1357\n",
      " 1360 1362 1366 1374 1378 1379 1384 1386 1387 1388 1389 1390 1393 1395\n",
      " 1402 1405 1411 1418 1419 1430 1431 1443 1451 1460 1461 1465 1469 1473\n",
      " 1477 1482 1488 1491 1495 1500 1506 1510 1515 1517 1518 1525 1532 1539\n",
      " 1541 1547 1548 1560 1562 1569 1570 1571 1572 1578 1579 1585 1591 1607\n",
      " 1620 1623 1626 1628 1629 1641 1648 1659 1662 1669 1679 1690 1694 1713\n",
      " 1714 1716 1724 1728 1738 1739 1741 1748 1751 1754 1755 1760 1762 1766\n",
      " 1772 1782 1784 1785 1788 1795 1797 1802 1807 1808 1813 1817 1823 1827\n",
      " 1837 1840 1844 1845 1846 1847 1869 1872 1877 1880 1881 1889 1892 1896\n",
      " 1904 1906 1907 1910 1913 1914 1915 1919 1920 1932 1941 1945 1948 1953\n",
      " 1954 1965 1967 1971 1987 1990 1994 1997]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.5827 - acc: 0.1617\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5314 - acc: 0.1710\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5226 - acc: 0.1751\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5180 - acc: 0.1771\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5103 - acc: 0.1808\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5070 - acc: 0.1824\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5012 - acc: 0.1847\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4976 - acc: 0.1863\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4943 - acc: 0.1878\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4962 - acc: 0.1869\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4887 - acc: 0.1901\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4850 - acc: 0.1918\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4805 - acc: 0.1939\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4790 - acc: 0.1944\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4757 - acc: 0.1954\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4716 - acc: 0.1973\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4687 - acc: 0.1987\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4602 - acc: 0.2018\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4531 - acc: 0.2047\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4480 - acc: 0.2070\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4420 - acc: 0.2089\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4370 - acc: 0.2102\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4346 - acc: 0.2112\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4296 - acc: 0.2130\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4249 - acc: 0.2150\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4224 - acc: 0.2155\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4163 - acc: 0.2178\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4128 - acc: 0.2190\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4080 - acc: 0.2201\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4046 - acc: 0.2218\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4011 - acc: 0.2227\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3976 - acc: 0.2242\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3938 - acc: 0.2252\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3901 - acc: 0.2263\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3873 - acc: 0.2270\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3851 - acc: 0.2283\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3804 - acc: 0.2294\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3774 - acc: 0.2305\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3737 - acc: 0.2316\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3727 - acc: 0.2320\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3669 - acc: 0.2338\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3639 - acc: 0.2347\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3640 - acc: 0.2349\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3600 - acc: 0.2360\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3569 - acc: 0.2370\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3555 - acc: 0.2377\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3545 - acc: 0.2376\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3494 - acc: 0.2392\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3489 - acc: 0.2394\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3460 - acc: 0.2403\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3441 - acc: 0.2411\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3397 - acc: 0.2424\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3387 - acc: 0.2425\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3385 - acc: 0.2429\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3377 - acc: 0.2432\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3322 - acc: 0.2450\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3308 - acc: 0.2453\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3296 - acc: 0.2458\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3275 - acc: 0.2464\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3247 - acc: 0.2473\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3238 - acc: 0.2478\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3211 - acc: 0.2488\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3204 - acc: 0.2490\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3188 - acc: 0.2495\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3179 - acc: 0.2499\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3171 - acc: 0.2497\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3143 - acc: 0.2507\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3126 - acc: 0.2513\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3136 - acc: 0.2510\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3103 - acc: 0.2523\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3089 - acc: 0.2524\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3064 - acc: 0.2535\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3054 - acc: 0.2541\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3042 - acc: 0.2544\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3025 - acc: 0.2546\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3022 - acc: 0.2547\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2998 - acc: 0.2554\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2988 - acc: 0.2560\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2973 - acc: 0.2563\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2981 - acc: 0.2561\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2963 - acc: 0.2568\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2944 - acc: 0.2575\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2954 - acc: 0.2569\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2924 - acc: 0.2581\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2912 - acc: 0.2584\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2906 - acc: 0.2588\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2895 - acc: 0.2591\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2880 - acc: 0.2595\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2875 - acc: 0.2598\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2861 - acc: 0.2602\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2849 - acc: 0.2605\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2847 - acc: 0.2607\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2834 - acc: 0.2612\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2815 - acc: 0.2618\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2828 - acc: 0.2615\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2799 - acc: 0.2624\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2793 - acc: 0.2625\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2794 - acc: 0.2627\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2786 - acc: 0.2630\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2770 - acc: 0.2635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.02      0.04      1352\n",
      "           1       0.63      0.70      0.66     21460\n",
      "           2       0.36      0.29      0.32      4056\n",
      "           3       0.75      0.81      0.78     34376\n",
      "           4       0.44      0.27      0.34       730\n",
      "           5       0.48      0.54      0.51     21246\n",
      "           6       0.34      0.15      0.21      9016\n",
      "           7       0.43      0.42      0.42     12155\n",
      "\n",
      "    accuracy                           0.59    104391\n",
      "   macro avg       0.50      0.40      0.41    104391\n",
      "weighted avg       0.58      0.59      0.58    104391\n",
      "\n",
      "Acur√°cia\n",
      "0.39911047471403166\n",
      "Precisao\n",
      "0.576876404280097\n",
      "Recall\n",
      "0.5934707014972556\n",
      "F1\n",
      "0.577017641940452\n",
      "[[   27   313    48   146     1   589    75   153]\n",
      " [    2 14930   249  1884    30  3115   301   949]\n",
      " [    0   455  1179   913     3   805   132   569]\n",
      " [    1  1965   547 27688   148  2205   258  1564]\n",
      " [    0    80     7   348   200    50     3    42]\n",
      " [    9  3686   487  2426    21 11533  1123  1961]\n",
      " [    2  1301   289  1146    18  3432  1329  1499]\n",
      " [    5  1066   455  2426    30  2423   683  5067]]\n",
      "TRAIN: [   1    2    4 ... 1995 1997 1998] TEST: [   0    3   31   32   46   52   56   57   64   65   72   73   86  100\n",
      "  101  103  109  110  116  117  118  121  124  131  136  140  145  148\n",
      "  155  156  159  166  170  174  175  178  182  183  185  197  211  224\n",
      "  225  232  235  237  252  256  260  270  274  276  289  294  295  304\n",
      "  310  314  315  316  318  328  331  336  342  354  368  370  371  376\n",
      "  378  382  389  391  416  418  420  424  428  433  437  441  463  467\n",
      "  468  480  487  492  493  498  501  503  508  517  525  527  530  531\n",
      "  544  545  554  557  564  567  568  575  581  584  585  586  589  590\n",
      "  604  607  608  612  618  625  630  644  645  648  653  657  666  684\n",
      "  686  689  697  701  703  708  717  719  725  737  739  744  749  757\n",
      "  758  759  763  765  770  785  786  797  805  842  849  858  864  865\n",
      "  867  874  881  887  897  912  920  921  933  941  943  954  956  964\n",
      "  971  976  986  991  998 1012 1014 1017 1022 1023 1026 1027 1031 1034\n",
      " 1040 1041 1044 1051 1052 1055 1058 1062 1074 1079 1083 1087 1090 1091\n",
      " 1093 1094 1095 1096 1099 1100 1105 1110 1112 1115 1121 1127 1137 1139\n",
      " 1143 1144 1152 1155 1156 1157 1167 1173 1175 1182 1184 1186 1189 1194\n",
      " 1200 1202 1203 1211 1216 1229 1240 1241 1251 1252 1254 1255 1256 1257\n",
      " 1260 1265 1267 1271 1273 1275 1276 1282 1288 1289 1296 1297 1305 1311\n",
      " 1315 1327 1332 1336 1341 1342 1344 1359 1361 1372 1373 1381 1382 1383\n",
      " 1398 1403 1410 1414 1416 1422 1425 1429 1445 1446 1449 1452 1455 1457\n",
      " 1458 1466 1467 1475 1478 1483 1496 1501 1509 1511 1512 1519 1522 1528\n",
      " 1533 1545 1552 1553 1561 1566 1580 1581 1582 1583 1586 1589 1596 1598\n",
      " 1600 1604 1610 1611 1614 1615 1618 1624 1627 1631 1633 1636 1642 1650\n",
      " 1666 1668 1673 1677 1678 1682 1686 1688 1692 1695 1699 1704 1707 1710\n",
      " 1712 1715 1717 1718 1740 1744 1747 1753 1756 1757 1763 1775 1780 1786\n",
      " 1789 1790 1791 1793 1798 1799 1800 1810 1812 1815 1816 1820 1826 1832\n",
      " 1833 1834 1835 1848 1857 1858 1860 1863 1865 1871 1873 1882 1886 1890\n",
      " 1891 1893 1895 1900 1916 1927 1931 1934 1935 1936 1937 1952 1955 1960\n",
      " 1964 1966 1973 1977 1978 1991 1996 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.5863 - acc: 0.1571\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5295 - acc: 0.1717\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.5203 - acc: 0.1761\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.5164 - acc: 0.1783\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5104 - acc: 0.1810\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5060 - acc: 0.1826\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5005 - acc: 0.1853\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4990 - acc: 0.1859\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4923 - acc: 0.1887\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4905 - acc: 0.1896\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4856 - acc: 0.1917\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4847 - acc: 0.1922\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4796 - acc: 0.1945\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4779 - acc: 0.1952\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4749 - acc: 0.1961\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4701 - acc: 0.1980\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4676 - acc: 0.1994\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4612 - acc: 0.2013\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4560 - acc: 0.2032\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4482 - acc: 0.2059\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4432 - acc: 0.2078\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4380 - acc: 0.2098\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4334 - acc: 0.2116\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4280 - acc: 0.2134\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4236 - acc: 0.2148\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4203 - acc: 0.2158\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4169 - acc: 0.2174\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4126 - acc: 0.2185\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4089 - acc: 0.2199\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4046 - acc: 0.2210\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4019 - acc: 0.2221\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3979 - acc: 0.2232\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3928 - acc: 0.2249\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3902 - acc: 0.2258\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3861 - acc: 0.2272\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3817 - acc: 0.2287\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3786 - acc: 0.2298\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3759 - acc: 0.2305\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3712 - acc: 0.2322\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3667 - acc: 0.2333\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3660 - acc: 0.2338\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3630 - acc: 0.2347\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3594 - acc: 0.2356\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3575 - acc: 0.2362\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3559 - acc: 0.2368\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3534 - acc: 0.2376\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3502 - acc: 0.2385\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3477 - acc: 0.2391\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3455 - acc: 0.2402\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3417 - acc: 0.2415\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3395 - acc: 0.2418\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3378 - acc: 0.2426\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3357 - acc: 0.2435\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3351 - acc: 0.2434\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3312 - acc: 0.2448\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3292 - acc: 0.2453\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3291 - acc: 0.2456\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3264 - acc: 0.2464\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3225 - acc: 0.2475\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3220 - acc: 0.2477\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3222 - acc: 0.2479\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3179 - acc: 0.2492\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3189 - acc: 0.2487\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3174 - acc: 0.2493\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3143 - acc: 0.2507\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3123 - acc: 0.2509\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3122 - acc: 0.2511\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3093 - acc: 0.2519\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3091 - acc: 0.2522\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3071 - acc: 0.2529\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3068 - acc: 0.2529\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3049 - acc: 0.2536\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3032 - acc: 0.2539\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3014 - acc: 0.2545\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3000 - acc: 0.2552\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2992 - acc: 0.2554\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2974 - acc: 0.2558\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2970 - acc: 0.2559\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2965 - acc: 0.2561\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2939 - acc: 0.2574\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2948 - acc: 0.2568\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2910 - acc: 0.2583\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2906 - acc: 0.2584\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2897 - acc: 0.2585\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2891 - acc: 0.2588\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2878 - acc: 0.2593\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2861 - acc: 0.2597\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2863 - acc: 0.2597\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2846 - acc: 0.2602\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2837 - acc: 0.2603\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2832 - acc: 0.2610\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2805 - acc: 0.2616\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2811 - acc: 0.2616\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2795 - acc: 0.2619\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2784 - acc: 0.2625\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2782 - acc: 0.2622\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2778 - acc: 0.2627\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2762 - acc: 0.2630\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2759 - acc: 0.2632\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2747 - acc: 0.2636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.01      0.01      1304\n",
      "           1       0.64      0.68      0.66     22079\n",
      "           2       0.34      0.30      0.32      4071\n",
      "           3       0.72      0.84      0.78     34181\n",
      "           4       0.57      0.28      0.38       726\n",
      "           5       0.48      0.52      0.50     21426\n",
      "           6       0.36      0.16      0.22      9417\n",
      "           7       0.44      0.39      0.41     11672\n",
      "\n",
      "    accuracy                           0.59    104876\n",
      "   macro avg       0.52      0.40      0.41    104876\n",
      "weighted avg       0.57      0.59      0.57    104876\n",
      "\n",
      "Acur√°cia\n",
      "0.3960440281144815\n",
      "Precisao\n",
      "0.5729075177396439\n",
      "Recall\n",
      "0.5936629924863649\n",
      "F1\n",
      "0.5737837128313789\n",
      "[[    9   292    46   190     0   590    65   112]\n",
      " [    0 14952   306  2769    29  2950   328   745]\n",
      " [    0   463  1216   990     4   728   119   551]\n",
      " [    0  1624   455 28746    79  1971   252  1054]\n",
      " [    0    40     7   362   204    62     8    43]\n",
      " [    3  3703   655  2847    12 11140  1200  1866]\n",
      " [    2  1308   379  1325    11  3460  1467  1465]\n",
      " [    1  1140   560  2615    17  2157   655  4527]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [  12   14   16   18   21   24   26   30   35   36   41   42   47   51\n",
      "   53   55   60   66   67   68   69   71   75   76   85   94   96  104\n",
      "  119  126  134  141  151  154  157  160  161  162  171  172  179  180\n",
      "  191  192  198  200  202  203  204  216  220  231  240  245  246  248\n",
      "  253  254  268  277  284  285  286  292  293  296  299  300  301  303\n",
      "  306  311  312  334  343  350  357  359  367  372  377  379  387  394\n",
      "  397  400  408  412  413  421  422  429  432  434  442  451  452  455\n",
      "  471  472  475  476  484  489  500  502  515  519  521  523  524  528\n",
      "  533  541  542  546  548  552  560  562  565  566  571  576  578  583\n",
      "  587  615  620  628  632  640  646  651  664  671  674  679  681  685\n",
      "  692  693  694  699  707  709  713  715  721  726  730  733  736  738\n",
      "  748  751  752  756  761  764  767  773  777  781  783  784  792  793\n",
      "  794  796  802  806  808  816  821  823  830  834  835  843  845  846\n",
      "  850  854  860  861  868  876  886  889  894  900  901  915  916  928\n",
      "  931  934  936  937  938  947  958  962  973  989  997 1004 1005 1008\n",
      " 1011 1013 1025 1029 1030 1049 1053 1056 1064 1065 1067 1075 1076 1080\n",
      " 1088 1098 1104 1111 1113 1118 1119 1128 1132 1133 1140 1145 1147 1151\n",
      " 1154 1160 1164 1168 1169 1180 1181 1198 1201 1212 1213 1217 1218 1221\n",
      " 1234 1235 1237 1247 1262 1264 1266 1269 1277 1280 1281 1283 1290 1292\n",
      " 1294 1295 1308 1317 1321 1326 1328 1330 1339 1346 1349 1351 1355 1365\n",
      " 1367 1368 1371 1376 1377 1380 1385 1394 1396 1400 1404 1412 1413 1415\n",
      " 1417 1420 1434 1438 1439 1440 1442 1447 1453 1459 1489 1492 1494 1503\n",
      " 1505 1507 1508 1514 1523 1529 1530 1531 1535 1537 1540 1555 1556 1557\n",
      " 1558 1565 1568 1573 1587 1597 1601 1603 1605 1609 1613 1619 1634 1652\n",
      " 1654 1658 1660 1664 1671 1674 1675 1676 1693 1696 1697 1700 1705 1706\n",
      " 1709 1719 1722 1727 1730 1731 1732 1733 1745 1752 1758 1765 1770 1776\n",
      " 1787 1804 1809 1830 1831 1839 1849 1850 1853 1855 1859 1861 1862 1866\n",
      " 1874 1878 1885 1887 1905 1923 1924 1930 1933 1949 1957 1961 1970 1974\n",
      " 1975 1976 1980 1981 1985 1986 1992 1993]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.5844 - acc: 0.1594\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5340 - acc: 0.1711\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.5214 - acc: 0.1771\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.5174 - acc: 0.1788\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.5134 - acc: 0.1805\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5068 - acc: 0.1836\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5040 - acc: 0.1844\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5001 - acc: 0.1861\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4997 - acc: 0.1861\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4957 - acc: 0.1884\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4903 - acc: 0.1898\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4863 - acc: 0.1923\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4854 - acc: 0.1925\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4831 - acc: 0.1935\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4767 - acc: 0.1966\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4819 - acc: 0.1941\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4684 - acc: 0.2000\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4607 - acc: 0.2027\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4557 - acc: 0.2043\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4494 - acc: 0.2067\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4439 - acc: 0.2087\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4380 - acc: 0.2112\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4332 - acc: 0.2126\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4283 - acc: 0.2149\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4242 - acc: 0.2162\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.4234 - acc: 0.2164\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4162 - acc: 0.2187\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4118 - acc: 0.2204\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4098 - acc: 0.2209\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.4045 - acc: 0.2223\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3991 - acc: 0.2247\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3965 - acc: 0.2254\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3942 - acc: 0.2260\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3901 - acc: 0.2271\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3851 - acc: 0.2288\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3830 - acc: 0.2296\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3799 - acc: 0.2308\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3751 - acc: 0.2323\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3725 - acc: 0.2329\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3701 - acc: 0.2340\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3667 - acc: 0.2347\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3642 - acc: 0.2357\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3605 - acc: 0.2369\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3573 - acc: 0.2378\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3550 - acc: 0.2384\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3525 - acc: 0.2396\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3501 - acc: 0.2403\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3481 - acc: 0.2410\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3450 - acc: 0.2417\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3435 - acc: 0.2423\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3413 - acc: 0.2431\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3410 - acc: 0.2429\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3365 - acc: 0.2444\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3359 - acc: 0.2447\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3327 - acc: 0.2456\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3301 - acc: 0.2466\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3292 - acc: 0.2471\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3273 - acc: 0.2473\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3263 - acc: 0.2477\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3241 - acc: 0.2483\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3221 - acc: 0.2493\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3195 - acc: 0.2501\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3179 - acc: 0.2505\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3159 - acc: 0.2512\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3151 - acc: 0.2516\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3141 - acc: 0.2519\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3138 - acc: 0.2520\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3106 - acc: 0.2528\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3105 - acc: 0.2531\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3096 - acc: 0.2532\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3066 - acc: 0.2542\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3048 - acc: 0.2547\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3027 - acc: 0.2554\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3032 - acc: 0.2555\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3016 - acc: 0.2558\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2996 - acc: 0.2564\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2979 - acc: 0.2572\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2982 - acc: 0.2572\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2971 - acc: 0.2575\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2969 - acc: 0.2577\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2947 - acc: 0.2582\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2938 - acc: 0.2584\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2915 - acc: 0.2594\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2914 - acc: 0.2594\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2903 - acc: 0.2599\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2891 - acc: 0.2604\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2877 - acc: 0.2605\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2861 - acc: 0.2611\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2864 - acc: 0.2609\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2840 - acc: 0.2618\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2840 - acc: 0.2618\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2833 - acc: 0.2618\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2817 - acc: 0.2625\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2823 - acc: 0.2626\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2789 - acc: 0.2635\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2817 - acc: 0.2629\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2795 - acc: 0.2635\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2789 - acc: 0.2637\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2770 - acc: 0.2640\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2749 - acc: 0.2650\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.01      0.02      1207\n",
      "           1       0.67      0.68      0.67     21988\n",
      "           2       0.37      0.30      0.33      4058\n",
      "           3       0.74      0.82      0.78     33852\n",
      "           4       0.52      0.27      0.35       718\n",
      "           5       0.47      0.55      0.51     20627\n",
      "           6       0.39      0.14      0.21      9428\n",
      "           7       0.41      0.45      0.42     11665\n",
      "\n",
      "    accuracy                           0.60    103543\n",
      "   macro avg       0.51      0.40      0.41    103543\n",
      "weighted avg       0.59      0.60      0.58    103543\n",
      "\n",
      "Acur√°cia\n",
      "0.40215075732017913\n",
      "Precisao\n",
      "0.5852875417492183\n",
      "Recall\n",
      "0.5995383560453145\n",
      "F1\n",
      "0.5824030445652317\n",
      "[[   13   263    32   158     0   555    47   139]\n",
      " [    2 14966   297  1994    10  3415   237  1067]\n",
      " [    0   388  1220   920     1   750   112   667]\n",
      " [    0  1503   430 27914   109  2037   180  1679]\n",
      " [    0    54     8   326   193    78    11    48]\n",
      " [    7  3154   488  2477    22 11242   986  2251]\n",
      " [    2  1110   272  1312     9  3621  1325  1777]\n",
      " [    0   957   514  2386    30  2067   506  5205]]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_32 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_33 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_34 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_35 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_36 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_37 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_38 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_39 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 1,343,208\n",
      "Trainable params: 1,343,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acur√°cias total\n",
      "[0.3971256100494075, 0.4008522625130785, 0.39911047471403166, 0.3960440281144815, 0.40215075732017913]\n",
      "0.3990566265422356\n",
      "Precision total\n",
      "[0.5836254568227557, 0.5828602929588377, 0.576876404280097, 0.5729075177396439, 0.5852875417492183]\n",
      "0.5803114427101106\n",
      "Recalls total\n",
      "[0.5970143424816692, 0.5987571464081531, 0.5934707014972556, 0.5936629924863649, 0.5995383560453145]\n",
      "0.5964887077837514\n",
      "F1 total\n",
      "[0.5798848993790338, 0.5812737375933678, 0.577017641940452, 0.5737837128313789, 0.5824030445652317]\n",
      "0.5788726072618928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    3 ... 1995 1996 1997] TEST: [   2   13   15   16   17   18   26   32   33   36   39   45   60   63\n",
      "   66   68   69   71   73   78   82   85   89   90   94   96  100  102\n",
      "  111  113  117  133  134  139  141  147  148  158  162  166  167  170\n",
      "  174  186  197  201  204  205  209  210  221  224  230  234  243  245\n",
      "  251  253  254  257  258  259  260  268  270  272  276  291  299  303\n",
      "  304  310  314  323  344  346  361  363  366  372  375  380  382  383\n",
      "  394  402  407  408  413  415  418  421  422  425  434  439  450  462\n",
      "  466  473  474  476  478  487  503  508  512  526  531  532  534  538\n",
      "  547  557  559  564  565  569  571  573  575  577  581  593  596  611\n",
      "  612  616  620  622  623  630  632  633  636  640  645  652  660  661\n",
      "  662  663  670  674  691  695  706  708  712  714  724  728  732  738\n",
      "  741  747  755  761  762  763  777  782  783  786  788  789  793  804\n",
      "  805  814  816  826  827  833  834  838  839  840  841  853  858  859\n",
      "  874  890  893  897  898  900  904  906  908  924  927  933  935  939\n",
      "  940  943  945  953  957  966  970  982  984  987  997 1021 1033 1037\n",
      " 1039 1043 1054 1058 1060 1064 1073 1075 1076 1078 1085 1086 1094 1106\n",
      " 1107 1110 1113 1117 1118 1138 1144 1145 1148 1150 1152 1155 1157 1159\n",
      " 1177 1183 1189 1194 1200 1201 1211 1218 1221 1226 1227 1236 1237 1238\n",
      " 1239 1241 1242 1244 1252 1259 1261 1264 1265 1270 1273 1277 1278 1280\n",
      " 1286 1288 1298 1300 1302 1310 1314 1315 1317 1318 1323 1325 1331 1332\n",
      " 1333 1349 1357 1359 1365 1370 1372 1373 1380 1381 1386 1390 1391 1395\n",
      " 1397 1398 1404 1406 1410 1417 1418 1422 1424 1441 1443 1448 1453 1454\n",
      " 1456 1458 1461 1467 1468 1471 1473 1476 1480 1481 1484 1514 1523 1532\n",
      " 1538 1545 1559 1563 1571 1572 1574 1586 1587 1593 1595 1602 1604 1607\n",
      " 1608 1610 1643 1644 1647 1653 1654 1660 1664 1667 1668 1672 1680 1697\n",
      " 1703 1709 1716 1721 1727 1735 1743 1753 1754 1767 1771 1777 1780 1786\n",
      " 1790 1797 1798 1819 1822 1828 1830 1834 1841 1843 1849 1855 1856 1861\n",
      " 1862 1866 1867 1870 1882 1884 1905 1906 1936 1938 1945 1955 1961 1965\n",
      " 1971 1973 1975 1976 1987 1989 1998 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.3420 - acc: 0.8228\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3160 - acc: 0.8578\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3090 - acc: 0.8603\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3097 - acc: 0.8594\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3042 - acc: 0.8622\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3034 - acc: 0.8634\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3008 - acc: 0.8643\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2994 - acc: 0.8654\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2946 - acc: 0.8670\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2970 - acc: 0.8656\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2909 - acc: 0.8686\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2889 - acc: 0.8698\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2862 - acc: 0.8711\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2858 - acc: 0.8714\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2840 - acc: 0.8724\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2828 - acc: 0.8732\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2781 - acc: 0.8757\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2815 - acc: 0.8746\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2736 - acc: 0.8779\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2692 - acc: 0.8805\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2628 - acc: 0.8844\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2603 - acc: 0.8854\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2568 - acc: 0.8872\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2525 - acc: 0.8889\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2483 - acc: 0.8916\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2469 - acc: 0.8926\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2421 - acc: 0.8948\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2410 - acc: 0.8952\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2374 - acc: 0.8968\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2330 - acc: 0.8989\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2313 - acc: 0.9002\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2281 - acc: 0.9015\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2261 - acc: 0.9023\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2257 - acc: 0.9027\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2219 - acc: 0.9044\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2176 - acc: 0.9064\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2136 - acc: 0.9082\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2114 - acc: 0.9095\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2095 - acc: 0.9099\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2070 - acc: 0.9112\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2048 - acc: 0.9123\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2019 - acc: 0.9135\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2004 - acc: 0.9143\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1974 - acc: 0.9159\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1963 - acc: 0.9161\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1937 - acc: 0.9176\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1914 - acc: 0.9186\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1889 - acc: 0.9196\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1869 - acc: 0.9205\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1849 - acc: 0.9213\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1828 - acc: 0.9224\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1824 - acc: 0.9225\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1804 - acc: 0.9235\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1788 - acc: 0.9243\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1764 - acc: 0.9252\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1755 - acc: 0.9259\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1736 - acc: 0.9266\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1712 - acc: 0.9273\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1705 - acc: 0.9273\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1688 - acc: 0.9284\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1675 - acc: 0.9293\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1664 - acc: 0.9295\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1647 - acc: 0.9301\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1635 - acc: 0.9306\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1621 - acc: 0.9314\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1613 - acc: 0.9312\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1597 - acc: 0.9323\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1586 - acc: 0.9328\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1568 - acc: 0.9338\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1559 - acc: 0.9341\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1556 - acc: 0.9342\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1544 - acc: 0.9348\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1527 - acc: 0.9356\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1516 - acc: 0.9358\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1523 - acc: 0.9356\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1511 - acc: 0.9360\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1495 - acc: 0.9371\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1475 - acc: 0.9378\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1480 - acc: 0.9376\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1468 - acc: 0.9380\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1458 - acc: 0.9386\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1443 - acc: 0.9389\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1442 - acc: 0.9389\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1428 - acc: 0.9397\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1418 - acc: 0.9400\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1417 - acc: 0.9400\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1406 - acc: 0.9408\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1399 - acc: 0.9407\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1387 - acc: 0.9414\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1376 - acc: 0.9419\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1380 - acc: 0.9420\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1364 - acc: 0.9424\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1359 - acc: 0.9428\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1362 - acc: 0.9428\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1345 - acc: 0.9435\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1341 - acc: 0.9434\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1334 - acc: 0.9437\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1333 - acc: 0.9438\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1316 - acc: 0.9447\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1323 - acc: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72     42326\n",
      "           1       0.68      0.63      0.66     22732\n",
      "           2       0.76      0.78      0.77     36628\n",
      "\n",
      "    accuracy                           0.72    101686\n",
      "   macro avg       0.72      0.71      0.72    101686\n",
      "weighted avg       0.72      0.72      0.72    101686\n",
      "\n",
      "Acur√°cia\n",
      "0.7131677352497455\n",
      "Precisao\n",
      "0.7232358096259303\n",
      "Recall\n",
      "0.7242884959581457\n",
      "F1\n",
      "0.7234506602439073\n",
      "[[30495  4858  6973]\n",
      " [ 5970 14430  2332]\n",
      " [ 6116  1787 28725]]\n",
      "TRAIN: [   2    3    6 ... 1997 1998 1999] TEST: [   0    1    4    5    8   10   12   20   23   35   43   52   53   56\n",
      "   62   65   67   70   86   91   92   95  103  108  122  125  138  142\n",
      "  143  152  156  159  163  165  173  176  179  183  190  193  194  196\n",
      "  206  207  208  222  226  236  239  247  248  249  264  267  269  273\n",
      "  288  292  296  297  298  300  301  305  307  313  316  318  320  328\n",
      "  329  334  335  336  337  339  340  341  342  343  347  348  349  350\n",
      "  359  360  368  377  381  388  389  399  401  417  420  433  437  440\n",
      "  441  445  446  448  454  459  460  467  469  470  475  494  500  502\n",
      "  505  510  514  517  519  520  529  536  539  540  545  550  560  562\n",
      "  567  568  572  579  583  587  594  599  606  609  614  621  628  631\n",
      "  638  639  641  642  644  651  665  666  671  672  676  678  682  693\n",
      "  696  697  721  729  731  740  744  749  752  759  766  767  775  780\n",
      "  781  790  801  802  803  809  813  815  831  846  851  862  867  872\n",
      "  881  889  902  903  905  907  912  913  916  922  923  931  937  948\n",
      "  956  968  969  971  972  993  995 1002 1004 1006 1010 1017 1018 1019\n",
      " 1026 1027 1028 1035 1036 1040 1041 1049 1051 1052 1055 1057 1062 1063\n",
      " 1084 1087 1089 1095 1101 1104 1109 1112 1123 1134 1137 1139 1140 1142\n",
      " 1151 1161 1162 1166 1167 1175 1182 1186 1190 1191 1198 1199 1206 1210\n",
      " 1212 1219 1222 1225 1228 1231 1234 1235 1247 1253 1254 1257 1258 1262\n",
      " 1266 1268 1272 1276 1284 1291 1293 1299 1307 1313 1326 1328 1334 1341\n",
      " 1345 1352 1354 1363 1375 1377 1396 1401 1403 1405 1414 1415 1419 1421\n",
      " 1425 1431 1437 1439 1442 1450 1477 1479 1482 1487 1491 1497 1505 1506\n",
      " 1510 1525 1530 1531 1539 1551 1553 1556 1564 1568 1570 1575 1576 1594\n",
      " 1601 1605 1606 1609 1615 1620 1627 1628 1630 1634 1641 1650 1657 1669\n",
      " 1670 1678 1679 1681 1683 1689 1695 1700 1701 1706 1710 1725 1726 1729\n",
      " 1731 1744 1746 1755 1757 1761 1779 1789 1794 1801 1816 1820 1831 1835\n",
      " 1842 1844 1850 1851 1860 1864 1871 1873 1879 1885 1887 1891 1899 1903\n",
      " 1904 1917 1918 1923 1926 1927 1928 1929 1935 1937 1942 1943 1944 1950\n",
      " 1951 1963 1972 1981 1990 1991 1993 1995]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.3421 - acc: 0.7743\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3136 - acc: 0.8576\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3107 - acc: 0.8591\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3069 - acc: 0.8611\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3032 - acc: 0.8633\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3037 - acc: 0.8631\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3000 - acc: 0.8649\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2981 - acc: 0.8653\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2961 - acc: 0.8662\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2956 - acc: 0.8666\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2925 - acc: 0.8687\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2900 - acc: 0.8689\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2889 - acc: 0.8705\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2878 - acc: 0.8701\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2851 - acc: 0.8717\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2830 - acc: 0.8724\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2808 - acc: 0.8734\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2786 - acc: 0.8748\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2762 - acc: 0.8760\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2745 - acc: 0.8776\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2760 - acc: 0.8769\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2711 - acc: 0.8794\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2616 - acc: 0.8844\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2562 - acc: 0.8870\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2520 - acc: 0.8892\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2550 - acc: 0.8879\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2565 - acc: 0.8878\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2468 - acc: 0.8922\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2429 - acc: 0.8942\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2404 - acc: 0.8954\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2362 - acc: 0.8970\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2329 - acc: 0.8992\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2292 - acc: 0.9007\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2268 - acc: 0.9016\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2240 - acc: 0.9030\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2204 - acc: 0.9052\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2192 - acc: 0.9053\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2163 - acc: 0.9069\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2136 - acc: 0.9082\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2102 - acc: 0.9094\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2077 - acc: 0.9108\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2054 - acc: 0.9120\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2014 - acc: 0.9137\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1991 - acc: 0.9148\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1974 - acc: 0.9156\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1949 - acc: 0.9170\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1929 - acc: 0.9179\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1914 - acc: 0.9184\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1898 - acc: 0.9191\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1867 - acc: 0.9206\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1849 - acc: 0.9216\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1829 - acc: 0.9224\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1809 - acc: 0.9235\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1793 - acc: 0.9239\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1776 - acc: 0.9246\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1757 - acc: 0.9257\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1752 - acc: 0.9258\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1744 - acc: 0.9258\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1712 - acc: 0.9273\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1692 - acc: 0.9285\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1677 - acc: 0.9290\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1664 - acc: 0.9299\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1652 - acc: 0.9302\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1644 - acc: 0.9307\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1634 - acc: 0.9310\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1625 - acc: 0.9317\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1607 - acc: 0.9323\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1591 - acc: 0.9329\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1584 - acc: 0.9332\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1559 - acc: 0.9344\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1549 - acc: 0.9347\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1550 - acc: 0.9348\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1539 - acc: 0.9353\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1537 - acc: 0.9354\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1527 - acc: 0.9358\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1496 - acc: 0.9370\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1487 - acc: 0.9378\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1485 - acc: 0.9375\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1472 - acc: 0.9382\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1458 - acc: 0.9390\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1453 - acc: 0.9390\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1433 - acc: 0.9402\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1438 - acc: 0.9399\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1434 - acc: 0.9400\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1419 - acc: 0.9410\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1411 - acc: 0.9408\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1408 - acc: 0.9412\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1389 - acc: 0.9418\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1398 - acc: 0.9416\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1376 - acc: 0.9423\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1379 - acc: 0.9422\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1370 - acc: 0.9428\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1362 - acc: 0.9429\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1346 - acc: 0.9438\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1343 - acc: 0.9441\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1341 - acc: 0.9442\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1332 - acc: 0.9447\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1318 - acc: 0.9452\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1314 - acc: 0.9451\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1308 - acc: 0.9456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72     41747\n",
      "           1       0.72      0.63      0.67     23623\n",
      "           2       0.77      0.78      0.77     37181\n",
      "\n",
      "    accuracy                           0.73    102551\n",
      "   macro avg       0.73      0.72      0.72    102551\n",
      "weighted avg       0.73      0.73      0.73    102551\n",
      "\n",
      "Acur√°cia\n",
      "0.7180042941421422\n",
      "Precisao\n",
      "0.7298791785330961\n",
      "Recall\n",
      "0.7301147721621437\n",
      "F1\n",
      "0.729248217183579\n",
      "[[30822  4395  6530]\n",
      " [ 6302 14959  2362]\n",
      " [ 6521  1567 29093]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   3    9   11   21   25   30   37   41   44   48   50   51   58   61\n",
      "   75   80   81   93  104  105  107  109  115  121  124  127  129  140\n",
      "  144  146  153  175  182  184  195  216  219  220  223  237  246  250\n",
      "  256  262  263  265  266  274  281  285  287  290  293  295  311  312\n",
      "  321  322  325  326  327  338  345  355  356  373  391  397  404  416\n",
      "  428  430  438  443  449  461  471  477  479  480  482  483  485  497\n",
      "  498  504  515  516  518  522  523  528  537  541  544  556  558  561\n",
      "  576  584  586  588  592  598  601  603  607  613  618  619  629  634\n",
      "  637  648  654  655  656  657  668  677  679  680  686  687  689  694\n",
      "  698  700  709  727  730  734  735  739  745  754  764  773  774  778\n",
      "  792  807  811  817  819  820  825  830  837  845  848  850  854  855\n",
      "  856  861  865  866  868  869  873  876  877  879  887  888  895  909\n",
      "  910  911  914  915  917  929  934  936  944  949  950  955  959  962\n",
      "  977  978  979  980  985  988  991  994  998 1000 1009 1016 1020 1022\n",
      " 1025 1029 1030 1038 1046 1050 1061 1065 1068 1072 1082 1083 1090 1091\n",
      " 1092 1096 1098 1102 1114 1115 1126 1130 1131 1135 1153 1172 1176 1180\n",
      " 1188 1193 1195 1202 1204 1205 1208 1214 1215 1216 1224 1229 1232 1255\n",
      " 1256 1260 1263 1274 1287 1289 1296 1301 1304 1305 1321 1322 1327 1335\n",
      " 1339 1342 1344 1346 1347 1348 1350 1351 1367 1374 1385 1387 1389 1392\n",
      " 1393 1394 1416 1429 1433 1444 1455 1460 1462 1463 1466 1472 1475 1478\n",
      " 1486 1490 1493 1496 1499 1501 1503 1515 1519 1521 1524 1527 1529 1540\n",
      " 1542 1544 1547 1548 1552 1554 1565 1566 1567 1573 1578 1580 1581 1582\n",
      " 1583 1585 1589 1600 1613 1618 1619 1624 1625 1633 1639 1649 1656 1659\n",
      " 1661 1662 1665 1666 1674 1677 1685 1687 1692 1693 1696 1704 1705 1707\n",
      " 1708 1720 1722 1730 1733 1736 1756 1759 1763 1769 1772 1775 1782 1783\n",
      " 1784 1785 1787 1788 1792 1796 1799 1802 1804 1813 1814 1815 1821 1825\n",
      " 1826 1840 1846 1852 1853 1859 1872 1875 1881 1883 1888 1890 1894 1896\n",
      " 1908 1911 1914 1919 1921 1922 1931 1933 1934 1939 1940 1948 1953 1954\n",
      " 1959 1962 1968 1969 1977 1978 1982 1996]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.3430 - acc: 0.8051\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3171 - acc: 0.8561\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3107 - acc: 0.8593\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3077 - acc: 0.8609\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3052 - acc: 0.8621\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3038 - acc: 0.8622\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3009 - acc: 0.8641\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2984 - acc: 0.8659\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2967 - acc: 0.8671\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2968 - acc: 0.8666\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2951 - acc: 0.8676\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2907 - acc: 0.8693\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2871 - acc: 0.8705\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2891 - acc: 0.8706\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2850 - acc: 0.8724\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2815 - acc: 0.8749\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2802 - acc: 0.8753\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2768 - acc: 0.8782\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2758 - acc: 0.8787\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2716 - acc: 0.8799\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2687 - acc: 0.8813\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2625 - acc: 0.8852\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2588 - acc: 0.8869\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2536 - acc: 0.8900\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2492 - acc: 0.8919\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2457 - acc: 0.8935\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2480 - acc: 0.8928\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2418 - acc: 0.8953\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2377 - acc: 0.8974\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2341 - acc: 0.8994\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2302 - acc: 0.9010\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2269 - acc: 0.9023\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2248 - acc: 0.9033\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2214 - acc: 0.9047\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2185 - acc: 0.9062\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2148 - acc: 0.9079\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2138 - acc: 0.9085\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2106 - acc: 0.9099\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2083 - acc: 0.9111\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2059 - acc: 0.9121\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2014 - acc: 0.9140\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1994 - acc: 0.9148\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1970 - acc: 0.9158\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1961 - acc: 0.9162\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1935 - acc: 0.9178\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1923 - acc: 0.9180\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1904 - acc: 0.9190\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1874 - acc: 0.9203\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1853 - acc: 0.9214\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1839 - acc: 0.9219\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1822 - acc: 0.9228\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1807 - acc: 0.9234\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1775 - acc: 0.9250\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1757 - acc: 0.9256\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1750 - acc: 0.9261\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1739 - acc: 0.9265\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1713 - acc: 0.9276\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1702 - acc: 0.9280\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1686 - acc: 0.9289\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1672 - acc: 0.9295\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1663 - acc: 0.9297\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1641 - acc: 0.9307\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1631 - acc: 0.9311\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1616 - acc: 0.9318\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1603 - acc: 0.9325\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1590 - acc: 0.9330\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1575 - acc: 0.9337\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1565 - acc: 0.9342\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1552 - acc: 0.9347\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1540 - acc: 0.9351\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1544 - acc: 0.9351\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1533 - acc: 0.9359\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1524 - acc: 0.9358\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1510 - acc: 0.9365\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1499 - acc: 0.9371\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1481 - acc: 0.9380\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1485 - acc: 0.9377\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1470 - acc: 0.9383\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1460 - acc: 0.9386\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1449 - acc: 0.9391\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1433 - acc: 0.9401\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1426 - acc: 0.9404\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1423 - acc: 0.9407\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1418 - acc: 0.9406\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1403 - acc: 0.9411\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1402 - acc: 0.9415\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1392 - acc: 0.9419\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1387 - acc: 0.9418\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1380 - acc: 0.9424\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1376 - acc: 0.9423\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1364 - acc: 0.9429\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1350 - acc: 0.9436\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1349 - acc: 0.9437\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1349 - acc: 0.9436\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1325 - acc: 0.9449\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1323 - acc: 0.9449\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1323 - acc: 0.9448\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1316 - acc: 0.9448\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1309 - acc: 0.9455\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1304 - acc: 0.9458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.72     41343\n",
      "           1       0.71      0.61      0.65     23082\n",
      "           2       0.76      0.77      0.77     36849\n",
      "\n",
      "    accuracy                           0.72    101274\n",
      "   macro avg       0.72      0.71      0.71    101274\n",
      "weighted avg       0.72      0.72      0.72    101274\n",
      "\n",
      "Acur√°cia\n",
      "0.7065367744895507\n",
      "Precisao\n",
      "0.7214094248999888\n",
      "Recall\n",
      "0.7214388688113434\n",
      "F1\n",
      "0.7202868270234749\n",
      "[[30555  4208  6580]\n",
      " [ 6685 14023  2374]\n",
      " [ 6733  1631 28485]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   6    7   14   22   24   28   38   40   42   46   47   55   59   64\n",
      "   76   77   79   83   87   97   98   99  101  106  118  123  130  132\n",
      "  135  136  145  149  154  155  157  161  168  169  171  178  185  192\n",
      "  198  199  200  211  215  217  225  228  233  235  238  241  242  244\n",
      "  255  261  271  278  279  280  282  283  284  294  302  306  309  319\n",
      "  324  330  331  333  351  352  353  354  367  369  384  385  387  390\n",
      "  392  395  398  403  409  412  419  426  435  447  452  457  468  481\n",
      "  484  488  491  492  495  496  506  513  525  527  530  535  542  548\n",
      "  549  553  554  555  563  566  570  580  582  585  589  595  597  600\n",
      "  602  605  608  615  625  626  646  653  667  669  675  683  684  685\n",
      "  692  699  701  702  705  710  715  716  717  718  720  722  725  737\n",
      "  750  753  756  758  768  769  770  776  784  787  794  795  796  799\n",
      "  800  806  808  810  818  828  829  832  836  844  847  852  857  860\n",
      "  864  871  878  880  899  918  920  925  928  938  941  946  947  951\n",
      "  960  964  967  973  974  981  986  989  992 1001 1011 1013 1014 1015\n",
      " 1023 1031 1032 1045 1047 1056 1066 1069 1070 1071 1074 1077 1080 1081\n",
      " 1088 1100 1105 1111 1121 1122 1124 1125 1127 1128 1129 1132 1136 1141\n",
      " 1143 1146 1147 1149 1158 1165 1174 1179 1181 1184 1187 1192 1197 1203\n",
      " 1207 1209 1220 1223 1233 1243 1245 1246 1248 1251 1267 1269 1271 1285\n",
      " 1295 1306 1308 1309 1312 1337 1343 1356 1364 1366 1371 1376 1379 1382\n",
      " 1384 1388 1399 1400 1402 1413 1423 1427 1432 1436 1438 1451 1457 1464\n",
      " 1469 1474 1483 1485 1488 1489 1492 1494 1498 1500 1502 1504 1509 1512\n",
      " 1513 1516 1517 1518 1526 1528 1535 1536 1546 1550 1555 1560 1562 1577\n",
      " 1588 1590 1591 1596 1598 1612 1616 1617 1622 1623 1626 1629 1631 1632\n",
      " 1635 1636 1637 1638 1645 1648 1651 1675 1676 1690 1691 1699 1717 1718\n",
      " 1732 1737 1739 1741 1742 1747 1749 1750 1751 1758 1760 1764 1765 1770\n",
      " 1776 1781 1791 1795 1800 1803 1806 1810 1811 1812 1824 1827 1829 1838\n",
      " 1845 1848 1858 1863 1869 1877 1878 1886 1889 1910 1913 1920 1930 1932\n",
      " 1941 1952 1956 1958 1960 1964 1966 1984]\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.3454 - acc: 0.7165\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3151 - acc: 0.8567\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3076 - acc: 0.8608\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.3041 - acc: 0.8626\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3054 - acc: 0.8616\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3021 - acc: 0.8632\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2987 - acc: 0.8646\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2976 - acc: 0.8656\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2953 - acc: 0.8670\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2926 - acc: 0.8679\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2896 - acc: 0.8694\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2875 - acc: 0.8710\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2857 - acc: 0.8716\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2847 - acc: 0.8722\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2821 - acc: 0.8729\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2804 - acc: 0.8740\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2760 - acc: 0.8761\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2746 - acc: 0.8767\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2719 - acc: 0.8778\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2674 - acc: 0.8808\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2655 - acc: 0.8824\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2579 - acc: 0.8862\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2511 - acc: 0.8891\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2490 - acc: 0.8903\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2450 - acc: 0.8929\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2407 - acc: 0.8948\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2405 - acc: 0.8949\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2361 - acc: 0.8974\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2319 - acc: 0.8995\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2296 - acc: 0.9002\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2269 - acc: 0.9014\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2254 - acc: 0.9028\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2229 - acc: 0.9033\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2186 - acc: 0.9058\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2163 - acc: 0.9070\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2135 - acc: 0.9082\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2131 - acc: 0.9083\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2098 - acc: 0.9100\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2058 - acc: 0.9117\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2032 - acc: 0.9133\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2028 - acc: 0.9133\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1998 - acc: 0.9148\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1971 - acc: 0.9160\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1956 - acc: 0.9166\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1935 - acc: 0.9176\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1900 - acc: 0.9193\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1902 - acc: 0.9192\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1870 - acc: 0.9207\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1854 - acc: 0.9214\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1829 - acc: 0.9222\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1818 - acc: 0.9227\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1804 - acc: 0.9234\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1790 - acc: 0.9241\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1770 - acc: 0.9251\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1752 - acc: 0.9257\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1742 - acc: 0.9264\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1731 - acc: 0.9266\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1703 - acc: 0.9279\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1693 - acc: 0.9283\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1678 - acc: 0.9291\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1676 - acc: 0.9294\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1655 - acc: 0.9302\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1635 - acc: 0.9311\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1626 - acc: 0.9315\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1622 - acc: 0.9317\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1601 - acc: 0.9327\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1595 - acc: 0.9329\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1590 - acc: 0.9328\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1577 - acc: 0.9337\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1564 - acc: 0.9341\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1554 - acc: 0.9347\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1539 - acc: 0.9354\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1528 - acc: 0.9359\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1531 - acc: 0.9355\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1517 - acc: 0.9363\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1500 - acc: 0.9369\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1490 - acc: 0.9375\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1477 - acc: 0.9379\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1468 - acc: 0.9385\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1468 - acc: 0.9385\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1449 - acc: 0.9394\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1449 - acc: 0.9391\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1445 - acc: 0.9397\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1427 - acc: 0.9402\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1427 - acc: 0.9406\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1424 - acc: 0.9405\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1411 - acc: 0.9412\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1406 - acc: 0.9413\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1395 - acc: 0.9418\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1390 - acc: 0.9420\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1377 - acc: 0.9426\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1373 - acc: 0.9427\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1369 - acc: 0.9429\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1357 - acc: 0.9436\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1354 - acc: 0.9436\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1344 - acc: 0.9440\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1341 - acc: 0.9442\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1330 - acc: 0.9446\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1327 - acc: 0.9451\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1319 - acc: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.72     42797\n",
      "           1       0.69      0.65      0.67     22382\n",
      "           2       0.78      0.79      0.78     39242\n",
      "\n",
      "    accuracy                           0.73    104421\n",
      "   macro avg       0.73      0.72      0.73    104421\n",
      "weighted avg       0.73      0.73      0.73    104421\n",
      "\n",
      "Acur√°cia\n",
      "0.7225104591806891\n",
      "Precisao\n",
      "0.734076700332434\n",
      "Recall\n",
      "0.7349287978471764\n",
      "F1\n",
      "0.7342889240056468\n",
      "[[31159  4910  6728]\n",
      " [ 5612 14476  2294]\n",
      " [ 6602  1533 31107]]\n",
      "TRAIN: [   0    1    2 ... 1996 1998 1999] TEST: [  19   27   29   31   34   49   54   57   72   74   84   88  110  112\n",
      "  114  116  119  120  126  128  131  137  150  151  160  164  172  177\n",
      "  180  181  187  188  189  191  202  203  212  213  214  218  227  229\n",
      "  231  232  240  252  275  277  286  289  308  315  317  332  357  358\n",
      "  362  364  365  370  371  374  376  378  379  386  393  396  400  405\n",
      "  406  410  411  414  423  424  427  429  431  432  436  442  444  451\n",
      "  453  455  456  458  463  464  465  472  486  489  490  493  499  501\n",
      "  507  509  511  521  524  533  543  546  551  552  574  578  590  591\n",
      "  604  610  617  624  627  635  643  647  649  650  658  659  664  673\n",
      "  681  688  690  703  704  707  711  713  719  723  726  733  736  742\n",
      "  743  746  748  751  757  760  765  771  772  779  785  791  797  798\n",
      "  812  821  822  823  824  835  842  843  849  863  870  875  882  883\n",
      "  884  885  886  891  892  894  896  901  919  921  926  930  932  942\n",
      "  952  954  958  961  963  965  975  976  983  990  996  999 1003 1005\n",
      " 1007 1008 1012 1024 1034 1042 1044 1048 1053 1059 1067 1079 1093 1097\n",
      " 1099 1103 1108 1116 1119 1120 1133 1154 1156 1160 1163 1164 1168 1169\n",
      " 1170 1171 1173 1178 1185 1196 1213 1217 1230 1240 1249 1250 1275 1279\n",
      " 1281 1282 1283 1290 1292 1294 1297 1303 1311 1316 1319 1320 1324 1329\n",
      " 1330 1336 1338 1340 1353 1355 1358 1360 1361 1362 1368 1369 1378 1383\n",
      " 1407 1408 1409 1411 1412 1420 1426 1428 1430 1434 1435 1440 1445 1446\n",
      " 1447 1449 1452 1459 1465 1470 1495 1507 1508 1511 1520 1522 1533 1534\n",
      " 1537 1541 1543 1549 1557 1558 1561 1569 1579 1584 1592 1597 1599 1603\n",
      " 1611 1614 1621 1640 1642 1646 1652 1655 1658 1663 1671 1673 1682 1684\n",
      " 1686 1688 1694 1698 1702 1711 1712 1713 1714 1715 1719 1723 1724 1728\n",
      " 1734 1738 1740 1745 1748 1752 1762 1766 1768 1773 1774 1778 1793 1805\n",
      " 1807 1808 1809 1817 1818 1823 1832 1833 1836 1837 1839 1847 1854 1857\n",
      " 1865 1868 1874 1876 1880 1892 1893 1895 1897 1898 1900 1901 1902 1907\n",
      " 1909 1912 1915 1916 1924 1925 1946 1947 1949 1957 1967 1970 1974 1979\n",
      " 1980 1983 1985 1986 1988 1992 1994 1997]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.3424 - acc: 0.7965\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3116 - acc: 0.8590\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3056 - acc: 0.8627\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3023 - acc: 0.8638\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.3012 - acc: 0.8648\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2986 - acc: 0.8659\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2972 - acc: 0.8664\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2964 - acc: 0.8664\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2922 - acc: 0.8683\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2936 - acc: 0.8684\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2916 - acc: 0.8692\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2870 - acc: 0.8705\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2851 - acc: 0.8716\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2839 - acc: 0.8726\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2794 - acc: 0.8748\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2844 - acc: 0.8725\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2795 - acc: 0.8752\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2763 - acc: 0.8770\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2704 - acc: 0.8799\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2644 - acc: 0.8831\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2586 - acc: 0.8869\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2583 - acc: 0.8876\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2500 - acc: 0.8914\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2487 - acc: 0.8919\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2446 - acc: 0.8938\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2390 - acc: 0.8967\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2363 - acc: 0.8978\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2323 - acc: 0.8994\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2296 - acc: 0.9010\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2287 - acc: 0.9014\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2240 - acc: 0.9036\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2206 - acc: 0.9054\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2190 - acc: 0.9060\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2170 - acc: 0.9072\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.2126 - acc: 0.9090\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2109 - acc: 0.9097\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2064 - acc: 0.9115\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2048 - acc: 0.9123\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.2026 - acc: 0.9134\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1987 - acc: 0.9151\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1971 - acc: 0.9160\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1968 - acc: 0.9160\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1933 - acc: 0.9179\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1910 - acc: 0.9186\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1873 - acc: 0.9203\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1895 - acc: 0.9195\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1844 - acc: 0.9216\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1814 - acc: 0.9230\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1803 - acc: 0.9237\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1776 - acc: 0.9247\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1759 - acc: 0.9257\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1745 - acc: 0.9258\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1728 - acc: 0.9269\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1719 - acc: 0.9274\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1695 - acc: 0.9281\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1674 - acc: 0.9295\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1672 - acc: 0.9291\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1650 - acc: 0.9303\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1636 - acc: 0.9309\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1628 - acc: 0.9312\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1615 - acc: 0.9319\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1590 - acc: 0.9328\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1590 - acc: 0.9330\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1590 - acc: 0.9330\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1555 - acc: 0.9344\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1536 - acc: 0.9356\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1532 - acc: 0.9357\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1519 - acc: 0.9360\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1509 - acc: 0.9367\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1505 - acc: 0.9369\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1484 - acc: 0.9375\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1480 - acc: 0.9378\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1475 - acc: 0.9380\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1463 - acc: 0.9385\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1453 - acc: 0.9391\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1440 - acc: 0.9394\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1439 - acc: 0.9395\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1434 - acc: 0.9396\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1413 - acc: 0.9409\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1407 - acc: 0.9410\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1399 - acc: 0.9413\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1380 - acc: 0.9421\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1381 - acc: 0.9423\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1372 - acc: 0.9425\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1358 - acc: 0.9431\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1353 - acc: 0.9436\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1345 - acc: 0.9436\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1361 - acc: 0.9430\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1341 - acc: 0.9442\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1321 - acc: 0.9447\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1330 - acc: 0.9446\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1316 - acc: 0.9451\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1307 - acc: 0.9454\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1301 - acc: 0.9455\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1287 - acc: 0.9463\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1288 - acc: 0.9462\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1277 - acc: 0.9465\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1275 - acc: 0.9468\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.1278 - acc: 0.9465\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.1265 - acc: 0.9472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72     43385\n",
      "           1       0.67      0.64      0.65     23377\n",
      "           2       0.77      0.77      0.77     39114\n",
      "\n",
      "    accuracy                           0.72    105876\n",
      "   macro avg       0.71      0.71      0.71    105876\n",
      "weighted avg       0.72      0.72      0.72    105876\n",
      "\n",
      "Acur√°cia\n",
      "0.7119485490017929\n",
      "Precisao\n",
      "0.7219305509606644\n",
      "Recall\n",
      "0.7224016774339793\n",
      "F1\n",
      "0.722111738661636\n",
      "[[31208  5408  6769]\n",
      " [ 5956 15046  2375]\n",
      " [ 6735  2148 30231]]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_72 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_73 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_74 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_75 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_76 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_77 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_78 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_79 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 700, 3)            603       \n",
      "=================================================================\n",
      "Total params: 1,342,203\n",
      "Trainable params: 1,342,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acur√°cias total\n",
      "[0.7131677352497455, 0.7180042941421422, 0.7065367744895507, 0.7225104591806891, 0.7119485490017929]\n",
      "0.7144335624127841\n",
      "Precision total\n",
      "[0.7232358096259303, 0.7298791785330961, 0.7214094248999888, 0.734076700332434, 0.7219305509606644]\n",
      "0.7261063328704227\n",
      "Recalls total\n",
      "[0.7242884959581457, 0.7301147721621437, 0.7214388688113434, 0.7349287978471764, 0.7224016774339793]\n",
      "0.7266345224425577\n",
      "F1 total\n",
      "[0.7234506602439073, 0.729248217183579, 0.7202868270234749, 0.7342889240056468, 0.722111738661636]\n",
      "0.7258772734236489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(8)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ8[train_index],\n",
    "                           previsores[test_index], classesQ8[test_index], 8)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(3)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ3[train_index],\n",
    "                           previsores[test_index], classesQ3[test_index], 3)\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
