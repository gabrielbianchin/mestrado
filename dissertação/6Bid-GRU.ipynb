{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n",
      "(2000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classesQ8 = base.iloc[:1400000, 20:28].values\n",
    "classesQ8 = np.reshape(classesQ8, (2000, 700, 8))\n",
    "print(classesQ8.shape)\n",
    "\n",
    "classesQ3 = base.iloc[:1400000, 28:31].values\n",
    "classesQ3 = np.reshape(classesQ3, (2000, 700, 3))\n",
    "print(classesQ3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNGRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede(saida):\n",
    "    model = Sequential()\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(saida, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test, saida):\n",
    "    model.fit(x_train, y_train, epochs = 100, verbose = 1)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], saida))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], saida))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "    \n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acurácia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0822 16:50:10.034723  2648 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0822 16:50:10.043672  2648 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0822 16:50:10.045668  2648 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0822 16:50:10.046665  2648 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   1    3    4 ... 1996 1997 1999] TEST: [   0    2    9   16   18   22   23   28   31   34   35   47   49   51\n",
      "   54   64   66   73   75   77   78   82   84   86   87   90   92   93\n",
      "   96  101  106  109  113  118  124  125  126  129  140  144  146  147\n",
      "  161  163  164  176  177  178  181  184  187  189  201  202  208  218\n",
      "  219  221  238  261  263  287  290  291  292  294  299  301  306  313\n",
      "  314  325  329  337  365  366  374  385  388  389  390  391  398  399\n",
      "  411  412  418  422  423  427  432  436  440  450  451  468  479  480\n",
      "  485  487  493  494  498  507  511  515  516  518  523  526  534  535\n",
      "  545  549  550  551  556  561  562  565  567  568  575  580  584  587\n",
      "  592  597  602  603  610  619  628  633  637  639  647  649  661  665\n",
      "  672  675  681  682  690  702  706  719  730  732  735  742  748  761\n",
      "  768  778  780  786  787  792  795  798  804  817  826  827  831  833\n",
      "  841  847  862  863  874  877  905  909  912  913  914  916  925  927\n",
      "  934  947  950  952  956  958  961  968  970  972  974  983  984  986\n",
      "  987  992 1001 1015 1017 1024 1028 1035 1057 1068 1073 1075 1077 1078\n",
      " 1092 1097 1098 1102 1111 1112 1117 1122 1129 1136 1141 1149 1151 1154\n",
      " 1158 1161 1162 1170 1178 1179 1180 1185 1190 1192 1202 1207 1211 1212\n",
      " 1216 1219 1221 1224 1226 1228 1232 1242 1244 1251 1256 1257 1260 1266\n",
      " 1272 1273 1282 1288 1295 1298 1299 1300 1303 1304 1314 1315 1335 1337\n",
      " 1350 1356 1358 1363 1377 1383 1385 1399 1406 1412 1414 1423 1424 1427\n",
      " 1429 1433 1434 1435 1441 1442 1445 1446 1453 1459 1472 1474 1475 1476\n",
      " 1480 1485 1488 1489 1495 1499 1507 1508 1511 1522 1536 1543 1546 1558\n",
      " 1562 1571 1577 1605 1612 1614 1619 1625 1641 1643 1647 1649 1656 1668\n",
      " 1672 1675 1676 1681 1682 1694 1701 1702 1705 1708 1710 1716 1731 1739\n",
      " 1741 1751 1752 1758 1763 1765 1773 1775 1783 1786 1787 1788 1789 1790\n",
      " 1792 1801 1803 1809 1810 1812 1815 1816 1822 1824 1827 1837 1842 1843\n",
      " 1847 1849 1858 1859 1865 1871 1874 1876 1880 1882 1883 1886 1888 1912\n",
      " 1913 1916 1918 1921 1925 1928 1932 1933 1936 1945 1948 1958 1959 1966\n",
      " 1968 1972 1975 1976 1978 1980 1991 1998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 16:50:11.548677  2648 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.5804 - acc: 0.1602\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5286 - acc: 0.1723\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5192 - acc: 0.1767\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5132 - acc: 0.1791\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5084 - acc: 0.1815\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.5064 - acc: 0.1822\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5028 - acc: 0.1841\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4976 - acc: 0.1861\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4938 - acc: 0.1880\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4894 - acc: 0.1898\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4865 - acc: 0.1909\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4842 - acc: 0.1919\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4809 - acc: 0.1932\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4761 - acc: 0.1957\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4731 - acc: 0.1965\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4699 - acc: 0.1978\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4693 - acc: 0.1978\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4564 - acc: 0.2034\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4501 - acc: 0.2055\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4439 - acc: 0.2076\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4405 - acc: 0.2088\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4374 - acc: 0.2100\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4331 - acc: 0.2114\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4279 - acc: 0.2134\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4254 - acc: 0.2141\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4205 - acc: 0.2161\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4170 - acc: 0.2170\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4141 - acc: 0.2181\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4091 - acc: 0.2198\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4065 - acc: 0.2208\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4026 - acc: 0.2221\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3977 - acc: 0.2236\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3961 - acc: 0.2242\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3917 - acc: 0.2260\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3892 - acc: 0.2264\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3852 - acc: 0.2280\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3823 - acc: 0.2291\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3792 - acc: 0.2296\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3754 - acc: 0.2308\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3734 - acc: 0.2317\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3704 - acc: 0.2329\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3690 - acc: 0.2334\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3665 - acc: 0.2339\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3631 - acc: 0.2351\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3588 - acc: 0.2367\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3577 - acc: 0.2368\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3551 - acc: 0.2374\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3526 - acc: 0.2384\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3483 - acc: 0.2397\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3481 - acc: 0.2396\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3454 - acc: 0.2405\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3438 - acc: 0.2413\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3424 - acc: 0.2415\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3391 - acc: 0.2426\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3369 - acc: 0.2436\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3367 - acc: 0.2436\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3331 - acc: 0.2447\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3313 - acc: 0.2453\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3291 - acc: 0.2460\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3288 - acc: 0.2460\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3257 - acc: 0.2471\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3247 - acc: 0.2474\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3221 - acc: 0.2483\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3209 - acc: 0.2485\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3211 - acc: 0.2484\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3183 - acc: 0.2496\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3165 - acc: 0.2502\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3151 - acc: 0.2504\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3143 - acc: 0.2509\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3131 - acc: 0.2515\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3107 - acc: 0.2523\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3109 - acc: 0.2520\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3080 - acc: 0.2528\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3068 - acc: 0.2532\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3059 - acc: 0.2536\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3044 - acc: 0.2539\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3034 - acc: 0.2546\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3021 - acc: 0.2548\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3022 - acc: 0.2549\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3002 - acc: 0.2553\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2988 - acc: 0.2559\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2992 - acc: 0.2556\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2971 - acc: 0.2565\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2956 - acc: 0.2571\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2943 - acc: 0.2576\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2932 - acc: 0.2580\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2923 - acc: 0.2582\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2916 - acc: 0.2587\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2907 - acc: 0.2586\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2913 - acc: 0.2585\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2894 - acc: 0.2589\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2880 - acc: 0.2598\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2884 - acc: 0.2596\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2862 - acc: 0.2601\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2853 - acc: 0.2604\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2835 - acc: 0.2610\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2839 - acc: 0.2613\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2824 - acc: 0.2617\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2805 - acc: 0.2620\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2800 - acc: 0.2624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.01      0.02      1288\n",
      "           1       0.67      0.70      0.68     21621\n",
      "           2       0.43      0.28      0.34      4006\n",
      "           3       0.76      0.83      0.79     34740\n",
      "           4       0.56      0.27      0.36       749\n",
      "           5       0.48      0.58      0.53     20959\n",
      "           6       0.39      0.14      0.21      9235\n",
      "           7       0.43      0.44      0.44     11920\n",
      "\n",
      "    accuracy                           0.61    104518\n",
      "   macro avg       0.57      0.41      0.42    104518\n",
      "weighted avg       0.60      0.61      0.59    104518\n",
      "\n",
      "Acurácia\n",
      "0.4055533959906649\n",
      "Precisao\n",
      "0.6006078964084597\n",
      "Recall\n",
      "0.6122868788151323\n",
      "F1\n",
      "0.593589997590732\n",
      "[[   10   259    32   161     1   654    57   114]\n",
      " [    2 15177   182  1833    12  3313   267   835]\n",
      " [    0   393  1115   886    11   804   120   677]\n",
      " [    0  1756   291 28734   114  2055   230  1560]\n",
      " [    0    42     7   356   200    72     6    66]\n",
      " [    0  3106   374  2375     4 12240   823  2037]\n",
      " [    0  1126   202  1173    10  3862  1285  1577]\n",
      " [    0   927   413  2415     7  2430   494  5234]]\n",
      "TRAIN: [   0    1    2 ... 1996 1998 1999] TEST: [  12   13   14   25   26   27   29   30   37   39   41   44   45   56\n",
      "   59   61   70   81   83   85   89   94  103  107  112  115  120  122\n",
      "  130  142  145  152  157  158  170  171  173  180  192  193  207  212\n",
      "  231  249  251  256  264  274  279  281  285  296  302  303  305  307\n",
      "  322  332  334  340  343  349  351  352  353  357  358  360  361  362\n",
      "  367  372  378  379  383  384  394  396  400  408  424  430  431  438\n",
      "  448  453  455  458  459  483  489  491  500  502  510  513  514  527\n",
      "  536  542  552  553  557  560  570  579  581  585  594  595  596  604\n",
      "  609  615  620  621  623  641  644  651  658  660  664  668  676  677\n",
      "  687  688  692  698  699  704  708  709  714  716  721  727  731  734\n",
      "  736  739  740  741  745  749  751  752  754  755  767  774  777  779\n",
      "  781  784  790  791  799  803  807  812  814  819  824  825  832  840\n",
      "  844  845  850  851  853  855  856  858  859  861  865  871  872  875\n",
      "  878  891  892  896  898  900  907  908  920  921  924  937  954  959\n",
      "  962  964  967  971  973  981 1000 1004 1005 1012 1013 1019 1021 1026\n",
      " 1031 1040 1043 1045 1049 1056 1058 1060 1065 1076 1085 1086 1088 1091\n",
      " 1096 1103 1104 1105 1108 1110 1113 1119 1120 1134 1137 1139 1144 1146\n",
      " 1152 1153 1155 1156 1181 1193 1195 1217 1218 1230 1236 1245 1246 1250\n",
      " 1252 1261 1263 1267 1285 1291 1297 1321 1323 1326 1329 1333 1341 1342\n",
      " 1344 1345 1349 1352 1353 1361 1364 1368 1371 1376 1378 1380 1382 1390\n",
      " 1398 1407 1409 1425 1438 1443 1452 1458 1464 1465 1470 1479 1486 1490\n",
      " 1498 1515 1517 1519 1527 1530 1531 1540 1545 1548 1553 1555 1556 1559\n",
      " 1561 1564 1566 1572 1573 1576 1581 1583 1587 1598 1604 1611 1621 1626\n",
      " 1629 1631 1633 1634 1635 1637 1644 1648 1650 1651 1655 1657 1660 1664\n",
      " 1677 1685 1686 1689 1695 1696 1698 1707 1711 1712 1718 1721 1724 1727\n",
      " 1733 1738 1740 1744 1746 1747 1748 1749 1753 1757 1772 1779 1785 1796\n",
      " 1798 1800 1804 1806 1832 1846 1852 1855 1872 1875 1877 1878 1890 1904\n",
      " 1905 1906 1909 1910 1915 1920 1927 1939 1940 1949 1952 1954 1955 1956\n",
      " 1957 1962 1967 1970 1979 1982 1990 1997]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.5865 - acc: 0.1634\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5337 - acc: 0.1728\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5225 - acc: 0.1780\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5172 - acc: 0.1806\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5117 - acc: 0.1831\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5083 - acc: 0.1845\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5020 - acc: 0.1870\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4977 - acc: 0.1889\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4929 - acc: 0.1910\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4891 - acc: 0.1928\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4904 - acc: 0.1921\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4846 - acc: 0.1946\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4801 - acc: 0.1966\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4802 - acc: 0.1966\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4777 - acc: 0.1979\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4727 - acc: 0.1992\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4665 - acc: 0.2019\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4610 - acc: 0.2042\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4548 - acc: 0.2063\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4471 - acc: 0.2093\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4428 - acc: 0.2111\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4385 - acc: 0.2125\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4337 - acc: 0.2144\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4298 - acc: 0.2154\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4271 - acc: 0.2164\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4225 - acc: 0.2180\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4174 - acc: 0.2199\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4135 - acc: 0.2209\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4107 - acc: 0.2221\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4058 - acc: 0.2237\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4036 - acc: 0.2240\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3969 - acc: 0.2264\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3981 - acc: 0.2259\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3920 - acc: 0.2279\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3900 - acc: 0.2286\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3845 - acc: 0.2304\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3786 - acc: 0.2323\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3778 - acc: 0.2328\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3744 - acc: 0.2337\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3709 - acc: 0.2350\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3672 - acc: 0.2360\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3649 - acc: 0.2366\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3633 - acc: 0.2371\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3597 - acc: 0.2380\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3573 - acc: 0.2391\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3543 - acc: 0.2398\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3523 - acc: 0.2406\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3491 - acc: 0.2417\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3470 - acc: 0.2423\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3437 - acc: 0.2433\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3410 - acc: 0.2442\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3398 - acc: 0.2446\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3380 - acc: 0.2453\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3351 - acc: 0.2464\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3329 - acc: 0.2469\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3312 - acc: 0.2474\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3293 - acc: 0.2482\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3277 - acc: 0.2487\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3256 - acc: 0.2491\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3239 - acc: 0.2498\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3231 - acc: 0.2503\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3211 - acc: 0.2510\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3189 - acc: 0.2514\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3182 - acc: 0.2520\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3187 - acc: 0.2514\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3148 - acc: 0.2530\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3129 - acc: 0.2533\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3111 - acc: 0.2537\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3102 - acc: 0.2543\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3078 - acc: 0.2550\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3076 - acc: 0.2551\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3063 - acc: 0.2556\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3056 - acc: 0.2559\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3042 - acc: 0.2563\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3023 - acc: 0.2570\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3000 - acc: 0.2580\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3000 - acc: 0.2576\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2973 - acc: 0.2583\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2978 - acc: 0.2584\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2960 - acc: 0.2592\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2945 - acc: 0.2596\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2932 - acc: 0.2599\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2936 - acc: 0.2602\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2911 - acc: 0.2606\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2904 - acc: 0.2611\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2908 - acc: 0.2607\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2888 - acc: 0.2613\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2877 - acc: 0.2621\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2871 - acc: 0.2623\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2857 - acc: 0.2624\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2845 - acc: 0.2630\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2834 - acc: 0.2634\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2812 - acc: 0.2643\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2824 - acc: 0.2639\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2800 - acc: 0.2642\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2801 - acc: 0.2644\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2789 - acc: 0.2651\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2779 - acc: 0.2652\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2765 - acc: 0.2656\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2767 - acc: 0.2658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.01      0.01      1235\n",
      "           1       0.63      0.70      0.66     22276\n",
      "           2       0.35      0.31      0.33      3979\n",
      "           3       0.76      0.80      0.78     32199\n",
      "           4       0.44      0.33      0.38       653\n",
      "           5       0.46      0.56      0.50     20974\n",
      "           6       0.35      0.13      0.19      9119\n",
      "           7       0.43      0.39      0.41     11443\n",
      "\n",
      "    accuracy                           0.59    101878\n",
      "   macro avg       0.53      0.40      0.41    101878\n",
      "weighted avg       0.58      0.59      0.57    101878\n",
      "\n",
      "Acurácia\n",
      "0.4026315221595775\n",
      "Precisao\n",
      "0.5776120359799215\n",
      "Recall\n",
      "0.5905102181040067\n",
      "F1\n",
      "0.5730248288316433\n",
      "[[    8   277    37   150     2   593    59   109]\n",
      " [    0 15525   288  1745    18  3569   319   812]\n",
      " [    0   473  1241   809     2   855   107   492]\n",
      " [    0  2094   476 25856   183  2149   220  1221]\n",
      " [    0    57     6   289   214    44    15    28]\n",
      " [    1  3755   579  2211    13 11690   916  1809]\n",
      " [    0  1346   309  1052    14  3879  1168  1351]\n",
      " [    1  1185   593  2058    38  2554   556  4458]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   5    6   10   15   20   40   46   52   55   68   69   76   79   97\n",
      "   98  104  105  111  114  121  123  127  131  132  133  134  137  148\n",
      "  154  155  156  159  168  174  175  182  185  197  200  217  222  223\n",
      "  224  232  241  248  250  253  254  258  262  270  271  272  275  286\n",
      "  300  304  310  311  318  320  323  326  327  328  330  331  338  339\n",
      "  341  346  347  348  363  373  377  386  395  397  405  406  413  414\n",
      "  415  421  425  441  444  445  446  461  466  469  470  471  477  481\n",
      "  482  486  488  490  495  497  505  508  509  520  522  528  530  540\n",
      "  541  543  546  548  558  559  563  569  571  573  577  578  583  591\n",
      "  593  605  616  617  618  626  630  632  640  645  646  648  669  674\n",
      "  679  683  684  686  693  701  703  712  715  738  764  766  773  793\n",
      "  794  797  801  809  813  829  834  836  846  854  870  881  882  883\n",
      "  884  893  895  897  899  902  906  910  911  915  917  933  941  955\n",
      "  960  966  976  988  991  995 1003 1006 1010 1030 1034 1037 1046 1047\n",
      " 1048 1054 1055 1062 1064 1066 1070 1079 1083 1087 1094 1095 1099 1101\n",
      " 1118 1125 1126 1130 1132 1133 1135 1142 1143 1150 1157 1167 1173 1174\n",
      " 1175 1177 1194 1196 1203 1205 1209 1213 1223 1225 1233 1235 1239 1249\n",
      " 1254 1259 1264 1274 1276 1280 1281 1284 1286 1289 1290 1293 1306 1310\n",
      " 1312 1316 1317 1322 1324 1325 1328 1334 1343 1354 1355 1359 1360 1366\n",
      " 1369 1370 1372 1379 1387 1388 1393 1394 1395 1396 1401 1403 1411 1413\n",
      " 1416 1417 1418 1421 1422 1426 1437 1449 1454 1455 1460 1466 1468 1469\n",
      " 1471 1477 1478 1481 1484 1491 1494 1496 1503 1505 1510 1514 1516 1518\n",
      " 1521 1532 1533 1541 1547 1549 1551 1554 1557 1567 1570 1574 1575 1582\n",
      " 1588 1590 1599 1602 1608 1616 1620 1623 1627 1640 1658 1669 1670 1674\n",
      " 1679 1680 1684 1693 1699 1704 1709 1713 1717 1722 1726 1732 1734 1736\n",
      " 1743 1759 1761 1768 1774 1776 1777 1780 1781 1782 1794 1795 1799 1802\n",
      " 1807 1818 1826 1841 1844 1848 1860 1863 1866 1868 1873 1879 1881 1887\n",
      " 1892 1895 1896 1897 1899 1907 1908 1917 1919 1931 1934 1935 1943 1944\n",
      " 1951 1961 1969 1971 1988 1989 1992 1996]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.5839 - acc: 0.1589\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5288 - acc: 0.1706\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5160 - acc: 0.1768\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5112 - acc: 0.1793\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5071 - acc: 0.1806\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5024 - acc: 0.1825\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4982 - acc: 0.1844\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4929 - acc: 0.1868\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4908 - acc: 0.1875\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4866 - acc: 0.1897\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4822 - acc: 0.1915\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4799 - acc: 0.1923\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4750 - acc: 0.1941\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4719 - acc: 0.1955\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4697 - acc: 0.1965\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4706 - acc: 0.1961\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4634 - acc: 0.1988\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4621 - acc: 0.1998\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4526 - acc: 0.2034\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4456 - acc: 0.2059\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4442 - acc: 0.2062\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4347 - acc: 0.2095\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4307 - acc: 0.2114\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4259 - acc: 0.2131\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4231 - acc: 0.2139\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4180 - acc: 0.2153\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4158 - acc: 0.2161\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4134 - acc: 0.2170\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4081 - acc: 0.2189\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4038 - acc: 0.2203\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4005 - acc: 0.2215\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3969 - acc: 0.2222\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3930 - acc: 0.2237\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3903 - acc: 0.2246\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3876 - acc: 0.2257\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3840 - acc: 0.2270\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3800 - acc: 0.2283\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3760 - acc: 0.2294\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3756 - acc: 0.2300\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3701 - acc: 0.2318\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3676 - acc: 0.2324\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3651 - acc: 0.2330\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3624 - acc: 0.2339\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3623 - acc: 0.2338\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3576 - acc: 0.2353\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3544 - acc: 0.2362\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3525 - acc: 0.2371\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3502 - acc: 0.2380\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3468 - acc: 0.2390\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3454 - acc: 0.2393\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3438 - acc: 0.2400\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3401 - acc: 0.2415\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3388 - acc: 0.2413\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3354 - acc: 0.2427\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3365 - acc: 0.2422\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3327 - acc: 0.2435\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3299 - acc: 0.2441\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3284 - acc: 0.2449\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3259 - acc: 0.2458\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3244 - acc: 0.2464\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3222 - acc: 0.2472\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3215 - acc: 0.2470\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3201 - acc: 0.2480\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3180 - acc: 0.2483\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3167 - acc: 0.2487\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3146 - acc: 0.2498\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3136 - acc: 0.2496\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3121 - acc: 0.2503\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3097 - acc: 0.2509\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3084 - acc: 0.2516\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3074 - acc: 0.2517\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3063 - acc: 0.2524\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3042 - acc: 0.2526\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3031 - acc: 0.2535\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3019 - acc: 0.2536\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3019 - acc: 0.2536\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3002 - acc: 0.2541\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2976 - acc: 0.2551\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2961 - acc: 0.2557\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2966 - acc: 0.2554\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2949 - acc: 0.2560\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2948 - acc: 0.2560\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2925 - acc: 0.2565\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2909 - acc: 0.2576\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2909 - acc: 0.2577\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2892 - acc: 0.2579\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2888 - acc: 0.2581\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2879 - acc: 0.2585\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2872 - acc: 0.2587\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2854 - acc: 0.2591\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2845 - acc: 0.2594\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2843 - acc: 0.2597\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2823 - acc: 0.2604\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2819 - acc: 0.2603\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2808 - acc: 0.2607\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2810 - acc: 0.2608\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2785 - acc: 0.2617\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2781 - acc: 0.2618\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2763 - acc: 0.2624\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2760 - acc: 0.2626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.01      0.02      1267\n",
      "           1       0.66      0.70      0.68     22648\n",
      "           2       0.41      0.31      0.35      4196\n",
      "           3       0.73      0.82      0.77     34280\n",
      "           4       0.40      0.28      0.33       733\n",
      "           5       0.47      0.55      0.50     21424\n",
      "           6       0.38      0.13      0.20      9375\n",
      "           7       0.45      0.40      0.42     12173\n",
      "\n",
      "    accuracy                           0.60    106096\n",
      "   macro avg       0.50      0.40      0.41    106096\n",
      "weighted avg       0.58      0.60      0.58    106096\n",
      "\n",
      "Acurácia\n",
      "0.4007965707637518\n",
      "Precisao\n",
      "0.5793846908875978\n",
      "Recall\n",
      "0.5980150052782386\n",
      "F1\n",
      "0.5782098815189919\n",
      "[[   16   254    43   192     0   595    70    97]\n",
      " [    2 15767   200  2475    23  3245   213   723]\n",
      " [    0   402  1306  1040    11   852   118   467]\n",
      " [    0  1643   388 28220   188  2352   223  1266]\n",
      " [    0    55    10   321   203    83    17    44]\n",
      " [    2  3556   502  2729    34 11784   910  1907]\n",
      " [    2  1230   271  1311    21  3770  1257  1513]\n",
      " [    7  1094   467  2589    27  2575   520  4894]]\n",
      "TRAIN: [   0    2    3 ... 1996 1997 1998] TEST: [   1    8   17   21   32   38   48   50   58   62   63   65   72   74\n",
      "   80   88   95   99  100  108  117  128  135  149  151  160  162  166\n",
      "  169  172  179  183  196  198  199  203  204  205  206  213  214  216\n",
      "  220  225  226  228  229  234  235  240  243  244  247  252  257  259\n",
      "  260  265  268  269  273  276  278  280  293  295  298  312  317  319\n",
      "  335  336  342  345  350  354  356  369  370  371  376  381  382  387\n",
      "  392  393  403  409  410  420  426  434  437  442  449  452  454  457\n",
      "  460  462  464  467  472  473  475  478  484  499  503  506  517  519\n",
      "  524  529  538  539  544  547  554  555  566  572  576  589  590  601\n",
      "  607  608  611  613  622  629  635  643  652  654  655  657  659  666\n",
      "  667  670  671  685  694  695  697  700  705  717  720  722  725  726\n",
      "  729  743  744  747  750  753  757  759  765  769  771  783  788  789\n",
      "  796  806  808  815  816  818  820  823  830  835  843  864  868  869\n",
      "  876  879  885  886  887  889  890  894  904  918  919  922  923  926\n",
      "  930  931  935  936  939  942  944  946  948  951  953  963  977  982\n",
      "  985  989  993  994  997  998  999 1002 1007 1008 1009 1018 1020 1022\n",
      " 1027 1033 1038 1041 1050 1051 1052 1053 1061 1072 1074 1080 1084 1089\n",
      " 1090 1093 1106 1107 1115 1116 1123 1124 1131 1140 1147 1159 1163 1164\n",
      " 1168 1169 1176 1182 1184 1186 1189 1197 1198 1214 1222 1234 1237 1253\n",
      " 1255 1262 1265 1271 1279 1292 1294 1296 1302 1308 1318 1319 1320 1330\n",
      " 1332 1336 1339 1346 1348 1351 1362 1365 1367 1375 1381 1386 1389 1397\n",
      " 1400 1405 1408 1415 1419 1420 1428 1431 1447 1456 1457 1461 1473 1482\n",
      " 1493 1500 1501 1502 1504 1506 1509 1513 1523 1524 1525 1528 1529 1534\n",
      " 1538 1539 1550 1552 1569 1578 1579 1585 1586 1591 1592 1593 1595 1597\n",
      " 1601 1603 1606 1609 1610 1617 1628 1632 1652 1653 1659 1661 1662 1663\n",
      " 1665 1666 1667 1723 1729 1735 1745 1750 1756 1760 1764 1767 1771 1778\n",
      " 1784 1793 1797 1811 1814 1817 1825 1829 1830 1833 1834 1835 1839 1845\n",
      " 1851 1854 1857 1861 1862 1867 1889 1891 1894 1923 1929 1937 1942 1947\n",
      " 1953 1963 1983 1986 1987 1994 1995 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.5876 - acc: 0.1592\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5334 - acc: 0.1716\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5213 - acc: 0.1779\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5156 - acc: 0.1802\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5111 - acc: 0.1820\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5064 - acc: 0.1839\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5040 - acc: 0.1847\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4996 - acc: 0.1873\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4951 - acc: 0.1891\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4918 - acc: 0.1903\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4871 - acc: 0.1926\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4868 - acc: 0.1926\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4818 - acc: 0.1949\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4789 - acc: 0.1962\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4761 - acc: 0.1971\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4727 - acc: 0.1986\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4677 - acc: 0.2007\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4627 - acc: 0.2025\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4588 - acc: 0.2039\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4482 - acc: 0.2080\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4407 - acc: 0.2108\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4364 - acc: 0.2124\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4332 - acc: 0.2133\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4272 - acc: 0.2153\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4241 - acc: 0.2166\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4199 - acc: 0.2179\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4167 - acc: 0.2189\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4132 - acc: 0.2199\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4082 - acc: 0.2218\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4036 - acc: 0.2232\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4009 - acc: 0.2244\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3965 - acc: 0.2256\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3930 - acc: 0.2269\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3904 - acc: 0.2280\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3870 - acc: 0.2290\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3821 - acc: 0.2304\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3795 - acc: 0.2314\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3778 - acc: 0.2317\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3728 - acc: 0.2335\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3689 - acc: 0.2350\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3680 - acc: 0.2350\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3635 - acc: 0.2365\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3606 - acc: 0.2373\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3580 - acc: 0.2383\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3548 - acc: 0.2393\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3541 - acc: 0.2393\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3501 - acc: 0.2407\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3482 - acc: 0.2414\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3465 - acc: 0.2419\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3438 - acc: 0.2429\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3421 - acc: 0.2434\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3400 - acc: 0.2439\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3364 - acc: 0.2453\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3346 - acc: 0.2457\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3340 - acc: 0.2459\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3321 - acc: 0.2466\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3288 - acc: 0.2476\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3265 - acc: 0.2486\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3260 - acc: 0.2487\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3234 - acc: 0.2496\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3239 - acc: 0.2494\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3212 - acc: 0.2504\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3186 - acc: 0.2510\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3169 - acc: 0.2519\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3152 - acc: 0.2522\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3148 - acc: 0.2523\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3134 - acc: 0.2529\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3114 - acc: 0.2534\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3085 - acc: 0.2546\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3079 - acc: 0.2545\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3080 - acc: 0.2543\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3046 - acc: 0.2557\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3038 - acc: 0.2557\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3023 - acc: 0.2566\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3023 - acc: 0.2565\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3006 - acc: 0.2570\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2999 - acc: 0.2576\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2982 - acc: 0.2581\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2970 - acc: 0.2583\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2953 - acc: 0.2589\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2933 - acc: 0.2597\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2922 - acc: 0.2598\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2917 - acc: 0.2601\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2919 - acc: 0.2600\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2910 - acc: 0.2604\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2896 - acc: 0.2607\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2896 - acc: 0.2605\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2873 - acc: 0.2615\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2847 - acc: 0.2623\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2852 - acc: 0.2620\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2836 - acc: 0.2627\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2835 - acc: 0.2630\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2815 - acc: 0.2636\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2818 - acc: 0.2635\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2801 - acc: 0.2642\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2790 - acc: 0.2647\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2783 - acc: 0.2646\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2770 - acc: 0.2653\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2767 - acc: 0.2653\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2761 - acc: 0.2655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.01      0.01      1318\n",
      "           1       0.63      0.70      0.66     21646\n",
      "           2       0.34      0.28      0.31      3796\n",
      "           3       0.73      0.83      0.78     34008\n",
      "           4       0.52      0.27      0.36       699\n",
      "           5       0.47      0.52      0.49     20393\n",
      "           6       0.35      0.12      0.18      9127\n",
      "           7       0.42      0.38      0.40     11656\n",
      "\n",
      "    accuracy                           0.59    102643\n",
      "   macro avg       0.51      0.39      0.40    102643\n",
      "weighted avg       0.57      0.59      0.57    102643\n",
      "\n",
      "Acurácia\n",
      "0.3895932596667569\n",
      "Precisao\n",
      "0.57039111619252\n",
      "Recall\n",
      "0.592558674239841\n",
      "F1\n",
      "0.570923447776828\n",
      "[[    7   304    29   182     1   589    63   143]\n",
      " [    2 15154   247  2077     5  3063   288   810]\n",
      " [    2   426  1073  1000    11   648    91   545]\n",
      " [    0  1897   427 28196   105  1909   180  1294]\n",
      " [    0    70     5   362   191    31     4    36]\n",
      " [    0  3671   519  2724    11 10624   915  1929]\n",
      " [    1  1346   322  1404    12  3480  1132  1430]\n",
      " [    0  1181   532  2705    32  2193   568  4445]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   3    4    7   11   19   24   33   36   42   43   53   57   60   67\n",
      "   71   91  102  110  116  119  136  138  139  141  143  150  153  165\n",
      "  167  186  188  190  191  194  195  209  210  211  215  227  230  233\n",
      "  236  237  239  242  245  246  255  266  267  277  282  283  284  288\n",
      "  289  297  308  309  315  316  321  324  333  344  355  359  364  368\n",
      "  375  380  401  402  404  407  416  417  419  428  429  433  435  439\n",
      "  443  447  456  463  465  474  476  492  496  501  504  512  521  525\n",
      "  531  532  533  537  564  574  582  586  588  598  599  600  606  612\n",
      "  614  624  625  627  631  634  636  638  642  650  653  656  662  663\n",
      "  673  678  680  689  691  696  707  710  711  713  718  723  724  728\n",
      "  733  737  746  756  758  760  762  763  770  772  775  776  782  785\n",
      "  800  802  805  810  811  821  822  828  837  838  839  842  848  849\n",
      "  852  857  860  866  867  873  880  888  901  903  928  929  932  938\n",
      "  940  943  945  949  957  965  969  975  978  979  980  990  996 1011\n",
      " 1014 1016 1023 1025 1029 1032 1036 1039 1042 1044 1059 1063 1067 1069\n",
      " 1071 1081 1082 1100 1109 1114 1121 1127 1128 1138 1145 1148 1160 1165\n",
      " 1166 1171 1172 1183 1187 1188 1191 1199 1200 1201 1204 1206 1208 1210\n",
      " 1215 1220 1227 1229 1231 1238 1240 1241 1243 1247 1248 1258 1268 1269\n",
      " 1270 1275 1277 1278 1283 1287 1301 1305 1307 1309 1311 1313 1327 1331\n",
      " 1338 1340 1347 1357 1373 1374 1384 1391 1392 1402 1404 1410 1430 1432\n",
      " 1436 1439 1440 1444 1448 1450 1451 1462 1463 1467 1483 1487 1492 1497\n",
      " 1512 1520 1526 1535 1537 1542 1544 1560 1563 1565 1568 1580 1584 1589\n",
      " 1594 1596 1600 1607 1613 1615 1618 1622 1624 1630 1636 1638 1639 1642\n",
      " 1645 1646 1654 1671 1673 1678 1683 1687 1688 1690 1691 1692 1697 1700\n",
      " 1703 1706 1714 1715 1719 1720 1725 1728 1730 1737 1742 1754 1755 1762\n",
      " 1766 1769 1770 1791 1805 1808 1813 1819 1820 1821 1823 1828 1831 1836\n",
      " 1838 1840 1850 1853 1856 1864 1869 1870 1884 1885 1893 1898 1900 1901\n",
      " 1902 1903 1911 1914 1922 1924 1926 1930 1938 1941 1946 1950 1960 1964\n",
      " 1965 1973 1974 1977 1981 1984 1985 1993]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.5921 - acc: 0.1582\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5363 - acc: 0.1723\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5249 - acc: 0.1778\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5206 - acc: 0.1798\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5137 - acc: 0.1827\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5117 - acc: 0.1833\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5065 - acc: 0.1859\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.5034 - acc: 0.1872\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4993 - acc: 0.1890\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4958 - acc: 0.1909\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4940 - acc: 0.1914\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4903 - acc: 0.1934\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4864 - acc: 0.1948\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4877 - acc: 0.1944\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4786 - acc: 0.1984\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4759 - acc: 0.1991\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4739 - acc: 0.1999\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4631 - acc: 0.2041\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4555 - acc: 0.2074\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4506 - acc: 0.2089\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4443 - acc: 0.2113\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4428 - acc: 0.2118\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4384 - acc: 0.2136\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4333 - acc: 0.2151\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4298 - acc: 0.2162\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4238 - acc: 0.2185\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4198 - acc: 0.2195\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4170 - acc: 0.2208\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4108 - acc: 0.2226\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4076 - acc: 0.2238\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4047 - acc: 0.2250\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.4002 - acc: 0.2264\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3960 - acc: 0.2274\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3940 - acc: 0.2280\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3897 - acc: 0.2295\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3854 - acc: 0.2310\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3826 - acc: 0.2320\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3783 - acc: 0.2333\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3761 - acc: 0.2341\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3743 - acc: 0.2344\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3690 - acc: 0.2364\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3674 - acc: 0.2372\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3640 - acc: 0.2379\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3618 - acc: 0.2386\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3572 - acc: 0.2405\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3572 - acc: 0.2398\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3542 - acc: 0.2412\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3510 - acc: 0.2424\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3474 - acc: 0.2434\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3457 - acc: 0.2439\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3447 - acc: 0.2445\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3426 - acc: 0.2450\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3398 - acc: 0.2455\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3372 - acc: 0.2468\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3354 - acc: 0.2475\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3326 - acc: 0.2481\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3313 - acc: 0.2488\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3298 - acc: 0.2491\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3281 - acc: 0.2496\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3258 - acc: 0.2507\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3247 - acc: 0.2507\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3238 - acc: 0.2513\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3204 - acc: 0.2521\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3201 - acc: 0.2525\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3176 - acc: 0.2532\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3166 - acc: 0.2534\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3136 - acc: 0.2543\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3126 - acc: 0.2547\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3108 - acc: 0.2554\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3097 - acc: 0.2558\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3100 - acc: 0.2558\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3073 - acc: 0.2564\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3067 - acc: 0.2568\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3055 - acc: 0.2574\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3028 - acc: 0.2579\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3029 - acc: 0.2578\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3010 - acc: 0.2585\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2989 - acc: 0.2594\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2986 - acc: 0.2595\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2982 - acc: 0.2599\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2966 - acc: 0.2600\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2970 - acc: 0.2599\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2940 - acc: 0.2607\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2930 - acc: 0.2610\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2919 - acc: 0.2617\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2917 - acc: 0.2619\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2910 - acc: 0.2620\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2888 - acc: 0.2626\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2880 - acc: 0.2628\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2863 - acc: 0.2636\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2848 - acc: 0.2642\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2858 - acc: 0.2637\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2849 - acc: 0.2642\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2833 - acc: 0.2646\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2820 - acc: 0.2653\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2821 - acc: 0.2652\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2807 - acc: 0.2654\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2820 - acc: 0.2652\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2787 - acc: 0.2663\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2790 - acc: 0.2663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.01      0.02      1156\n",
      "           1       0.63      0.71      0.67     20741\n",
      "           2       0.38      0.28      0.32      3894\n",
      "           3       0.76      0.80      0.78     33916\n",
      "           4       0.50      0.26      0.34       683\n",
      "           5       0.48      0.52      0.50     20335\n",
      "           6       0.33      0.16      0.21      8732\n",
      "           7       0.42      0.43      0.42     11216\n",
      "\n",
      "    accuracy                           0.60    100673\n",
      "   macro avg       0.50      0.40      0.41    100673\n",
      "weighted avg       0.58      0.60      0.58    100673\n",
      "\n",
      "Acurácia\n",
      "0.39635003268332214\n",
      "Precisao\n",
      "0.5805926631839483\n",
      "Recall\n",
      "0.5969525096103225\n",
      "F1\n",
      "0.5817056999958385\n",
      "[[   12   282    31   119     0   513    79   120]\n",
      " [    2 14823   229  1673    14  2809   365   826]\n",
      " [    0   433  1084   841     8   775   152   601]\n",
      " [    0  1999   474 27191   110  2267   271  1604]\n",
      " [    0    57     9   330   176    47    21    43]\n",
      " [    7  3712   404  2335    17 10644  1210  2006]\n",
      " [    0  1262   226  1082     7  3275  1368  1512]\n",
      " [    2  1120   390  2136    23  2058   688  4799]]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_24 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_25 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_26 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_27 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 980,808\n",
      "Trainable params: 980,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acurácias total\n",
      "[0.4055533959906649, 0.4026315221595775, 0.4007965707637518, 0.3895932596667569, 0.39635003268332214]\n",
      "0.3989849562528146\n",
      "Precision total\n",
      "[0.6006078964084597, 0.5776120359799215, 0.5793846908875978, 0.57039111619252, 0.5805926631839483]\n",
      "0.5817176805304894\n",
      "Recalls total\n",
      "[0.6122868788151323, 0.5905102181040067, 0.5980150052782386, 0.592558674239841, 0.5969525096103225]\n",
      "0.5980646572095083\n",
      "F1 total\n",
      "[0.593589997590732, 0.5730248288316433, 0.5782098815189919, 0.570923447776828, 0.5817056999958385]\n",
      "0.5794907711428068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 1996 1997 1998] TEST: [   5    8    9   28   29   32   34   49   50   63   69   72   79   90\n",
      "   96   98  102  104  120  121  123  132  135  148  152  159  160  163\n",
      "  174  175  177  178  185  191  196  207  208  209  213  216  224  228\n",
      "  229  233  236  237  238  239  241  251  253  254  256  259  266  269\n",
      "  274  285  293  297  308  312  322  323  332  347  355  358  367  371\n",
      "  375  381  384  388  393  396  397  399  400  409  418  421  423  427\n",
      "  441  443  445  447  450  451  478  482  492  496  499  502  511  512\n",
      "  514  515  521  522  528  529  536  545  546  552  558  562  568  571\n",
      "  575  577  578  579  580  581  594  600  602  612  613  617  620  630\n",
      "  634  639  643  646  668  671  674  684  686  692  696  706  708  710\n",
      "  714  719  723  724  732  735  748  752  754  757  759  760  768  771\n",
      "  772  781  784  785  786  790  792  801  804  806  811  814  818  823\n",
      "  825  831  835  860  879  881  886  890  892  901  915  920  926  930\n",
      "  934  937  938  941  943  946  953  955  958  959  960  962  965  966\n",
      "  970  972  976  982 1002 1007 1019 1020 1021 1025 1040 1041 1046 1051\n",
      " 1055 1061 1064 1066 1069 1075 1076 1078 1086 1093 1099 1106 1112 1121\n",
      " 1137 1141 1145 1147 1153 1157 1159 1162 1163 1170 1174 1176 1183 1184\n",
      " 1190 1196 1201 1203 1207 1214 1215 1225 1246 1247 1249 1255 1256 1262\n",
      " 1265 1274 1280 1282 1284 1296 1298 1310 1320 1322 1326 1332 1337 1338\n",
      " 1343 1346 1357 1358 1362 1366 1376 1387 1392 1401 1402 1405 1406 1409\n",
      " 1434 1455 1458 1459 1460 1475 1480 1485 1496 1510 1512 1515 1518 1524\n",
      " 1527 1529 1530 1538 1542 1550 1555 1566 1574 1578 1581 1587 1592 1596\n",
      " 1605 1606 1607 1611 1612 1616 1632 1635 1637 1639 1646 1649 1657 1666\n",
      " 1668 1670 1681 1701 1702 1731 1734 1741 1760 1761 1766 1767 1772 1773\n",
      " 1783 1791 1792 1794 1795 1796 1808 1810 1812 1814 1816 1817 1820 1823\n",
      " 1826 1828 1831 1832 1840 1847 1851 1852 1854 1855 1856 1857 1862 1864\n",
      " 1867 1869 1871 1882 1885 1889 1894 1900 1904 1905 1906 1907 1908 1919\n",
      " 1922 1924 1930 1934 1943 1945 1948 1950 1951 1953 1957 1958 1959 1967\n",
      " 1969 1971 1974 1976 1977 1981 1989 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.3353 - acc: 0.8085\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3113 - acc: 0.8590\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3044 - acc: 0.8631\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3014 - acc: 0.8640\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3008 - acc: 0.8641\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3001 - acc: 0.8644\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2956 - acc: 0.8666\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2946 - acc: 0.8675\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2914 - acc: 0.8685\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2896 - acc: 0.8696\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2884 - acc: 0.8707\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2867 - acc: 0.8713\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2823 - acc: 0.8734\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2835 - acc: 0.8731\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2827 - acc: 0.8736\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2813 - acc: 0.8744\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2789 - acc: 0.8762\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2790 - acc: 0.8754\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2749 - acc: 0.8775\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2719 - acc: 0.8793\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2694 - acc: 0.8805\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2666 - acc: 0.8817\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2684 - acc: 0.8805\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2627 - acc: 0.8837\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2585 - acc: 0.8860\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2565 - acc: 0.8873\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2498 - acc: 0.8911\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2472 - acc: 0.8919\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2432 - acc: 0.8939\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2381 - acc: 0.8966\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2368 - acc: 0.8968\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2320 - acc: 0.8994\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2290 - acc: 0.9011\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2271 - acc: 0.9020\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2227 - acc: 0.9037\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2193 - acc: 0.9057\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2163 - acc: 0.9069\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2148 - acc: 0.9076\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2130 - acc: 0.9085\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2072 - acc: 0.9113\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2051 - acc: 0.9120\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2032 - acc: 0.9130\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1999 - acc: 0.9145\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1979 - acc: 0.9156\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1951 - acc: 0.9167\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1931 - acc: 0.9174\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1904 - acc: 0.9191\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1882 - acc: 0.9200\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1870 - acc: 0.9199\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1851 - acc: 0.9209\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1812 - acc: 0.9229\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1800 - acc: 0.9236\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1777 - acc: 0.9245\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1757 - acc: 0.9254\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1746 - acc: 0.9260\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1718 - acc: 0.9274\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1712 - acc: 0.9273\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1690 - acc: 0.9286\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1701 - acc: 0.9278\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1669 - acc: 0.9295\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1651 - acc: 0.9303\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1634 - acc: 0.9311\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1611 - acc: 0.9320\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1608 - acc: 0.9324\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1595 - acc: 0.9327\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1579 - acc: 0.9334\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1568 - acc: 0.9340\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1554 - acc: 0.9345\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1546 - acc: 0.9348\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1530 - acc: 0.9355\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1520 - acc: 0.9359\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1514 - acc: 0.9361\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1504 - acc: 0.9371\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1493 - acc: 0.9371\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1479 - acc: 0.9380\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1464 - acc: 0.9384\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1464 - acc: 0.9387\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1449 - acc: 0.9392\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1432 - acc: 0.9401\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1426 - acc: 0.9403\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1424 - acc: 0.9403\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1419 - acc: 0.9405\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1401 - acc: 0.9413\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1405 - acc: 0.9412\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1398 - acc: 0.9415\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1383 - acc: 0.9423\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1369 - acc: 0.9428\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1356 - acc: 0.9433\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1351 - acc: 0.9433\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1440 - acc: 0.9395\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1358 - acc: 0.9432\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1346 - acc: 0.9437\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1337 - acc: 0.9441\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1318 - acc: 0.9449\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1314 - acc: 0.9451\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1304 - acc: 0.9456\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1301 - acc: 0.9459\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1295 - acc: 0.9459\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1287 - acc: 0.9464\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1287 - acc: 0.9464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71     43580\n",
      "           1       0.69      0.60      0.65     23234\n",
      "           2       0.75      0.77      0.76     39328\n",
      "\n",
      "    accuracy                           0.72    106142\n",
      "   macro avg       0.71      0.70      0.71    106142\n",
      "weighted avg       0.72      0.72      0.71    106142\n",
      "\n",
      "Acurácia\n",
      "0.7001375918883753\n",
      "Precisao\n",
      "0.7150368042364401\n",
      "Recall\n",
      "0.7156827645983682\n",
      "F1\n",
      "0.7145107225706346\n",
      "[[31577  4446  7557]\n",
      " [ 6651 14035  2548]\n",
      " [ 7203  1773 30352]]\n",
      "TRAIN: [   0    1    2 ... 1996 1998 1999] TEST: [   4    7   13   14   17   19   22   30   33   36   42   43   45   46\n",
      "   51   55   56   57   58   61   65   67   76   81   84  114  116  122\n",
      "  137  138  140  141  153  155  168  169  170  171  184  195  198  203\n",
      "  210  211  217  221  225  240  247  249  252  257  258  262  263  278\n",
      "  288  292  299  302  306  309  310  317  319  320  324  326  327  350\n",
      "  361  373  376  378  387  392  398  406  414  417  424  433  434  435\n",
      "  436  440  444  448  452  454  460  464  469  470  472  476  480  484\n",
      "  489  490  500  506  507  513  516  517  518  531  541  543  548  554\n",
      "  556  557  563  573  584  585  587  588  595  598  599  603  607  611\n",
      "  623  627  628  631  635  641  652  653  655  660  662  672  675  678\n",
      "  680  685  687  693  694  699  713  715  730  733  740  755  758  762\n",
      "  765  766  775  776  789  791  794  799  812  813  815  821  827  829\n",
      "  838  840  848  849  851  854  855  859  862  864  874  888  895  898\n",
      "  899  902  907  908  909  910  914  925  935  936  942  981  986  990\n",
      " 1006 1011 1014 1017 1026 1028 1032 1039 1049 1052 1057 1059 1063 1071\n",
      " 1072 1079 1091 1100 1105 1114 1119 1122 1124 1134 1135 1138 1143 1149\n",
      " 1160 1166 1182 1194 1200 1205 1208 1209 1211 1217 1219 1220 1233 1234\n",
      " 1236 1250 1269 1275 1278 1285 1287 1292 1295 1301 1309 1311 1313 1318\n",
      " 1329 1331 1339 1340 1351 1354 1356 1365 1368 1374 1378 1382 1391 1399\n",
      " 1410 1412 1413 1414 1416 1418 1420 1423 1424 1428 1431 1435 1438 1441\n",
      " 1449 1450 1451 1452 1454 1463 1464 1465 1468 1469 1472 1476 1482 1497\n",
      " 1499 1500 1501 1507 1517 1520 1526 1528 1546 1548 1549 1551 1552 1556\n",
      " 1561 1569 1575 1577 1579 1586 1593 1594 1595 1601 1603 1609 1617 1618\n",
      " 1619 1620 1631 1634 1638 1643 1648 1650 1658 1671 1672 1673 1677 1679\n",
      " 1680 1684 1690 1691 1696 1698 1710 1718 1725 1729 1732 1736 1738 1747\n",
      " 1751 1754 1757 1758 1762 1763 1769 1771 1775 1776 1780 1785 1786 1788\n",
      " 1806 1811 1822 1827 1829 1838 1841 1843 1846 1848 1863 1874 1888 1891\n",
      " 1897 1898 1910 1915 1920 1925 1927 1932 1938 1940 1956 1960 1961 1968\n",
      " 1970 1973 1978 1986 1987 1993 1994 1997]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.3350 - acc: 0.8213\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3115 - acc: 0.8595\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3048 - acc: 0.8629\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3028 - acc: 0.8630\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3002 - acc: 0.8642\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2967 - acc: 0.8663\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2946 - acc: 0.8672\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2911 - acc: 0.8693\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2929 - acc: 0.8685\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2907 - acc: 0.8698\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2863 - acc: 0.8720\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2869 - acc: 0.8716\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2841 - acc: 0.8732\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2815 - acc: 0.8746\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2793 - acc: 0.8756\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2798 - acc: 0.8756\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2812 - acc: 0.8750\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2755 - acc: 0.8780\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2722 - acc: 0.8795\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2683 - acc: 0.8816\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2602 - acc: 0.8862\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2563 - acc: 0.8883\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2531 - acc: 0.8896\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2480 - acc: 0.8920\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2452 - acc: 0.8935\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2436 - acc: 0.8944\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2402 - acc: 0.8961\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2369 - acc: 0.8978\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2344 - acc: 0.8989\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2304 - acc: 0.9007\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2302 - acc: 0.9008\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2264 - acc: 0.9023\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2237 - acc: 0.9041\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2210 - acc: 0.9049\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2171 - acc: 0.9068\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2144 - acc: 0.9080\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2117 - acc: 0.9095\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2089 - acc: 0.9108\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2062 - acc: 0.9122\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2037 - acc: 0.9132\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2008 - acc: 0.9144\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1982 - acc: 0.9155\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1963 - acc: 0.9163\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1942 - acc: 0.9175\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1921 - acc: 0.9183\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1896 - acc: 0.9190\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1871 - acc: 0.9204\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1861 - acc: 0.9208\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1829 - acc: 0.9222\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1804 - acc: 0.9234\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1792 - acc: 0.9242\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1785 - acc: 0.9240\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1765 - acc: 0.9251\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1735 - acc: 0.9265\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1719 - acc: 0.9273\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1704 - acc: 0.9278\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1691 - acc: 0.9283\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1679 - acc: 0.9286\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1658 - acc: 0.9294\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1647 - acc: 0.9304\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1633 - acc: 0.9306\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1615 - acc: 0.9319\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1597 - acc: 0.9323\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1589 - acc: 0.9332\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1573 - acc: 0.9336\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1560 - acc: 0.9343\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1548 - acc: 0.9349\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1545 - acc: 0.9348\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1538 - acc: 0.9351\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1519 - acc: 0.9362\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1508 - acc: 0.9365\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1494 - acc: 0.9372\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1499 - acc: 0.9368\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1476 - acc: 0.9378\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1462 - acc: 0.9386\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1447 - acc: 0.9390\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1452 - acc: 0.9389\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1439 - acc: 0.9396\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1428 - acc: 0.9401\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1431 - acc: 0.9400\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1420 - acc: 0.9405\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1402 - acc: 0.9411\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1391 - acc: 0.9420\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1389 - acc: 0.9417\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1381 - acc: 0.9423\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1359 - acc: 0.9431\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1357 - acc: 0.9432\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1359 - acc: 0.9434\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1350 - acc: 0.9436\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1336 - acc: 0.9441\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1327 - acc: 0.9445\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1333 - acc: 0.9444\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1318 - acc: 0.9448\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1312 - acc: 0.9452\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1304 - acc: 0.9455\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1300 - acc: 0.9460\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1299 - acc: 0.9458\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1285 - acc: 0.9464\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1276 - acc: 0.9470\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1283 - acc: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72     43617\n",
      "           1       0.70      0.63      0.66     23976\n",
      "           2       0.77      0.78      0.77     39623\n",
      "\n",
      "    accuracy                           0.73    107216\n",
      "   macro avg       0.72      0.72      0.72    107216\n",
      "weighted avg       0.73      0.73      0.73    107216\n",
      "\n",
      "Acurácia\n",
      "0.7150102386321254\n",
      "Precisao\n",
      "0.7278655539482968\n",
      "Recall\n",
      "0.7282495149977616\n",
      "F1\n",
      "0.7275190705944977\n",
      "[[32177  4818  6622]\n",
      " [ 6305 15107  2564]\n",
      " [ 7110  1717 30796]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   6   10   11   12   23   31   37   38   40   44   52   53   54   60\n",
      "   62   64   74   75   78   99  106  107  111  112  134  136  139  145\n",
      "  162  164  172  176  179  180  182  188  190  193  197  200  202  205\n",
      "  206  226  227  230  232  234  243  248  268  275  282  284  286  289\n",
      "  291  294  296  311  314  331  338  348  351  353  362  366  372  374\n",
      "  383  385  389  391  401  403  405  407  415  425  426  428  430  431\n",
      "  439  442  455  468  474  477  481  491  493  494  497  503  508  519\n",
      "  523  526  532  542  550  551  559  560  561  566  567  569  582  614\n",
      "  616  618  626  629  648  657  658  663  665  666  669  670  676  677\n",
      "  679  701  704  718  720  722  726  727  728  734  737  747  751  753\n",
      "  761  763  767  769  770  778  779  796  798  800  810  816  826  830\n",
      "  832  833  836  846  847  850  863  872  875  876  878  880  882  883\n",
      "  884  885  891  894  896  906  911  954  968  969  975  977  979  983\n",
      "  988  989  991  997 1005 1013 1015 1024 1027 1029 1031 1033 1037 1038\n",
      " 1042 1047 1048 1053 1060 1068 1073 1081 1082 1083 1085 1101 1102 1103\n",
      " 1110 1113 1117 1118 1120 1123 1130 1131 1136 1148 1152 1169 1172 1180\n",
      " 1185 1188 1193 1197 1198 1199 1204 1210 1221 1222 1224 1227 1237 1239\n",
      " 1241 1245 1252 1253 1261 1264 1268 1271 1272 1273 1276 1277 1288 1289\n",
      " 1291 1293 1297 1300 1303 1305 1306 1315 1317 1324 1327 1341 1344 1345\n",
      " 1348 1349 1353 1372 1373 1379 1384 1385 1394 1395 1398 1404 1415 1417\n",
      " 1419 1425 1427 1430 1432 1433 1437 1439 1440 1445 1446 1462 1473 1477\n",
      " 1478 1479 1481 1483 1486 1487 1490 1492 1493 1508 1511 1514 1516 1522\n",
      " 1532 1543 1547 1554 1557 1558 1559 1560 1563 1564 1571 1580 1588 1589\n",
      " 1590 1598 1613 1615 1625 1626 1627 1629 1647 1653 1655 1659 1661 1662\n",
      " 1665 1683 1687 1689 1697 1699 1703 1717 1719 1722 1728 1733 1735 1737\n",
      " 1742 1745 1746 1748 1759 1774 1777 1779 1781 1787 1793 1801 1804 1807\n",
      " 1813 1815 1819 1821 1833 1849 1859 1866 1868 1877 1880 1881 1883 1884\n",
      " 1895 1913 1916 1929 1931 1935 1937 1941 1944 1946 1949 1954 1962 1963\n",
      " 1965 1966 1979 1982 1988 1990 1992 1995]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.3363 - acc: 0.7978\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3133 - acc: 0.8581\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3060 - acc: 0.8624\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3029 - acc: 0.8642\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3005 - acc: 0.8656\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2983 - acc: 0.8663\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2957 - acc: 0.8677\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2953 - acc: 0.8680\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2926 - acc: 0.8687\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2909 - acc: 0.8688\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2889 - acc: 0.8702\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2903 - acc: 0.8695\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2868 - acc: 0.8709\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2853 - acc: 0.8719\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2799 - acc: 0.8739\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2780 - acc: 0.8756\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2793 - acc: 0.8749\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2743 - acc: 0.8777\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2760 - acc: 0.8767\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2698 - acc: 0.8801\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2695 - acc: 0.8805\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2660 - acc: 0.8819\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2605 - acc: 0.8849\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2563 - acc: 0.8869\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2525 - acc: 0.8893\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2517 - acc: 0.8894\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2450 - acc: 0.8929\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2408 - acc: 0.8950\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2376 - acc: 0.8969\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2346 - acc: 0.8980\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2320 - acc: 0.8995\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2283 - acc: 0.9007\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2255 - acc: 0.9023\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2230 - acc: 0.9039\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2196 - acc: 0.9052\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2177 - acc: 0.9069\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2159 - acc: 0.9074\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2123 - acc: 0.9085\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2087 - acc: 0.9106\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2067 - acc: 0.9113\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2031 - acc: 0.9131\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2014 - acc: 0.9138\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1992 - acc: 0.9149\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1981 - acc: 0.9155\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1958 - acc: 0.9166\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1924 - acc: 0.9181\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1903 - acc: 0.9188\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1877 - acc: 0.9200\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1854 - acc: 0.9211\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1847 - acc: 0.9216\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1817 - acc: 0.9229\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1811 - acc: 0.9229\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1780 - acc: 0.9243\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1766 - acc: 0.9252\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1763 - acc: 0.9250\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1751 - acc: 0.9257\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1738 - acc: 0.9264\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1713 - acc: 0.9270\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1712 - acc: 0.9276\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1683 - acc: 0.9289\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1662 - acc: 0.9298\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1654 - acc: 0.9303\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1641 - acc: 0.9307\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1621 - acc: 0.9316\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1611 - acc: 0.9321\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1588 - acc: 0.9330\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1586 - acc: 0.9333\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1575 - acc: 0.9337\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1569 - acc: 0.9338\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1548 - acc: 0.9348\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1544 - acc: 0.9349\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1547 - acc: 0.9348\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1527 - acc: 0.9359\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1516 - acc: 0.9361\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1507 - acc: 0.9368\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1490 - acc: 0.9374\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1479 - acc: 0.9381\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1475 - acc: 0.9381\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1459 - acc: 0.9387\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1448 - acc: 0.9391\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1449 - acc: 0.9389\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1436 - acc: 0.9396\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1433 - acc: 0.9396\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1419 - acc: 0.9404\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1417 - acc: 0.9407\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1406 - acc: 0.9412\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1396 - acc: 0.9417\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1384 - acc: 0.9421\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1381 - acc: 0.9423\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1373 - acc: 0.9425\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1358 - acc: 0.9429\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1360 - acc: 0.9430\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1350 - acc: 0.9433\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1352 - acc: 0.9436\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1338 - acc: 0.9435\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1328 - acc: 0.9443\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1327 - acc: 0.9438\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1321 - acc: 0.9440\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1308 - acc: 0.9450\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1300 - acc: 0.9455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72     43052\n",
      "           1       0.70      0.62      0.66     23239\n",
      "           2       0.77      0.77      0.77     38900\n",
      "\n",
      "    accuracy                           0.73    105191\n",
      "   macro avg       0.72      0.71      0.72    105191\n",
      "weighted avg       0.73      0.73      0.73    105191\n",
      "\n",
      "Acurácia\n",
      "0.7116007696840244\n",
      "Precisao\n",
      "0.7256266931501734\n",
      "Recall\n",
      "0.7259271230428459\n",
      "F1\n",
      "0.7250886458964252\n",
      "[[31812  4373  6867]\n",
      " [ 6442 14469  2328]\n",
      " [ 6991  1829 30080]]\n",
      "TRAIN: [   4    5    6 ... 1997 1998 1999] TEST: [   0    1    2    3   16   21   25   26   27   35   41   48   59   66\n",
      "   70   71   80   83   86   87   89   95  105  108  109  117  118  125\n",
      "  126  128  129  131  133  142  149  150  151  154  156  157  161  173\n",
      "  192  194  204  215  223  242  244  245  246  250  255  260  261  265\n",
      "  273  279  287  300  301  307  313  315  328  329  334  341  343  354\n",
      "  364  365  370  379  380  386  394  404  408  410  412  422  438  453\n",
      "  457  458  459  462  467  471  473  475  479  483  485  486  488  495\n",
      "  498  501  509  520  524  535  539  544  547  553  555  564  570  574\n",
      "  589  591  593  596  597  606  608  615  619  621  624  625  632  633\n",
      "  636  642  647  649  654  659  664  673  683  689  697  698  700  703\n",
      "  707  712  716  725  731  736  738  741  742  756  764  774  780  782\n",
      "  783  787  793  803  824  834  837  839  841  844  845  853  856  861\n",
      "  867  868  869  870  871  873  877  887  889  893  903  904  905  912\n",
      "  922  928  940  944  948  949  952  957  963  964  967  971  985  992\n",
      "  996  998 1000 1003 1008 1010 1016 1018 1023 1034 1043 1050 1054 1058\n",
      " 1062 1065 1067 1070 1074 1080 1087 1096 1097 1098 1104 1107 1108 1109\n",
      " 1111 1115 1125 1128 1129 1140 1144 1146 1150 1158 1161 1165 1171 1175\n",
      " 1179 1181 1186 1187 1195 1202 1206 1213 1216 1229 1230 1244 1257 1260\n",
      " 1263 1266 1267 1279 1281 1283 1290 1294 1299 1304 1308 1316 1321 1325\n",
      " 1333 1334 1335 1336 1342 1350 1352 1355 1359 1360 1361 1364 1370 1371\n",
      " 1375 1377 1380 1381 1386 1389 1390 1396 1400 1403 1408 1411 1429 1442\n",
      " 1447 1448 1453 1470 1471 1474 1484 1498 1502 1504 1505 1513 1519 1521\n",
      " 1525 1533 1536 1539 1541 1545 1572 1576 1582 1583 1584 1597 1600 1602\n",
      " 1604 1608 1610 1614 1621 1623 1628 1636 1645 1652 1654 1663 1664 1676\n",
      " 1678 1682 1688 1692 1694 1695 1700 1704 1705 1706 1707 1708 1711 1715\n",
      " 1716 1721 1723 1726 1727 1750 1753 1765 1768 1770 1778 1784 1790 1797\n",
      " 1799 1800 1803 1805 1809 1825 1835 1842 1844 1845 1850 1858 1861 1865\n",
      " 1873 1878 1879 1892 1893 1899 1901 1903 1911 1914 1921 1923 1926 1939\n",
      " 1942 1955 1964 1975 1980 1984 1985 1996]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 17s 10ms/sample - loss: 0.3384 - acc: 0.8139\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3160 - acc: 0.8576\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3130 - acc: 0.8585\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3079 - acc: 0.8609\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3060 - acc: 0.8611\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3027 - acc: 0.8632\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.3036 - acc: 0.8628\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2969 - acc: 0.8658\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2957 - acc: 0.8667\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2937 - acc: 0.8676\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2929 - acc: 0.8684\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2921 - acc: 0.8691\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2925 - acc: 0.8689\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2909 - acc: 0.8702\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2854 - acc: 0.8726\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2827 - acc: 0.8740\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2837 - acc: 0.8735\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2788 - acc: 0.8763\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2818 - acc: 0.8753\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2776 - acc: 0.8778\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2728 - acc: 0.8796\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2697 - acc: 0.8820\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2633 - acc: 0.8854\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2609 - acc: 0.8867\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2548 - acc: 0.8892\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2533 - acc: 0.8902\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2482 - acc: 0.8927\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2445 - acc: 0.8941\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2424 - acc: 0.8952\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2404 - acc: 0.8968\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2371 - acc: 0.8979\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2333 - acc: 0.8997\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2312 - acc: 0.9008\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2297 - acc: 0.9012\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2254 - acc: 0.9031\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2231 - acc: 0.9042\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2209 - acc: 0.9054\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2169 - acc: 0.9073\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2140 - acc: 0.9085\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2129 - acc: 0.9088\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2101 - acc: 0.9102\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2081 - acc: 0.9109\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2043 - acc: 0.9126\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2032 - acc: 0.9133\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2013 - acc: 0.9147\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1974 - acc: 0.9158\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1946 - acc: 0.9171\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1926 - acc: 0.9182\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1918 - acc: 0.9184\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1925 - acc: 0.9180\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1872 - acc: 0.9206\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1856 - acc: 0.9213\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1834 - acc: 0.9222\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1822 - acc: 0.9227\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1794 - acc: 0.9241\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1777 - acc: 0.9249\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1762 - acc: 0.9254\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1753 - acc: 0.9259\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1737 - acc: 0.9266\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1720 - acc: 0.9276\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1700 - acc: 0.9282\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1692 - acc: 0.9285\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1689 - acc: 0.9287\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1670 - acc: 0.9298\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1654 - acc: 0.9303\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1659 - acc: 0.9300\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1634 - acc: 0.9310\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1607 - acc: 0.9323\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1608 - acc: 0.9326\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1592 - acc: 0.9331\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1575 - acc: 0.9340\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1569 - acc: 0.9340\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1550 - acc: 0.9350\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1549 - acc: 0.9347\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1544 - acc: 0.9351\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1530 - acc: 0.9358\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1522 - acc: 0.9360\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1506 - acc: 0.9367\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1498 - acc: 0.9371\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1494 - acc: 0.9373\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1485 - acc: 0.9379\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1479 - acc: 0.9381\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1472 - acc: 0.9383\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1455 - acc: 0.9389\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1445 - acc: 0.9396\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1433 - acc: 0.9401\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1427 - acc: 0.9403\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1413 - acc: 0.9406\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1410 - acc: 0.9409\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1407 - acc: 0.9412\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1393 - acc: 0.9416\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1390 - acc: 0.9415\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1380 - acc: 0.9421\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1380 - acc: 0.9421\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1371 - acc: 0.9425\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1364 - acc: 0.9431\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1362 - acc: 0.9431\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1358 - acc: 0.9434\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1346 - acc: 0.9435\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1339 - acc: 0.9441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72     40078\n",
      "           1       0.69      0.64      0.67     22313\n",
      "           2       0.77      0.77      0.77     35314\n",
      "\n",
      "    accuracy                           0.73     97705\n",
      "   macro avg       0.72      0.72      0.72     97705\n",
      "weighted avg       0.73      0.73      0.73     97705\n",
      "\n",
      "Acurácia\n",
      "0.7160468532690025\n",
      "Precisao\n",
      "0.7266730592266878\n",
      "Recall\n",
      "0.726677242720434\n",
      "F1\n",
      "0.726324947246533\n",
      "[[29587  4555  5936]\n",
      " [ 5906 14376  2031]\n",
      " [ 6433  1844 27037]]\n",
      "TRAIN: [   0    1    2 ... 1996 1997 1999] TEST: [  15   18   20   24   39   47   68   73   77   82   85   88   91   92\n",
      "   93   94   97  100  101  103  110  113  115  119  124  127  130  143\n",
      "  144  146  147  158  165  166  167  181  183  186  187  189  199  201\n",
      "  212  214  218  219  220  222  231  235  264  267  270  271  272  276\n",
      "  277  280  281  283  290  295  298  303  304  305  316  318  321  325\n",
      "  330  333  335  336  337  339  340  342  344  345  346  349  352  356\n",
      "  357  359  360  363  368  369  377  382  390  395  402  411  413  416\n",
      "  419  420  429  432  437  446  449  456  461  463  465  466  487  504\n",
      "  505  510  525  527  530  533  534  537  538  540  549  565  572  576\n",
      "  583  586  590  592  601  604  605  609  610  622  637  638  640  644\n",
      "  645  650  651  656  661  667  681  682  688  690  691  695  702  705\n",
      "  709  711  717  721  729  739  743  744  745  746  749  750  773  777\n",
      "  788  795  797  802  805  807  808  809  817  819  820  822  828  842\n",
      "  843  852  857  858  865  866  897  900  913  916  917  918  919  921\n",
      "  923  924  927  929  931  932  933  939  945  947  950  951  956  961\n",
      "  973  974  978  980  984  987  993  994  995  999 1001 1004 1009 1012\n",
      " 1022 1030 1035 1036 1044 1045 1056 1077 1084 1088 1089 1090 1092 1094\n",
      " 1095 1116 1126 1127 1132 1133 1139 1142 1151 1154 1155 1156 1164 1167\n",
      " 1168 1173 1177 1178 1189 1191 1192 1212 1218 1223 1226 1228 1231 1232\n",
      " 1235 1238 1240 1242 1243 1248 1251 1254 1258 1259 1270 1286 1302 1307\n",
      " 1312 1314 1319 1323 1328 1330 1347 1363 1367 1369 1383 1388 1393 1397\n",
      " 1407 1421 1422 1426 1436 1443 1444 1456 1457 1461 1466 1467 1488 1489\n",
      " 1491 1494 1495 1503 1506 1509 1523 1531 1534 1535 1537 1540 1544 1553\n",
      " 1562 1565 1567 1568 1570 1573 1585 1591 1599 1622 1624 1630 1633 1640\n",
      " 1641 1642 1644 1651 1656 1660 1667 1669 1674 1675 1685 1686 1693 1709\n",
      " 1712 1713 1714 1720 1724 1730 1739 1740 1743 1744 1749 1752 1755 1756\n",
      " 1764 1782 1789 1798 1802 1818 1824 1830 1834 1836 1837 1839 1853 1860\n",
      " 1870 1872 1875 1876 1886 1887 1890 1896 1902 1909 1912 1917 1918 1928\n",
      " 1933 1936 1947 1952 1972 1983 1991 1998]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3398 - acc: 0.7855\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.3153 - acc: 0.8576\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.3091 - acc: 0.8612\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.3078 - acc: 0.8613\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.3038 - acc: 0.8634\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.3024 - acc: 0.8639\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2998 - acc: 0.8657\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2954 - acc: 0.8674\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2951 - acc: 0.8678\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2942 - acc: 0.8684\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2926 - acc: 0.8685\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2907 - acc: 0.8699\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2885 - acc: 0.8704\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2873 - acc: 0.8707\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2832 - acc: 0.8727\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2853 - acc: 0.8719\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2817 - acc: 0.8741\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2783 - acc: 0.8758\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2766 - acc: 0.8765\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2742 - acc: 0.8776\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2705 - acc: 0.8798\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2677 - acc: 0.8814\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2613 - acc: 0.8851\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2568 - acc: 0.8874\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2540 - acc: 0.8895\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2483 - acc: 0.8918\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2477 - acc: 0.8925\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.2430 - acc: 0.8945\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2396 - acc: 0.8966\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2376 - acc: 0.8970\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2370 - acc: 0.8977\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2320 - acc: 0.8998\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2285 - acc: 0.9012\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2249 - acc: 0.9030\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2223 - acc: 0.9043\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2213 - acc: 0.9041\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2175 - acc: 0.9056\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2158 - acc: 0.9068\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2115 - acc: 0.9088\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2091 - acc: 0.9098\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2074 - acc: 0.9108\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2051 - acc: 0.9112\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.2030 - acc: 0.9123\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1993 - acc: 0.9142\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1974 - acc: 0.9150\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1941 - acc: 0.9160\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1930 - acc: 0.9172\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1908 - acc: 0.9179\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1881 - acc: 0.9191\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1883 - acc: 0.9189\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1869 - acc: 0.9194\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1833 - acc: 0.9207\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1820 - acc: 0.9218\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1809 - acc: 0.9216\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1783 - acc: 0.9230\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1771 - acc: 0.9235\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1754 - acc: 0.9245\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1729 - acc: 0.9253\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1716 - acc: 0.9261\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1704 - acc: 0.9260\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1700 - acc: 0.9262\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1679 - acc: 0.9274\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1663 - acc: 0.9284\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1648 - acc: 0.9288\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1640 - acc: 0.9290\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1629 - acc: 0.9294\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1618 - acc: 0.9303\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1600 - acc: 0.9310\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1596 - acc: 0.9307\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1580 - acc: 0.9319\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1576 - acc: 0.9321\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1561 - acc: 0.9325\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1538 - acc: 0.9339\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1541 - acc: 0.9332\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1522 - acc: 0.9342\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1517 - acc: 0.9344\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1508 - acc: 0.9353\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1496 - acc: 0.9359\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1498 - acc: 0.9353\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1478 - acc: 0.9361\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1475 - acc: 0.9366\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1470 - acc: 0.9370\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1459 - acc: 0.9374\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1453 - acc: 0.9375\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1433 - acc: 0.9381\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1426 - acc: 0.9386\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1417 - acc: 0.9385\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1419 - acc: 0.9388\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1408 - acc: 0.9396\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1394 - acc: 0.9400\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1394 - acc: 0.9400\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1384 - acc: 0.9407\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1375 - acc: 0.9413\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1372 - acc: 0.9413\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1363 - acc: 0.9421\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1345 - acc: 0.9425\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1351 - acc: 0.9419\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1346 - acc: 0.9420\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1340 - acc: 0.9425\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 15s 10ms/sample - loss: 0.1337 - acc: 0.9430\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72     41271\n",
      "           1       0.70      0.59      0.64     22434\n",
      "           2       0.76      0.77      0.76     35849\n",
      "\n",
      "    accuracy                           0.72     99554\n",
      "   macro avg       0.72      0.70      0.71     99554\n",
      "weighted avg       0.72      0.72      0.72     99554\n",
      "\n",
      "Acurácia\n",
      "0.7028339066212003\n",
      "Precisao\n",
      "0.7210562324726713\n",
      "Recall\n",
      "0.7212668501516765\n",
      "F1\n",
      "0.7195182361903878\n",
      "[[31025  3928  6318]\n",
      " [ 6704 13142  2588]\n",
      " [ 6624  1587 27638]]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_54 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_55 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_56 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_57 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_58 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_59 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 700, 3)            603       \n",
      "=================================================================\n",
      "Total params: 979,803\n",
      "Trainable params: 979,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acurácias total\n",
      "[0.7001375918883753, 0.7150102386321254, 0.7116007696840244, 0.7160468532690025, 0.7028339066212003]\n",
      "0.7091258720189456\n",
      "Precision total\n",
      "[0.7150368042364401, 0.7278655539482968, 0.7256266931501734, 0.7266730592266878, 0.7210562324726713]\n",
      "0.7232516686068539\n",
      "Recalls total\n",
      "[0.7156827645983682, 0.7282495149977616, 0.7259271230428459, 0.726677242720434, 0.7212668501516765]\n",
      "0.7235606991022172\n",
      "F1 total\n",
      "[0.7145107225706346, 0.7275190705944977, 0.7250886458964252, 0.726324947246533, 0.7195182361903878]\n",
      "0.7225923244996958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(8)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ8[train_index],\n",
    "                           previsores[test_index], classesQ8[test_index], 8)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('Acurácias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(3)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ3[train_index],\n",
    "                           previsores[test_index], classesQ3[test_index], 3)\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "print('Acurácias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
