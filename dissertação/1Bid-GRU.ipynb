{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n",
      "(2000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classesQ8 = base.iloc[:1400000, 20:28].values\n",
    "classesQ8 = np.reshape(classesQ8, (2000, 700, 8))\n",
    "print(classesQ8.shape)\n",
    "\n",
    "classesQ3 = base.iloc[:1400000, 28:31].values\n",
    "classesQ3 = np.reshape(classesQ3, (2000, 700, 3))\n",
    "print(classesQ3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNGRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede(saida):\n",
    "    model = Sequential()\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(saida, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test, saida):\n",
    "    model.fit(x_train, y_train, epochs = 100, verbose = 1)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], saida))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], saida))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "    \n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   1    2    5 ... 1997 1998 1999] TEST: [   0    3    4    8   12   22   23   25   30   31   33   43   46   49\n",
      "   53   62   64   67   78   79   81   83   84   89   90   93   96   99\n",
      "  111  114  115  140  142  143  145  151  153  174  187  192  198  200\n",
      "  205  223  233  239  241  243  250  251  268  273  276  284  286  289\n",
      "  290  303  307  309  313  316  320  326  328  329  335  336  340  347\n",
      "  351  355  359  360  374  375  378  384  390  397  403  405  410  419\n",
      "  427  428  430  433  440  444  450  451  452  460  464  465  469  470\n",
      "  476  479  481  482  485  500  501  507  522  525  527  532  534  543\n",
      "  545  549  559  561  564  565  566  575  580  584  586  593  607  618\n",
      "  619  626  628  629  632  635  641  644  650  653  662  665  667  671\n",
      "  672  676  677  679  688  694  696  703  708  714  721  742  750  757\n",
      "  758  762  767  771  776  778  783  786  792  805  806  807  812  813\n",
      "  820  823  830  841  844  845  851  855  860  861  865  870  871  872\n",
      "  873  874  878  891  905  906  910  915  919  920  922  925  929  950\n",
      "  959  960  961  962  980  982  989  994  995  996 1001 1005 1011 1012\n",
      " 1027 1034 1036 1045 1051 1059 1060 1062 1065 1067 1078 1084 1086 1089\n",
      " 1092 1096 1103 1118 1128 1143 1148 1149 1158 1159 1162 1168 1173 1176\n",
      " 1216 1217 1218 1222 1223 1235 1236 1240 1243 1247 1263 1266 1268 1285\n",
      " 1286 1287 1288 1296 1298 1299 1302 1304 1313 1316 1319 1320 1324 1326\n",
      " 1331 1332 1333 1342 1343 1348 1350 1357 1358 1371 1379 1395 1397 1402\n",
      " 1406 1408 1409 1417 1419 1420 1430 1433 1438 1439 1442 1444 1445 1446\n",
      " 1447 1454 1456 1458 1462 1463 1474 1475 1478 1481 1482 1486 1490 1494\n",
      " 1495 1499 1500 1504 1518 1524 1525 1527 1544 1554 1562 1563 1565 1567\n",
      " 1570 1571 1579 1581 1585 1587 1600 1602 1608 1614 1615 1619 1620 1626\n",
      " 1630 1641 1642 1647 1656 1666 1668 1671 1685 1696 1699 1708 1720 1726\n",
      " 1727 1731 1734 1736 1746 1758 1759 1763 1770 1772 1773 1775 1779 1782\n",
      " 1787 1796 1804 1807 1812 1826 1828 1830 1836 1839 1841 1855 1867 1873\n",
      " 1875 1887 1888 1893 1906 1908 1914 1924 1926 1928 1933 1937 1938 1951\n",
      " 1952 1968 1972 1978 1981 1992 1993 1994]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.6475 - acc: 0.1371\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5675 - acc: 0.1581\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5397 - acc: 0.1709\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5291 - acc: 0.1754\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5227 - acc: 0.1781\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5184 - acc: 0.1803\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5177 - acc: 0.1802\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5136 - acc: 0.1819\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5110 - acc: 0.1836\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5077 - acc: 0.1848\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5077 - acc: 0.1849\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5032 - acc: 0.1873\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5015 - acc: 0.1879\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5000 - acc: 0.1889\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4983 - acc: 0.1897\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.4954 - acc: 0.190 - 3s 2ms/sample - loss: 0.4953 - acc: 0.1910\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4935 - acc: 0.1917 0s - loss: 0.500\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4908 - acc: 0.1929\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4890 - acc: 0.1937\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4846 - acc: 0.1957\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4805 - acc: 0.1976\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4785 - acc: 0.1982\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4763 - acc: 0.1992\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4742 - acc: 0.2001\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4728 - acc: 0.2007\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4710 - acc: 0.2013\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4695 - acc: 0.2018\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4678 - acc: 0.2024\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4678 - acc: 0.2026 1s - loss: \n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4657 - acc: 0.2033\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4647 - acc: 0.2039\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4629 - acc: 0.2045 0s - loss: 0.4638\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4647 - acc: 0.2036\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4609 - acc: 0.2055\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4601 - acc: 0.2057\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4590 - acc: 0.2061\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4576 - acc: 0.2066\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4567 - acc: 0.2069\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4548 - acc: 0.2077 0s - loss: 0.4545 - acc: 0\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4540 - acc: 0.2083\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4568 - acc: 0.2067\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4529 - acc: 0.2085\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4512 - acc: 0.2090\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4501 - acc: 0.2095\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4490 - acc: 0.2098 1s - loss: 0.4367 - acc - ETA: 1s - lo\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4486 - acc: 0.2099\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4480 - acc: 0.2103\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4470 - acc: 0.2104\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4452 - acc: 0.2112\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4444 - acc: 0.2113\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4438 - acc: 0.2119\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4428 - acc: 0.2121\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4423 - acc: 0.2121\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4404 - acc: 0.2131\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4388 - acc: 0.2134\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4383 - acc: 0.2137 0s - loss: 0.4391 - acc: 0\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4368 - acc: 0.2143\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4363 - acc: 0.2141\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4351 - acc: 0.2149\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4339 - acc: 0.2152\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4334 - acc: 0.2152\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4315 - acc: 0.2161 1s - loss: 0.4320 - ETA: 0s - loss: 0.4346 - acc: 0.\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4309 - acc: 0.2162\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4292 - acc: 0.2169\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4284 - acc: 0.2172 0s - loss: 0.4291 - ac\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4263 - acc: 0.2177\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4252 - acc: 0.2182\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4256 - acc: 0.2179\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4242 - acc: 0.2183\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4229 - acc: 0.2189\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4231 - acc: 0.2189 1s - loss: 0\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4213 - acc: 0.2193\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4193 - acc: 0.2200\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4184 - acc: 0.2206\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4175 - acc: 0.2207\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4160 - acc: 0.2214\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4152 - acc: 0.2216\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4133 - acc: 0.2222 2s - los - ETA: 1s - loss: 0.4\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4130 - acc: 0.2226\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4117 - acc: 0.2230\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4108 - acc: 0.2232\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4093 - acc: 0.2236\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4075 - acc: 0.2241\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4066 - acc: 0.2243\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4058 - acc: 0.2249 1s - lo\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4044 - acc: 0.2250\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4030 - acc: 0.2258\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4018 - acc: 0.2261\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4011 - acc: 0.2262\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3997 - acc: 0.2268\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3998 - acc: 0.2266\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3987 - acc: 0.2271\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3970 - acc: 0.2278\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3953 - acc: 0.2283\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3953 - acc: 0.2282\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3947 - acc: 0.2285 0s - loss: 0.3939 - acc: 0.\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3932 - acc: 0.2289\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3925 - acc: 0.2293\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3918 - acc: 0.2294\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3893 - acc: 0.2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1270\n",
      "           1       0.58      0.68      0.62     22251\n",
      "           2       0.31      0.05      0.08      3847\n",
      "           3       0.67      0.79      0.73     32215\n",
      "           4       0.40      0.03      0.06       821\n",
      "           5       0.42      0.51      0.46     20402\n",
      "           6       0.31      0.04      0.07      8865\n",
      "           7       0.37      0.34      0.36     11398\n",
      "\n",
      "    accuracy                           0.55    101069\n",
      "   macro avg       0.38      0.30      0.30    101069\n",
      "weighted avg       0.51      0.55      0.51    101069\n",
      "\n",
      "Acur√°cia\n",
      "0.30497768427402544\n",
      "Precisao\n",
      "0.5103443556964967\n",
      "Recall\n",
      "0.548239321651545\n",
      "F1\n",
      "0.5119306604085974\n",
      "[[    0   381    11   199     0   534    27   118]\n",
      " [    0 15025    43  2905     5  3331   108   834]\n",
      " [    0   640   183  1122     0  1167    56   679]\n",
      " [    0  2505   136 25440    23  2763    65  1283]\n",
      " [    0    96     2   576    26    79     3    39]\n",
      " [    0  4225    92  3325     2 10488   286  1984]\n",
      " [    0  1582    58  1520     4  3773   354  1574]\n",
      " [    0  1606    70  2719     5  2855   249  3894]]\n",
      "TRAIN: [   0    2    3 ... 1997 1998 1999] TEST: [   1    9   10   11   18   19   26   32   34   36   42   44   54   55\n",
      "   56   57   60   66   68   71   77   91   95   97  106  118  120  123\n",
      "  126  129  132  133  149  156  159  160  163  166  167  169  170  173\n",
      "  178  184  185  188  193  211  212  216  218  231  234  235  236  244\n",
      "  248  258  259  266  278  279  292  293  297  299  302  319  322  324\n",
      "  327  333  334  341  345  348  362  376  380  386  392  393  401  416\n",
      "  417  435  448  449  454  461  466  474  475  488  489  491  493  497\n",
      "  498  502  508  510  512  513  514  517  518  526  533  536  538  541\n",
      "  548  554  556  567  569  588  591  594  595  599  612  621  630  631\n",
      "  638  640  642  645  648  649  651  655  666  670  673  674  682  686\n",
      "  690  698  701  704  707  709  722  726  727  731  734  735  744  761\n",
      "  764  765  770  780  782  784  788  799  814  815  822  826  827  831\n",
      "  833  839  842  843  852  868  877  879  881  889  890  895  897  907\n",
      "  908  912  913  914  916  918  924  936  937  938  941  942  943  945\n",
      "  956  958  969  970  971  973  979  981  997 1002 1004 1016 1019 1020\n",
      " 1035 1041 1053 1055 1056 1057 1058 1064 1068 1077 1082 1083 1094 1095\n",
      " 1099 1101 1102 1106 1107 1111 1115 1116 1117 1119 1121 1126 1129 1134\n",
      " 1137 1146 1150 1152 1161 1184 1185 1186 1188 1189 1191 1204 1205 1207\n",
      " 1215 1224 1225 1228 1250 1270 1274 1276 1277 1280 1283 1295 1309 1310\n",
      " 1314 1346 1347 1349 1352 1359 1361 1363 1365 1370 1373 1385 1391 1403\n",
      " 1405 1410 1412 1418 1424 1435 1437 1461 1464 1472 1476 1479 1483 1489\n",
      " 1491 1492 1493 1496 1506 1509 1512 1523 1529 1532 1533 1534 1536 1539\n",
      " 1551 1559 1566 1569 1592 1605 1611 1618 1624 1632 1634 1644 1646 1650\n",
      " 1653 1657 1661 1663 1667 1674 1681 1683 1693 1697 1707 1711 1712 1713\n",
      " 1715 1716 1719 1725 1729 1730 1732 1737 1747 1753 1756 1765 1767 1778\n",
      " 1785 1795 1798 1801 1806 1815 1816 1825 1829 1831 1832 1834 1835 1845\n",
      " 1849 1851 1852 1853 1856 1863 1864 1865 1866 1869 1874 1877 1878 1880\n",
      " 1883 1889 1891 1901 1903 1904 1905 1916 1934 1944 1947 1953 1957 1961\n",
      " 1962 1963 1966 1971 1974 1983 1987 1990]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.6407 - acc: 0.1363\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5651 - acc: 0.1574\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5372 - acc: 0.1698\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5294 - acc: 0.1726\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5227 - acc: 0.1757\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5171 - acc: 0.1782\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5136 - acc: 0.1795 0s - loss: 0.5120 -\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5116 - acc: 0.1806\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5084 - acc: 0.1822\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5055 - acc: 0.1833 0s - loss: 0.5084\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5052 - acc: 0.1833 1s - loss: 0.5045 - acc: 0.1 - ETA: 1s - lo\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5024 - acc: 0.1846\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5017 - acc: 0.1852\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4979 - acc: 0.1869\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4964 - acc: 0.1878 0s - loss: 0.4983\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4945 - acc: 0.1888\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4911 - acc: 0.1903\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4895 - acc: 0.1912\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4894 - acc: 0.1911\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4837 - acc: 0.1935\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4805 - acc: 0.1951\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4777 - acc: 0.1961 0s - loss: 0.4748 - acc: 0\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4780 - acc: 0.1957\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4741 - acc: 0.1979\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4723 - acc: 0.1984\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4706 - acc: 0.1990\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4696 - acc: 0.1995\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4687 - acc: 0.1999 \n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4659 - acc: 0.2010\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4652 - acc: 0.2012\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4641 - acc: 0.2016\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4621 - acc: 0.2025 1s - loss: 0.4733 - acc:  - ETA: 0s - loss: 0.46\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4614 - acc: 0.2028\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4622 - acc: 0.2023\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4592 - acc: 0.2035\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4593 - acc: 0.2036\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4584 - acc: 0.2039\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4559 - acc: 0.2047\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4549 - acc: 0.2051 1s - \n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4546 - acc: 0.2054\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4532 - acc: 0.2057\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4516 - acc: 0.2065\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4511 - acc: 0.2067\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4506 - acc: 0.2067 0s - loss: 0.4503 - acc: 0. - ETA: 0s - loss: 0.4521 - acc: 0.207\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4489 - acc: 0.2073 1s - loss: 0.4371 - acc: 0 - ETA: 1s - los\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4483 - acc: 0.2075\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4471 - acc: 0.2080 0s - loss: 0.4462 -\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4476 - acc: 0.2077\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4462 - acc: 0.2083\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4440 - acc: 0.2093\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4442 - acc: 0.2090\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4433 - acc: 0.2091\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4415 - acc: 0.2098 0s - loss: 0.4435 - acc: 0.\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4404 - acc: 0.2103\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4398 - acc: 0.2107\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4388 - acc: 0.2108\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4375 - acc: 0.2113\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4366 - acc: 0.2119\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4350 - acc: 0.2120\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4341 - acc: 0.2125\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4325 - acc: 0.2130\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4322 - acc: 0.2131\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4320 - acc: 0.2133\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4308 - acc: 0.2136 0s - loss: 0.4319 - acc: 0.2\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4292 - acc: 0.2142\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4276 - acc: 0.2150 1s - l\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4273 - acc: 0.2147\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4263 - acc: 0.2153\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4248 - acc: 0.2159\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4243 - acc: 0.2161 \n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4238 - acc: 0.2161\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4206 - acc: 0.2173\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4204 - acc: 0.2174\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4189 - acc: 0.2178\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4194 - acc: 0.2177\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4170 - acc: 0.2184\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4167 - acc: 0.2187\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4147 - acc: 0.2193\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4142 - acc: 0.2192\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4123 - acc: 0.2200\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4115 - acc: 0.2203\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4100 - acc: 0.2208\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4088 - acc: 0.2214 0s - loss: 0.4059 - \n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4079 - acc: 0.2214\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4069 - acc: 0.2218 0s - loss: 0.40\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4058 - acc: 0.2222\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4047 - acc: 0.2226 2s - loss: 0.42 - ETA: 1s - loss: 0\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4038 - acc: 0.2228\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4037 - acc: 0.2228\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4022 - acc: 0.2233\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3999 - acc: 0.2243\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3993 - acc: 0.2244\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3981 - acc: 0.2247\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3976 - acc: 0.2250\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3969 - acc: 0.2252\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3948 - acc: 0.2258\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3938 - acc: 0.2257\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3933 - acc: 0.2263\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3937 - acc: 0.2260\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3944 - acc: 0.2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1192\n",
      "           1       0.56      0.67      0.61     20654\n",
      "           2       0.24      0.03      0.05      4035\n",
      "           3       0.67      0.80      0.73     35789\n",
      "           4       0.45      0.02      0.05       690\n",
      "           5       0.43      0.50      0.46     20560\n",
      "           6       0.34      0.05      0.09      9144\n",
      "           7       0.37      0.33      0.35     11718\n",
      "\n",
      "    accuracy                           0.55    103782\n",
      "   macro avg       0.38      0.30      0.29    103782\n",
      "weighted avg       0.51      0.55      0.52    103782\n",
      "\n",
      "Acur√°cia\n",
      "0.30149565978010917\n",
      "Precisao\n",
      "0.5126510449085298\n",
      "Recall\n",
      "0.5523115761885491\n",
      "F1\n",
      "0.515269737091279\n",
      "[[    0   346     5   223     0   464    33   121]\n",
      " [    0 13823    51  2947     5  2972   106   750]\n",
      " [    0   632   124  1451     2  1103    52   671]\n",
      " [    0  2879    89 28704     9  2606   101  1401]\n",
      " [    0    34     2   528    17    58     1    50]\n",
      " [    0  4025    91  3795     3 10273   398  1975]\n",
      " [    0  1551    57  1789     0  3637   497  1613]\n",
      " [    0  1509    93  3216     2  2748   268  3882]]\n",
      "TRAIN: [   0    1    3 ... 1997 1998 1999] TEST: [   2    6   15   20   28   39   40   45   47   51   52   65   69   82\n",
      "   85   88   94   98  100  101  102  103  109  110  112  116  117  124\n",
      "  130  134  141  146  152  171  175  176  190  194  195  199  203  213\n",
      "  214  215  220  227  237  238  245  247  249  254  262  269  270  277\n",
      "  280  296  298  300  301  306  310  312  314  318  332  338  343  344\n",
      "  346  356  358  368  369  371  372  381  385  387  388  391  395  396\n",
      "  408  411  413  414  420  423  429  437  441  453  455  459  462  473\n",
      "  477  486  492  496  504  506  511  515  519  523  524  551  552  560\n",
      "  577  578  585  589  590  597  600  608  609  614  622  633  639  646\n",
      "  656  669  681  684  685  700  712  716  724  728  737  741  746  748\n",
      "  753  754  755  769  772  773  774  779  787  791  796  802  810  816\n",
      "  818  819  829  832  835  836  837  848  857  858  863  867  869  876\n",
      "  882  886  892  894  896  898  899  917  927  930  932  935  939  940\n",
      "  944  946  947  952  954  957  963  976  978  983  990  993  999 1009\n",
      " 1010 1015 1017 1018 1025 1026 1042 1044 1049 1054 1066 1071 1073 1074\n",
      " 1079 1081 1104 1105 1110 1113 1120 1124 1125 1131 1132 1140 1153 1155\n",
      " 1166 1167 1169 1170 1175 1177 1182 1187 1199 1202 1208 1220 1221 1226\n",
      " 1232 1233 1239 1245 1246 1249 1251 1253 1257 1259 1261 1272 1275 1278\n",
      " 1279 1281 1289 1294 1312 1318 1321 1323 1334 1337 1338 1344 1345 1351\n",
      " 1367 1368 1372 1374 1378 1380 1381 1389 1390 1393 1398 1401 1425 1432\n",
      " 1448 1452 1467 1469 1477 1485 1498 1502 1505 1510 1511 1514 1516 1517\n",
      " 1519 1520 1545 1546 1549 1550 1552 1555 1557 1561 1568 1574 1580 1583\n",
      " 1588 1589 1599 1603 1606 1610 1616 1622 1637 1639 1640 1649 1654 1659\n",
      " 1672 1673 1677 1678 1679 1686 1687 1689 1695 1698 1701 1703 1706 1717\n",
      " 1733 1735 1740 1742 1748 1750 1752 1764 1766 1774 1780 1783 1784 1788\n",
      " 1792 1797 1805 1808 1809 1814 1819 1820 1821 1822 1827 1837 1838 1842\n",
      " 1843 1854 1857 1859 1860 1861 1871 1876 1879 1881 1892 1896 1898 1899\n",
      " 1900 1923 1927 1930 1932 1935 1936 1940 1942 1943 1948 1955 1956 1959\n",
      " 1967 1973 1975 1979 1980 1982 1984 1988]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.6421 - acc: 0.1372 1s - los\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5626 - acc: 0.1572\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5351 - acc: 0.1696\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5251 - acc: 0.1739\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5202 - acc: 0.1761\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5162 - acc: 0.1772\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5123 - acc: 0.1793 1s - loss: 0.5212 - acc: 0. - ETA: 1s - loss: \n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5099 - acc: 0.1806\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5084 - acc: 0.1815\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5059 - acc: 0.1822\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5037 - acc: 0.1831\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5031 - acc: 0.1834\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5027 - acc: 0.1839\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4983 - acc: 0.1860\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4949 - acc: 0.1877\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4908 - acc: 0.1898\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4879 - acc: 0.1908\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4849 - acc: 0.1924\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4805 - acc: 0.1942\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4775 - acc: 0.1956\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4762 - acc: 0.1963\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4740 - acc: 0.1969\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4718 - acc: 0.1981\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4711 - acc: 0.1979\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4684 - acc: 0.1995 1s - \n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4674 - acc: 0.1997\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4655 - acc: 0.2006 1s - loss: 0.\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4640 - acc: 0.2012\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4631 - acc: 0.2016\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4634 - acc: 0.2014 0s - loss: 0.4646 - acc:\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4607 - acc: 0.2022\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4607 - acc: 0.2026\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4588 - acc: 0.2034\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4582 - acc: 0.2034\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4570 - acc: 0.2039\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4565 - acc: 0.2038\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4541 - acc: 0.2050\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4531 - acc: 0.2054\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4530 - acc: 0.2055\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4531 - acc: 0.2053\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4503 - acc: 0.2065\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4506 - acc: 0.2064\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4505 - acc: 0.2061\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4470 - acc: 0.2075\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4466 - acc: 0.2080 0s - loss: 0.4496 -\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4463 - acc: 0.2078 1s - lo\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4459 - acc: 0.2082\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4435 - acc: 0.2092\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4428 - acc: 0.2092\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4421 - acc: 0.2095\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4403 - acc: 0.2101\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4394 - acc: 0.2105 1s - loss: 0\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4377 - acc: 0.2113\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4370 - acc: 0.2115\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4363 - acc: 0.2117 1s - lo\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4349 - acc: 0.2122\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4334 - acc: 0.2125\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4335 - acc: 0.2127\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4314 - acc: 0.2134\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4310 - acc: 0.2135 1s - loss\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4290 - acc: 0.2143ETA: 0s - loss: 0.4270 - acc:  - ETA: 0s - loss: 0.4274 - acc:\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4283 - acc: 0.2145\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4267 - acc: 0.2146\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4253 - acc: 0.2153\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4243 - acc: 0.2158\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4226 - acc: 0.2165\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4221 - acc: 0.2166 1s - \n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4207 - acc: 0.2173\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4194 - acc: 0.2177 1s - loss\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4183 - acc: 0.2180\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4170 - acc: 0.2185\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4154 - acc: 0.2190\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4138 - acc: 0.2195\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4136 - acc: 0.2195\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4119 - acc: 0.2203\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4113 - acc: 0.2203\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4096 - acc: 0.2209\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4088 - acc: 0.2214\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4067 - acc: 0.2215\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4055 - acc: 0.2221\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4061 - acc: 0.2219 1s - lo\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4034 - acc: 0.2229\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4021 - acc: 0.2235\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4031 - acc: 0.2230\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4011 - acc: 0.2237\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3983 - acc: 0.2243\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3971 - acc: 0.2250\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3967 - acc: 0.2251\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3955 - acc: 0.2254\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3938 - acc: 0.2259\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3945 - acc: 0.2258\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3922 - acc: 0.2266\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3919 - acc: 0.2265\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3904 - acc: 0.2273\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3896 - acc: 0.2274\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3887 - acc: 0.2276\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3870 - acc: 0.2283\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3868 - acc: 0.2282\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3851 - acc: 0.2287 1s \n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3844 - acc: 0.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1299\n",
      "           1       0.56      0.67      0.61     22206\n",
      "           2       0.26      0.03      0.06      4037\n",
      "           3       0.69      0.77      0.73     34271\n",
      "           4       0.45      0.05      0.08       626\n",
      "           5       0.42      0.54      0.47     21079\n",
      "           6       0.33      0.04      0.07      9209\n",
      "           7       0.38      0.34      0.36     11759\n",
      "\n",
      "    accuracy                           0.55    104486\n",
      "   macro avg       0.39      0.31      0.30    104486\n",
      "weighted avg       0.52      0.55      0.51    104486\n",
      "\n",
      "Acur√°cia\n",
      "0.3061005963067508\n",
      "Precisao\n",
      "0.5153678307605626\n",
      "Recall\n",
      "0.5489730681622418\n",
      "F1\n",
      "0.514482323407129\n",
      "[[    0   383     7   202     0   571    21   115]\n",
      " [    0 14865    35  2711     1  3678    95   821]\n",
      " [    0   704   139  1141     5  1249    48   751]\n",
      " [    0  2915   121 26538    22  3075    72  1528]\n",
      " [    0    93     3   405    29    60     1    35]\n",
      " [    0  4401    87  3038     1 11364   300  1888]\n",
      " [    0  1598    48  1469     2  4110   376  1606]\n",
      " [    0  1524    92  2694     5  3172   223  4049]]\n",
      "TRAIN: [   0    1    2 ... 1996 1997 1999] TEST: [   5    7   13   14   16   21   35   38   48   50   61   63   72   73\n",
      "   76   80   86   87   92  104  105  107  113  119  122  125  127  131\n",
      "  135  136  137  138  144  147  150  155  157  158  161  164  168  172\n",
      "  180  181  186  196  197  208  217  219  221  222  224  228  230  232\n",
      "  240  246  252  256  261  263  264  265  271  274  282  285  291  295\n",
      "  304  308  311  321  323  331  337  339  350  354  364  365  366  367\n",
      "  370  379  383  389  394  398  399  400  404  415  421  422  431  432\n",
      "  438  439  442  445  456  463  467  472  480  490  495  503  505  509\n",
      "  516  529  537  542  546  547  557  562  568  571  576  582  598  603\n",
      "  605  606  616  624  634  643  647  654  658  659  660  661  680  683\n",
      "  689  691  695  702  705  713  715  720  730  732  733  736  738  739\n",
      "  743  747  752  760  763  768  775  777  785  790  793  794  795  798\n",
      "  801  803  804  808  809  811  817  824  834  840  849  850  853  854\n",
      "  859  862  864  866  883  884  885  900  902  911  926  934  949  951\n",
      "  955  964  967  974  975  985  987  991 1007 1014 1022 1023 1028 1030\n",
      " 1031 1032 1038 1039 1043 1046 1047 1069 1070 1072 1080 1085 1087 1088\n",
      " 1090 1093 1097 1098 1100 1108 1109 1112 1122 1123 1127 1130 1133 1135\n",
      " 1138 1139 1144 1145 1151 1154 1163 1171 1172 1174 1190 1192 1193 1194\n",
      " 1195 1206 1210 1212 1213 1214 1219 1227 1230 1234 1237 1241 1244 1260\n",
      " 1262 1264 1265 1269 1271 1282 1291 1292 1301 1322 1325 1335 1336 1339\n",
      " 1341 1353 1355 1362 1364 1366 1375 1377 1384 1396 1399 1416 1427 1428\n",
      " 1440 1443 1453 1459 1460 1468 1471 1484 1488 1497 1508 1513 1515 1521\n",
      " 1528 1531 1535 1537 1541 1543 1547 1553 1572 1575 1577 1578 1593 1594\n",
      " 1596 1597 1598 1601 1604 1613 1617 1627 1628 1629 1636 1643 1645 1648\n",
      " 1651 1652 1655 1658 1662 1664 1665 1684 1694 1700 1704 1705 1709 1710\n",
      " 1718 1722 1723 1728 1738 1744 1745 1749 1754 1755 1757 1769 1771 1776\n",
      " 1781 1790 1791 1793 1794 1802 1803 1810 1813 1818 1823 1844 1848 1884\n",
      " 1885 1886 1897 1902 1907 1909 1915 1917 1918 1921 1922 1925 1929 1941\n",
      " 1945 1946 1950 1954 1976 1977 1985 1998]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.6379 - acc: 0.1355\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5605 - acc: 0.1578\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5345 - acc: 0.1690\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5239 - acc: 0.1732\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5190 - acc: 0.1757 \n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5132 - acc: 0.1781 0s - loss: 0.5145 - acc: 0.17\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5099 - acc: 0.1797 2s - loss: 0.4938 - acc: -\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5063 - acc: 0.1813\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5037 - acc: 0.1826\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5042 - acc: 0.1826\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5003 - acc: 0.1845 0s - loss: 0.4965 - a - ETA: 0s - loss: 0.5013 - acc:\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4999 - acc: 0.1843\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4969 - acc: 0.1860\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4938 - acc: 0.1875 0s - loss: 0.4951 - acc: \n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4921 - acc: 0.1882\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4896 - acc: 0.1894\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4859 - acc: 0.1911\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4832 - acc: 0.1923\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4791 - acc: 0.1939 1s \n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4783 - acc: 0.1943\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4733 - acc: 0.1965\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4724 - acc: 0.1968\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4704 - acc: 0.1975\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4672 - acc: 0.1989\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4660 - acc: 0.1995\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.4654 - acc: 0.1996- ETA: 2s - loss: - ETA: 1s - l - 3s 2ms/sample - loss: 0.4654 - acc: 0.1996\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4632 - acc: 0.2004 0s - loss: 0.4609 - a\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4634 - acc: 0.2002 0s - loss: 0.4630 - acc: 0.199\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4603 - acc: 0.2019\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4609 - acc: 0.2015 1s - loss: 0\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4600 - acc: 0.2018\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4576 - acc: 0.2024\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4570 - acc: 0.2031 2s - loss: 0.464 - ETA: 1s - loss: 0.4612 - acc: 0 - ETA: 1s - loss\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.4563 - acc: 0.203 - 3s 2ms/sample - loss: 0.4556 - acc: 0.2035\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4539 - acc: 0.2042\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4533 - acc: 0.2043\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4516 - acc: 0.2049\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4514 - acc: 0.2050\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4496 - acc: 0.2058\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4483 - acc: 0.2062 1s - loss: 0.4621 - ac - ETA: 1s - loss: \n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4477 - acc: 0.2065\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4476 - acc: 0.2067\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4466 - acc: 0.2070\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4457 - acc: 0.2072\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4435 - acc: 0.2081\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4436 - acc: 0.2081\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4413 - acc: 0.2088\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4405 - acc: 0.2093 0s - loss: 0.4385 - acc: 0.20\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4401 - acc: 0.2093\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4388 - acc: 0.2099 0s - loss: 0.4370 - acc\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4372 - acc: 0.2105\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4359 - acc: 0.2108\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4362 - acc: 0.2108\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4343 - acc: 0.2117\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4327 - acc: 0.2120\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4325 - acc: 0.2120 1s - loss: 0\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4320 - acc: 0.2124\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4299 - acc: 0.2129 0s - loss: 0.4354 - a\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4287 - acc: 0.2133\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4275 - acc: 0.2139\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4267 - acc: 0.2140\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4258 - acc: 0.2145\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4244 - acc: 0.2147\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4244 - acc: 0.2147\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4239 - acc: 0.2145\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4215 - acc: 0.2160\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4200 - acc: 0.2165\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4192 - acc: 0.2166\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4176 - acc: 0.2172\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4166 - acc: 0.2174\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4164 - acc: 0.2175 1s - loss: \n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4146 - acc: 0.2181\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4131 - acc: 0.2186\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4115 - acc: 0.2192\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4105 - acc: 0.2196\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4094 - acc: 0.2199\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4087 - acc: 0.2203\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4071 - acc: 0.2207\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4059 - acc: 0.2211 0s - loss: 0.4076 -\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4061 - acc: 0.2209\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4051 - acc: 0.2213\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4029 - acc: 0.2223 0s - loss: 0.4002 - acc: 0.2\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4011 - acc: 0.2228\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3999 - acc: 0.2230 2s  - ETA: 0s - loss: 0.40\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3991 - acc: 0.2234\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3978 - acc: 0.2236 0s - loss: 0.4002 - acc\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3979 - acc: 0.2235\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3971 - acc: 0.2240\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3952 - acc: 0.2246 0s - loss: 0.3958 \n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3944 - acc: 0.2248\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3947 - acc: 0.2249\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3936 - acc: 0.2252\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3919 - acc: 0.2255\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3901 - acc: 0.2263\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3892 - acc: 0.2266\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3885 - acc: 0.2268\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3890 - acc: 0.2268\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3865 - acc: 0.2274\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3858 - acc: 0.2277\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3846 - acc: 0.2280 1s - loss:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1301\n",
      "           1       0.55      0.68      0.61     22111\n",
      "           2       0.31      0.05      0.08      4205\n",
      "           3       0.68      0.77      0.72     34274\n",
      "           4       0.35      0.02      0.03       691\n",
      "           5       0.42      0.52      0.46     21509\n",
      "           6       0.31      0.05      0.08      9427\n",
      "           7       0.38      0.34      0.36     11992\n",
      "\n",
      "    accuracy                           0.54    105510\n",
      "   macro avg       0.38      0.30      0.29    105510\n",
      "weighted avg       0.51      0.54      0.51    105510\n",
      "\n",
      "Acur√°cia\n",
      "0.3017751780482968\n",
      "Precisao\n",
      "0.5065077357838685\n",
      "Recall\n",
      "0.542138185953938\n",
      "F1\n",
      "0.5071645936249878\n",
      "[[    0   416     8   221     1   516    24   115]\n",
      " [    0 15014    46  2856     1  3285   122   787]\n",
      " [    0   727   203  1221     1  1293    75   685]\n",
      " [    0  3182   141 26347    13  2965   103  1523]\n",
      " [    0    65     1   477    11    80     2    55]\n",
      " [    0  4592    84  3373     1 11132   377  1950]\n",
      " [    0  1697    49  1559     1  4140   439  1542]\n",
      " [    0  1672   119  2821     2  3057   266  4055]]\n",
      "TRAIN: [   0    1    2 ... 1993 1994 1998] TEST: [  17   24   27   29   37   41   58   59   70   74   75  108  121  128\n",
      "  139  148  154  162  165  177  179  182  183  189  191  201  202  204\n",
      "  206  207  209  210  225  226  229  242  253  255  257  260  267  272\n",
      "  275  281  283  287  288  294  305  315  317  325  330  342  349  352\n",
      "  353  357  361  363  373  377  382  402  406  407  409  412  418  424\n",
      "  425  426  434  436  443  446  447  457  458  468  471  478  483  484\n",
      "  487  494  499  520  521  528  530  531  535  539  540  544  550  553\n",
      "  555  558  563  570  572  573  574  579  581  583  587  592  596  601\n",
      "  602  604  610  611  613  615  617  620  623  625  627  636  637  652\n",
      "  657  663  664  668  675  678  687  692  693  697  699  706  710  711\n",
      "  717  718  719  723  725  729  740  745  749  751  756  759  766  781\n",
      "  789  797  800  821  825  828  838  846  847  856  875  880  887  888\n",
      "  893  901  903  904  909  921  923  928  931  933  948  953  965  966\n",
      "  968  972  977  984  986  988  992  998 1000 1003 1006 1008 1013 1021\n",
      " 1024 1029 1033 1037 1040 1048 1050 1052 1061 1063 1075 1076 1091 1114\n",
      " 1136 1141 1142 1147 1156 1157 1160 1164 1165 1178 1179 1180 1181 1183\n",
      " 1196 1197 1198 1200 1201 1203 1209 1211 1229 1231 1238 1242 1248 1252\n",
      " 1254 1255 1256 1258 1267 1273 1284 1290 1293 1297 1300 1303 1305 1306\n",
      " 1307 1308 1311 1315 1317 1327 1328 1329 1330 1340 1354 1356 1360 1369\n",
      " 1376 1382 1383 1386 1387 1388 1392 1394 1400 1404 1407 1411 1413 1414\n",
      " 1415 1421 1422 1423 1426 1429 1431 1434 1436 1441 1449 1450 1451 1455\n",
      " 1457 1465 1466 1470 1473 1480 1487 1501 1503 1507 1522 1526 1530 1538\n",
      " 1540 1542 1548 1556 1558 1560 1564 1573 1576 1582 1584 1586 1590 1591\n",
      " 1595 1607 1609 1612 1621 1623 1625 1631 1633 1635 1638 1660 1669 1670\n",
      " 1675 1676 1680 1682 1688 1690 1691 1692 1702 1714 1721 1724 1739 1741\n",
      " 1743 1751 1760 1761 1762 1768 1777 1786 1789 1799 1800 1811 1817 1824\n",
      " 1833 1840 1846 1847 1850 1858 1862 1868 1870 1872 1882 1890 1894 1895\n",
      " 1910 1911 1912 1913 1919 1920 1931 1939 1949 1958 1960 1964 1965 1969\n",
      " 1970 1986 1989 1991 1995 1996 1997 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.6448 - acc: 0.1357\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5646 - acc: 0.1603 0s - loss: 0.5709\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5393 - acc: 0.1715\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5287 - acc: 0.1760\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5220 - acc: 0.1787\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5174 - acc: 0.1808\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5145 - acc: 0.1822\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5147 - acc: 0.1816\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5090 - acc: 0.1846\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5070 - acc: 0.1855\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5063 - acc: 0.1859\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5025 - acc: 0.1877\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5011 - acc: 0.1883\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4968 - acc: 0.1902\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4929 - acc: 0.1924\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4922 - acc: 0.1924\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4873 - acc: 0.1948\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4826 - acc: 0.1966\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4805 - acc: 0.1978 1s - loss: 0.4724 - acc: 0. - ETA: 1s \n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4772 - acc: 0.1992\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4751 - acc: 0.2001 1s - los\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4740 - acc: 0.2008\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4724 - acc: 0.2013\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4704 - acc: 0.2020\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4689 - acc: 0.2026\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4672 - acc: 0.2033\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4668 - acc: 0.2034\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4650 - acc: 0.2041 1s - loss: \n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4657 - acc: 0.2037\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4643 - acc: 0.2042\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4652 - acc: 0.2037\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4623 - acc: 0.2051\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4605 - acc: 0.2060\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4604 - acc: 0.2056\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4604 - acc: 0.2058\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4582 - acc: 0.2067\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4564 - acc: 0.2076\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4570 - acc: 0.2071\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4545 - acc: 0.2081\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4534 - acc: 0.2085\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4534 - acc: 0.2087\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4527 - acc: 0.2088\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4514 - acc: 0.2093 0s - loss: 0.4506\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4498 - acc: 0.2100\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4482 - acc: 0.2107\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4471 - acc: 0.2111\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4462 - acc: 0.2114\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4457 - acc: 0.2116\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4462 - acc: 0.2110 1s - l\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4443 - acc: 0.2119\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4435 - acc: 0.2120\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4415 - acc: 0.2130\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4401 - acc: 0.2135\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4411 - acc: 0.2130\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4382 - acc: 0.2141\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4372 - acc: 0.2145\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4355 - acc: 0.2150\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4356 - acc: 0.2152\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4335 - acc: 0.2158\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4340 - acc: 0.2155\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4318 - acc: 0.2164\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4310 - acc: 0.2168\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4299 - acc: 0.2169 1s - loss: - ETA: 0s - loss: 0.4286 - acc: \n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4279 - acc: 0.2177\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4272 - acc: 0.2179\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4259 - acc: 0.2184\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4254 - acc: 0.2184\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4235 - acc: 0.2190\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4222 - acc: 0.2197 2s - loss: 0.4351 - acc: 0.22 - ET\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4214 - acc: 0.2198 0s - loss: 0.42\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4204 - acc: 0.2203\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4191 - acc: 0.2207\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4183 - acc: 0.2209\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4166 - acc: 0.2213\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4163 - acc: 0.2217\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4142 - acc: 0.2225\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4136 - acc: 0.2225 0s - loss: 0.41\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4119 - acc: 0.2231 1s -  - ETA: 0s - loss: 0.4106 - acc: \n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4119 - acc: 0.2228 1s - los\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4104 - acc: 0.2236\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4097 - acc: 0.2240\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4072 - acc: 0.2245\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4067 - acc: 0.2249\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4054 - acc: 0.2252\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4037 - acc: 0.2258\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4062 - acc: 0.2248 1s - loss:\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4027 - acc: 0.2262 2s - loss: 0.40 - ETA: 1s - loss: 0.4007 - acc: 0.2 - ETA: 1s\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4012 - acc: 0.2268\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3994 - acc: 0.2272 0s - loss: 0.4010 - acc:\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4003 - acc: 0.2266\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3983 - acc: 0.2276\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3974 - acc: 0.2277\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3954 - acc: 0.2284\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3945 - acc: 0.2287\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3951 - acc: 0.2284\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3929 - acc: 0.2293\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3920 - acc: 0.2296\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3923 - acc: 0.2294 0s - loss: 0.3883 - acc\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3915 - acc: 0.2297\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 4s 3ms/sample - loss: 0.3895 - acc: 0.2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1202\n",
      "           1       0.57      0.64      0.60     21710\n",
      "           2       0.23      0.03      0.06      3747\n",
      "           3       0.64      0.83      0.72     32594\n",
      "           4       0.31      0.04      0.08       689\n",
      "           5       0.44      0.48      0.46     20535\n",
      "           6       0.34      0.05      0.08      8943\n",
      "           7       0.38      0.32      0.35     11541\n",
      "\n",
      "    accuracy                           0.55    100961\n",
      "   macro avg       0.36      0.30      0.29    100961\n",
      "weighted avg       0.50      0.55      0.51    100961\n",
      "\n",
      "Acur√°cia\n",
      "0.30011002155617916\n",
      "Precisao\n",
      "0.5026694972178551\n",
      "Recall\n",
      "0.546121769792296\n",
      "F1\n",
      "0.5061705274117002\n",
      "[[    0   349     8   261     0   467    20    97]\n",
      " [    0 13868    61  3597     7  3172   107   898]\n",
      " [    0   580   130  1455     8   927    48   599]\n",
      " [    0  2188    97 27036    39  2058    71  1105]\n",
      " [    0    83     4   498    31    47     2    24]\n",
      " [    0  4135    83  4138     7  9926   335  1911]\n",
      " [    0  1485    64  1900     3  3556   410  1525]\n",
      " [    0  1452   109  3439     5  2590   210  3736]]\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_11 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 74,808\n",
      "Trainable params: 74,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acur√°cias total\n",
      "[0.30497768427402544, 0.30149565978010917, 0.3061005963067508, 0.3017751780482968, 0.30011002155617916]\n",
      "0.30289182799307224\n",
      "Precision total\n",
      "[0.5103443556964967, 0.5126510449085298, 0.5153678307605626, 0.5065077357838685, 0.5026694972178551]\n",
      "0.5095080928734624\n",
      "Recalls total\n",
      "[0.548239321651545, 0.5523115761885491, 0.5489730681622418, 0.542138185953938, 0.546121769792296]\n",
      "0.547556784349714\n",
      "F1 total\n",
      "[0.5119306604085974, 0.515269737091279, 0.514482323407129, 0.5071645936249878, 0.5061705274117002]\n",
      "0.5110035683887386\n",
      "TRAIN: [   0    1    3 ... 1997 1998 1999] TEST: [   2    6   14   21   39   47   54   68   70   72   78   81   89   91\n",
      "   92   93   95   99  100  101  107  117  132  134  138  139  152  153\n",
      "  154  162  163  172  188  189  191  194  201  208  210  211  227  228\n",
      "  230  234  236  241  248  251  252  254  260  262  270  284  288  294\n",
      "  306  307  312  315  319  324  327  329  334  335  341  342  350  364\n",
      "  367  377  381  395  396  401  405  409  421  429  434  448  451  461\n",
      "  467  470  473  474  478  489  491  494  496  499  512  528  529  532\n",
      "  533  538  539  548  553  559  563  567  568  572  584  586  589  590\n",
      "  591  596  606  609  620  621  624  627  628  629  635  636  638  640\n",
      "  652  664  668  670  673  676  681  682  694  702  703  715  716  728\n",
      "  731  736  742  743  753  757  768  778  779  784  791  800  804  808\n",
      "  818  822  825  830  831  832  851  852  853  858  860  861  862  873\n",
      "  875  876  881  886  890  895  899  918  919  923  926  932  938  942\n",
      "  954  964  974  979  981  982  984  985  995 1003 1016 1019 1035 1040\n",
      " 1042 1046 1048 1053 1058 1059 1061 1068 1083 1086 1091 1093 1094 1096\n",
      " 1108 1110 1117 1124 1125 1127 1130 1133 1139 1145 1149 1158 1163 1165\n",
      " 1173 1180 1187 1188 1190 1191 1192 1199 1202 1218 1228 1235 1238 1239\n",
      " 1240 1254 1256 1266 1267 1270 1286 1287 1292 1293 1307 1309 1323 1324\n",
      " 1326 1327 1335 1342 1344 1349 1354 1372 1373 1376 1382 1386 1391 1396\n",
      " 1398 1400 1402 1408 1410 1411 1418 1426 1432 1436 1437 1441 1445 1448\n",
      " 1451 1462 1469 1480 1481 1488 1492 1495 1499 1503 1514 1518 1522 1531\n",
      " 1534 1536 1538 1539 1555 1557 1558 1564 1565 1569 1573 1585 1590 1591\n",
      " 1596 1603 1610 1617 1627 1630 1634 1638 1640 1641 1649 1653 1669 1672\n",
      " 1674 1675 1680 1681 1684 1686 1693 1700 1704 1705 1706 1707 1711 1714\n",
      " 1717 1719 1724 1729 1730 1731 1739 1743 1753 1759 1762 1763 1765 1766\n",
      " 1784 1786 1787 1798 1802 1810 1816 1822 1828 1830 1832 1843 1853 1857\n",
      " 1858 1859 1864 1870 1875 1876 1880 1881 1884 1886 1887 1890 1895 1900\n",
      " 1909 1915 1922 1924 1927 1929 1930 1932 1937 1949 1952 1954 1958 1959\n",
      " 1965 1970 1971 1973 1979 1987 1989 1996]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3654 - acc: 0.8211\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3233 - acc: 0.8519\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3156 - acc: 0.8568\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3129 - acc: 0.8584 1s - los\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3089 - acc: 0.8609\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3068 - acc: 0.8621\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3043 - acc: 0.8637\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3018 - acc: 0.8651\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3010 - acc: 0.8654\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2999 - acc: 0.8656\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3007 - acc: 0.8659\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2989 - acc: 0.8663\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2979 - acc: 0.8673 1s - loss: 0.\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2958 - acc: 0.8682\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2934 - acc: 0.8693\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2921 - acc: 0.8701\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2928 - acc: 0.8698\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2905 - acc: 0.8712 0s - loss: 0.2889 - a\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2879 - acc: 0.8727 0s - loss: 0.2894 - acc: 0.8\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2874 - acc: 0.8731 2s - loss: 0.2899 - - ETA: 1s - \n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2823 - acc: 0.8762\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2800 - acc: 0.8772\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2790 - acc: 0.8776\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2770 - acc: 0.8790 1s - loss: 0.2791 - acc: 0.877 - ETA: 0s - loss: 0.2785\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2755 - acc: 0.8796\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2733 - acc: 0.8807\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2743 - acc: 0.8801 1s - loss\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2723 - acc: 0.8812\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2712 - acc: 0.8818\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2704 - acc: 0.8823\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2693 - acc: 0.8827\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2694 - acc: 0.8827\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2674 - acc: 0.8836\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2675 - acc: 0.8837\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2657 - acc: 0.8844 0s - loss: 0.2649 - acc: 0.88\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2662 - acc: 0.8840\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2669 - acc: 0.8839\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2642 - acc: 0.8851\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2635 - acc: 0.8856\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2620 - acc: 0.8864\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2613 - acc: 0.8867\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2620 - acc: 0.8862\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2611 - acc: 0.8866 1s\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2601 - acc: 0.8873 0s - loss: 0.2595 - acc: 0\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2629 - acc: 0.8855 0s - loss: 0.2629 - acc: 0.88\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2586 - acc: 0.8882\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2579 - acc: 0.8882\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2567 - acc: 0.8887\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2559 - acc: 0.8891\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2556 - acc: 0.8894\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2537 - acc: 0.8903 0s - loss: 0.249\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2544 - acc: 0.8900\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2528 - acc: 0.8908\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2524 - acc: 0.8910\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2515 - acc: 0.8912\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2501 - acc: 0.8918\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2508 - acc: 0.8917\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2490 - acc: 0.8925\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2480 - acc: 0.8930 0s - loss: 0.24\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2472 - acc: 0.8935\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2460 - acc: 0.8940\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2456 - acc: 0.8941\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2442 - acc: 0.8946\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2445 - acc: 0.8945\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2439 - acc: 0.8948\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2425 - acc: 0.8954\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2418 - acc: 0.8960\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2404 - acc: 0.8963\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2396 - acc: 0.8969\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2392 - acc: 0.8970\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2375 - acc: 0.8980\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2372 - acc: 0.8980\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2369 - acc: 0.8979 1s - lo\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2368 - acc: 0.8978\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2347 - acc: 0.8988\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2346 - acc: 0.8991\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2325 - acc: 0.9000\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2320 - acc: 0.9002\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2310 - acc: 0.9004\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2302 - acc: 0.9007\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2295 - acc: 0.9011\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2288 - acc: 0.9015\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2273 - acc: 0.9023\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2275 - acc: 0.9024\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2264 - acc: 0.9028\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2257 - acc: 0.9028\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2239 - acc: 0.9039\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2229 - acc: 0.9044\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2221 - acc: 0.9047\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2217 - acc: 0.9047\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2218 - acc: 0.9046\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2199 - acc: 0.9058\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2205 - acc: 0.9053\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2183 - acc: 0.9063 0s - loss: 0.2183 - ac\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2184 - acc: 0.9062\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2190 - acc: 0.9059\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2160 - acc: 0.9072 2s - lo - ETA: 0s - loss: 0.2153 \n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2150 - acc: 0.9077\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2146 - acc: 0.9080\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2142 - acc: 0.9081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69     41275\n",
      "           1       0.65      0.57      0.61     22382\n",
      "           2       0.73      0.74      0.74     38002\n",
      "\n",
      "    accuracy                           0.69    101659\n",
      "   macro avg       0.68      0.67      0.68    101659\n",
      "weighted avg       0.69      0.69      0.69    101659\n",
      "\n",
      "Acur√°cia\n",
      "0.6738402696371918\n",
      "Precisao\n",
      "0.6895582119388497\n",
      "Recall\n",
      "0.6903471409319392\n",
      "F1\n",
      "0.6892006410460636\n",
      "[[29112  4682  7481]\n",
      " [ 6793 12825  2764]\n",
      " [ 7576  2183 28243]]\n",
      "TRAIN: [   0    1    2 ... 1996 1997 1998] TEST: [   7   11   15   16   18   19   22   29   40   45   49   50   55   58\n",
      "   61   65   66   75   84   86   90   96  102  103  108  116  118  123\n",
      "  128  131  135  136  137  140  145  149  165  169  175  177  180  202\n",
      "  207  213  217  219  229  246  247  249  255  256  259  263  267  269\n",
      "  287  289  290  291  292  299  300  302  308  323  332  345  346  349\n",
      "  352  358  361  366  371  380  386  387  391  392  397  400  415  416\n",
      "  419  428  430  440  449  450  453  456  463  469  475  481  482  485\n",
      "  488  492  497  498  502  503  506  507  514  516  517  524  542  556\n",
      "  561  564  574  575  577  582  595  598  601  610  613  614  622  623\n",
      "  625  626  637  639  646  649  651  654  660  667  669  671  674  675\n",
      "  697  701  704  713  717  726  727  732  734  737  738  745  747  748\n",
      "  749  756  759  761  764  765  770  774  781  782  785  788  793  801\n",
      "  803  812  814  815  819  820  821  826  827  828  854  855  856  857\n",
      "  863  864  867  877  879  892  893  897  900  904  905  910  921  924\n",
      "  930  931  934  937  941  945  949  950  951  960  965  966  967  968\n",
      "  970  971  975  987  988  990  997 1001 1006 1010 1013 1021 1022 1033\n",
      " 1038 1043 1047 1055 1056 1069 1070 1075 1076 1090 1097 1101 1109 1119\n",
      " 1121 1126 1128 1129 1132 1134 1151 1154 1176 1183 1185 1194 1197 1203\n",
      " 1209 1211 1219 1220 1222 1225 1227 1232 1241 1248 1249 1255 1263 1265\n",
      " 1280 1281 1296 1299 1314 1325 1338 1343 1353 1356 1366 1367 1369 1374\n",
      " 1377 1380 1387 1393 1394 1397 1399 1413 1416 1419 1430 1433 1438 1446\n",
      " 1449 1454 1467 1472 1473 1484 1486 1487 1489 1491 1493 1496 1502 1506\n",
      " 1510 1515 1516 1521 1525 1533 1537 1542 1543 1553 1554 1562 1563 1567\n",
      " 1571 1576 1587 1588 1592 1594 1599 1604 1606 1609 1613 1633 1635 1636\n",
      " 1643 1647 1648 1652 1661 1671 1679 1682 1691 1692 1694 1696 1699 1710\n",
      " 1716 1722 1728 1734 1735 1740 1741 1749 1750 1754 1758 1770 1775 1791\n",
      " 1792 1794 1800 1811 1814 1818 1824 1831 1833 1839 1844 1845 1846 1847\n",
      " 1852 1854 1855 1868 1872 1882 1914 1919 1921 1923 1935 1938 1939 1962\n",
      " 1963 1977 1980 1981 1982 1990 1995 1999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3593 - acc: 0.7963\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3160 - acc: 0.8550\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3088 - acc: 0.8594\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3065 - acc: 0.8610\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3025 - acc: 0.8626\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3001 - acc: 0.8641\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3007 - acc: 0.8643 1s - \n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2961 - acc: 0.8660\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2942 - acc: 0.8678\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2927 - acc: 0.8681\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2918 - acc: 0.8689\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2909 - acc: 0.8692\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2883 - acc: 0.8706\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2886 - acc: 0.8709\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2878 - acc: 0.8714\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2850 - acc: 0.8726\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2824 - acc: 0.8738\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2805 - acc: 0.8750\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2783 - acc: 0.8765\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2767 - acc: 0.8774\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2744 - acc: 0.8788\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2733 - acc: 0.8796\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2724 - acc: 0.8804\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2720 - acc: 0.8805\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2691 - acc: 0.8820\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2677 - acc: 0.8828\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2668 - acc: 0.8832\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2649 - acc: 0.8841\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2642 - acc: 0.8844\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2639 - acc: 0.8844\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2644 - acc: 0.8845\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2618 - acc: 0.8856\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2627 - acc: 0.8852\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2611 - acc: 0.8860\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2588 - acc: 0.8872\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2590 - acc: 0.8870\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2578 - acc: 0.8875\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2571 - acc: 0.8878\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2567 - acc: 0.8878\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2566 - acc: 0.8881\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2560 - acc: 0.8884\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2547 - acc: 0.8890 1s -\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2540 - acc: 0.8893\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2536 - acc: 0.8895\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2522 - acc: 0.8900 1s\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2518 - acc: 0.8902\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2506 - acc: 0.8908 1s - loss: 0.2502 - - ETA: 0s - loss: 0.2506 - acc: 0\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2497 - acc: 0.8914\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2492 - acc: 0.8917\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2485 - acc: 0.8919\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2480 - acc: 0.8921\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2474 - acc: 0.8926\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2464 - acc: 0.8931\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2469 - acc: 0.8931\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2448 - acc: 0.8939\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2440 - acc: 0.8944\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2431 - acc: 0.8947\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2426 - acc: 0.8951\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2424 - acc: 0.8952\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2403 - acc: 0.8962\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2401 - acc: 0.8962\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2388 - acc: 0.8969\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2384 - acc: 0.8970\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2383 - acc: 0.8972\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2372 - acc: 0.8977\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2360 - acc: 0.8981\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2352 - acc: 0.8987\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2341 - acc: 0.8990\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2331 - acc: 0.8994\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2331 - acc: 0.8994\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2320 - acc: 0.9003\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2307 - acc: 0.9007\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2299 - acc: 0.9008\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2295 - acc: 0.9012\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2290 - acc: 0.9014\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2262 - acc: 0.9028\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2258 - acc: 0.9028\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2252 - acc: 0.9031\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2243 - acc: 0.9032\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2241 - acc: 0.9036\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2252 - acc: 0.9033\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2221 - acc: 0.9044\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2204 - acc: 0.9053\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2200 - acc: 0.9054\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2185 - acc: 0.9059\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2189 - acc: 0.9059\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2175 - acc: 0.9065\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2162 - acc: 0.9068\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2164 - acc: 0.9071\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2145 - acc: 0.9079\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2141 - acc: 0.9079\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2132 - acc: 0.9084\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2126 - acc: 0.9087\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2126 - acc: 0.9089\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2112 - acc: 0.9090\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2099 - acc: 0.9100\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2090 - acc: 0.9100 0s - loss: 0.2091 - acc: 0.909\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2082 - acc: 0.9105\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2072 - acc: 0.9108\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2062 - acc: 0.9113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68     45106\n",
      "           1       0.64      0.53      0.58     24109\n",
      "           2       0.70      0.72      0.71     39812\n",
      "\n",
      "    accuracy                           0.67    109027\n",
      "   macro avg       0.67      0.65      0.66    109027\n",
      "weighted avg       0.67      0.67      0.67    109027\n",
      "\n",
      "Acur√°cia\n",
      "0.6498970169348053\n",
      "Precisao\n",
      "0.6689888931631459\n",
      "Recall\n",
      "0.6698707659570565\n",
      "F1\n",
      "0.6678184817798573\n",
      "[[31723  4693  8690]\n",
      " [ 7798 12759  3552]\n",
      " [ 8875  2385 28552]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   3    4    9   20   24   26   28   35   36   38   46   51   52   60\n",
      "   69   71   76   79   94   98  104  111  119  120  142  151  156  161\n",
      "  164  167  171  182  193  197  199  200  203  216  231  233  243  261\n",
      "  268  275  278  279  280  281  283  293  297  305  310  320  321  326\n",
      "  331  340  344  357  360  365  369  370  376  378  383  385  388  389\n",
      "  393  399  404  407  408  414  418  420  422  423  426  436  439  441\n",
      "  452  454  455  464  466  476  480  483  486  495  500  501  505  508\n",
      "  509  510  518  519  522  526  527  531  536  544  547  551  554  555\n",
      "  560  562  571  579  583  587  592  594  597  607  608  611  612  615\n",
      "  618  630  631  632  642  643  644  645  656  657  659  662  663  666\n",
      "  678  689  692  699  714  720  722  730  755  758  760  766  776  780\n",
      "  789  792  796  809  810  813  816  824  833  836  837  839  841  845\n",
      "  850  865  871  872  878  882  885  889  896  898  901  909  912  913\n",
      "  914  920  922  925  928  944  946  947  948  961  969  972  973  977\n",
      "  980  991  993  994 1000 1018 1020 1026 1028 1032 1039 1044 1045 1052\n",
      " 1066 1073 1074 1077 1081 1082 1085 1087 1088 1089 1095 1098 1103 1105\n",
      " 1106 1107 1111 1112 1113 1115 1116 1136 1140 1142 1144 1147 1150 1161\n",
      " 1169 1172 1175 1178 1182 1200 1201 1205 1216 1217 1229 1236 1245 1253\n",
      " 1257 1258 1262 1269 1282 1284 1285 1290 1294 1298 1306 1310 1312 1313\n",
      " 1316 1321 1322 1330 1331 1332 1336 1340 1348 1351 1358 1359 1361 1362\n",
      " 1368 1370 1371 1378 1388 1389 1390 1392 1395 1403 1409 1415 1424 1427\n",
      " 1439 1447 1452 1453 1456 1458 1460 1464 1477 1478 1494 1497 1498 1505\n",
      " 1507 1509 1512 1517 1520 1527 1529 1530 1541 1552 1561 1566 1574 1575\n",
      " 1579 1581 1583 1584 1597 1600 1601 1602 1605 1608 1615 1618 1620 1622\n",
      " 1624 1625 1626 1656 1662 1668 1683 1697 1702 1703 1720 1723 1737 1738\n",
      " 1742 1746 1751 1752 1771 1772 1773 1781 1783 1793 1799 1803 1807 1808\n",
      " 1812 1813 1820 1823 1827 1834 1835 1837 1838 1865 1879 1885 1889 1897\n",
      " 1899 1901 1905 1907 1908 1912 1918 1926 1933 1934 1936 1942 1943 1967\n",
      " 1968 1972 1978 1983 1984 1986 1992 1994]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3647 - acc: 0.8210\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3210 - acc: 0.8528\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3140 - acc: 0.8575\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3098 - acc: 0.8602\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3062 - acc: 0.8625\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3056 - acc: 0.8627\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3024 - acc: 0.8649\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3016 - acc: 0.8650\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2992 - acc: 0.8668\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2974 - acc: 0.8675\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2969 - acc: 0.8679\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2943 - acc: 0.8692\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2941 - acc: 0.8694\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2927 - acc: 0.8702\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2927 - acc: 0.8702\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2910 - acc: 0.8709 1s - loss: \n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2901 - acc: 0.8716\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2876 - acc: 0.8729\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2855 - acc: 0.8743\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2827 - acc: 0.8756\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2807 - acc: 0.8765\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2795 - acc: 0.8773\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2773 - acc: 0.8783\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2751 - acc: 0.8797\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2736 - acc: 0.8803\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2722 - acc: 0.8809\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2737 - acc: 0.8801\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2712 - acc: 0.8812\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2706 - acc: 0.8819\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2685 - acc: 0.8827\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2682 - acc: 0.8828\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2673 - acc: 0.8832\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2663 - acc: 0.8838\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2662 - acc: 0.8839\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2650 - acc: 0.8844\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2640 - acc: 0.8847\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2635 - acc: 0.8852\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2635 - acc: 0.8849\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2627 - acc: 0.8856\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2613 - acc: 0.8860\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2607 - acc: 0.8865\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2606 - acc: 0.8864\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2591 - acc: 0.8872\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2588 - acc: 0.8874\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2578 - acc: 0.8878\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2577 - acc: 0.8880\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2574 - acc: 0.8879\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2561 - acc: 0.8887\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2554 - acc: 0.8892\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2550 - acc: 0.8893\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2549 - acc: 0.8890\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2535 - acc: 0.8902\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2516 - acc: 0.8911\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 4s 3ms/sample - loss: 0.2520 - acc: 0.8908\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2519 - acc: 0.8909\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2502 - acc: 0.8917\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2501 - acc: 0.8919 1s\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2485 - acc: 0.8927\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2475 - acc: 0.8931\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2465 - acc: 0.8936\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2463 - acc: 0.8939\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2450 - acc: 0.8941\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2442 - acc: 0.8947\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2436 - acc: 0.8951\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2433 - acc: 0.8953\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2432 - acc: 0.8953\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2419 - acc: 0.8960\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2415 - acc: 0.8959\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2400 - acc: 0.8970\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2397 - acc: 0.8968\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2377 - acc: 0.8981\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2371 - acc: 0.8983\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2362 - acc: 0.8987\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2352 - acc: 0.8990\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2347 - acc: 0.8995\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2335 - acc: 0.9001\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2325 - acc: 0.9007\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2317 - acc: 0.9008\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2306 - acc: 0.9012\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2301 - acc: 0.9015\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2298 - acc: 0.9016\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2299 - acc: 0.9016\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2279 - acc: 0.9025\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2257 - acc: 0.9035\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2261 - acc: 0.9034\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2243 - acc: 0.9042\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2243 - acc: 0.9044\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2226 - acc: 0.9052\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2222 - acc: 0.9053\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2218 - acc: 0.9055\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2225 - acc: 0.9052\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2191 - acc: 0.9065\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2185 - acc: 0.9067\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2173 - acc: 0.9073\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2164 - acc: 0.9078\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2171 - acc: 0.9075\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2157 - acc: 0.9083\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2139 - acc: 0.9092\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2138 - acc: 0.9090\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2140 - acc: 0.9090\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69     43070\n",
      "           1       0.66      0.53      0.59     23027\n",
      "           2       0.71      0.76      0.73     38115\n",
      "\n",
      "    accuracy                           0.68    104212\n",
      "   macro avg       0.68      0.66      0.67    104212\n",
      "weighted avg       0.68      0.68      0.68    104212\n",
      "\n",
      "Acur√°cia\n",
      "0.6640544256228496\n",
      "Precisao\n",
      "0.6835225598777734\n",
      "Recall\n",
      "0.6849786972709477\n",
      "F1\n",
      "0.6823857269560915\n",
      "[[30308  4528  8234]\n",
      " [ 7376 12263  3388]\n",
      " [ 7472  1831 28812]]\n",
      "TRAIN: [   2    3    4 ... 1996 1997 1999] TEST: [   0    1    5   13   17   31   33   34   37   41   43   48   56   57\n",
      "   73   74   77   80   82   85   97  105  110  114  115  122  126  130\n",
      "  143  148  150  155  158  159  160  166  168  173  174  178  181  183\n",
      "  185  186  190  192  198  204  205  206  209  220  222  224  225  226\n",
      "  232  238  239  242  244  245  257  264  272  285  286  295  296  298\n",
      "  301  304  309  311  316  336  338  343  347  348  353  354  355  359\n",
      "  363  368  372  379  384  402  403  412  417  427  431  435  442  443\n",
      "  445  446  447  457  458  459  462  465  471  477  484  520  523  534\n",
      "  535  540  543  545  546  549  557  570  573  578  580  581  585  599\n",
      "  600  602  604  616  633  650  653  655  658  685  686  687  691  696\n",
      "  698  706  708  710  718  723  724  725  739  740  741  750  752  762\n",
      "  767  772  773  777  786  790  794  797  799  802  805  806  807  823\n",
      "  834  843  846  849  866  870  874  880  883  887  888  894  903  906\n",
      "  907  908  911  929  936  939  943  957  958  959  962  976  978  986\n",
      "  992  996  999 1017 1023 1024 1025 1027 1029 1030 1031 1034 1049 1051\n",
      " 1054 1057 1060 1062 1063 1065 1071 1072 1079 1080 1099 1100 1114 1123\n",
      " 1135 1138 1143 1155 1156 1157 1159 1162 1164 1171 1195 1198 1207 1213\n",
      " 1215 1226 1231 1233 1242 1244 1246 1251 1259 1260 1272 1273 1275 1277\n",
      " 1278 1283 1288 1297 1300 1301 1302 1303 1304 1305 1311 1317 1318 1319\n",
      " 1337 1341 1345 1346 1352 1360 1363 1364 1381 1383 1384 1401 1404 1406\n",
      " 1414 1422 1428 1429 1431 1434 1440 1443 1444 1455 1457 1459 1463 1466\n",
      " 1468 1470 1474 1475 1476 1482 1483 1485 1490 1504 1511 1513 1524 1544\n",
      " 1548 1549 1550 1551 1568 1570 1572 1577 1580 1586 1589 1595 1598 1607\n",
      " 1611 1616 1619 1621 1628 1629 1631 1639 1646 1651 1654 1657 1664 1665\n",
      " 1667 1670 1673 1677 1685 1695 1698 1708 1713 1718 1726 1732 1736 1747\n",
      " 1748 1760 1761 1767 1769 1776 1778 1780 1782 1785 1788 1790 1796 1806\n",
      " 1825 1826 1836 1841 1842 1849 1850 1856 1861 1862 1863 1866 1871 1873\n",
      " 1878 1891 1893 1894 1904 1906 1913 1944 1947 1948 1950 1951 1953 1957\n",
      " 1960 1961 1974 1975 1988 1991 1993 1998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3617 - acc: 0.8270\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3216 - acc: 0.8531\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3149 - acc: 0.8574\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3113 - acc: 0.8598\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3082 - acc: 0.8616\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3066 - acc: 0.8626\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3040 - acc: 0.8637\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3034 - acc: 0.8647\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3008 - acc: 0.8664\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2985 - acc: 0.8670\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2985 - acc: 0.8673\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2954 - acc: 0.8690\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2934 - acc: 0.8697\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2934 - acc: 0.8699\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2912 - acc: 0.8714\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2895 - acc: 0.8723\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2861 - acc: 0.8739\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2851 - acc: 0.8746\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2827 - acc: 0.8760\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2810 - acc: 0.8768\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2799 - acc: 0.8776\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2777 - acc: 0.8786\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2774 - acc: 0.8789\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2765 - acc: 0.8791 1s - loss: 0.\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2741 - acc: 0.8804\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2749 - acc: 0.8801\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2717 - acc: 0.8817\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2705 - acc: 0.8821\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2694 - acc: 0.8827\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2687 - acc: 0.8831\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2682 - acc: 0.8832\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2665 - acc: 0.8842\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2662 - acc: 0.8841\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2659 - acc: 0.8844\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2651 - acc: 0.8848\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2652 - acc: 0.8846 0s - loss: 0.2655 - acc: 0\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2644 - acc: 0.8852\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2624 - acc: 0.8864\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2620 - acc: 0.8864\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2615 - acc: 0.8866\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2618 - acc: 0.8863\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2597 - acc: 0.8878\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2601 - acc: 0.8874\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2582 - acc: 0.8882\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2585 - acc: 0.8881\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2576 - acc: 0.8886\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2576 - acc: 0.8887\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2559 - acc: 0.8895\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2555 - acc: 0.8895\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2546 - acc: 0.8901\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2534 - acc: 0.8907\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2531 - acc: 0.8908\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2527 - acc: 0.8909\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2517 - acc: 0.8915\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2520 - acc: 0.8912\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2505 - acc: 0.8918\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2490 - acc: 0.8929\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2483 - acc: 0.8929\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2478 - acc: 0.8931\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2465 - acc: 0.8938\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2466 - acc: 0.8939\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2468 - acc: 0.8939\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2447 - acc: 0.8948\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2437 - acc: 0.8952\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2428 - acc: 0.8955\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2422 - acc: 0.8957\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2406 - acc: 0.8965\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2400 - acc: 0.8967\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2392 - acc: 0.8973\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2382 - acc: 0.8978\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2374 - acc: 0.8981\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2364 - acc: 0.8983\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2363 - acc: 0.8987\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2348 - acc: 0.8993\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2344 - acc: 0.8998\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2345 - acc: 0.8994\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2330 - acc: 0.9002\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2320 - acc: 0.9006\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2300 - acc: 0.9016 1s - \n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2305 - acc: 0.9013\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2303 - acc: 0.9014\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2280 - acc: 0.9026\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2275 - acc: 0.9027\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2264 - acc: 0.9032\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2251 - acc: 0.9038\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2245 - acc: 0.9042\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2243 - acc: 0.9039\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2243 - acc: 0.9044\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2220 - acc: 0.9052\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2214 - acc: 0.9055\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2204 - acc: 0.9058\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2206 - acc: 0.9058\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2193 - acc: 0.9064\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2186 - acc: 0.9069 0s - loss: 0.2158 - acc:\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2176 - acc: 0.9072\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2168 - acc: 0.9077\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2162 - acc: 0.9079\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2149 - acc: 0.9086\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2165 - acc: 0.9077\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2284 - acc: 0.9022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.69     41854\n",
      "           1       0.68      0.53      0.59     23614\n",
      "           2       0.70      0.74      0.72     36692\n",
      "\n",
      "    accuracy                           0.68    102160\n",
      "   macro avg       0.68      0.66      0.67    102160\n",
      "weighted avg       0.68      0.68      0.68    102160\n",
      "\n",
      "Acur√°cia\n",
      "0.659925548401875\n",
      "Precisao\n",
      "0.6798842758876843\n",
      "Recall\n",
      "0.679600626468285\n",
      "F1\n",
      "0.676919795809103\n",
      "[[29883  4065  7906]\n",
      " [ 7621 12458  3535]\n",
      " [ 7809  1796 27087]]\n",
      "TRAIN: [   0    1    2 ... 1996 1998 1999] TEST: [   8   10   12   23   25   27   30   32   42   44   53   59   62   63\n",
      "   64   67   83   87   88  106  109  112  113  121  124  125  127  129\n",
      "  133  141  144  146  147  157  170  176  179  184  187  195  196  212\n",
      "  214  215  218  221  223  235  237  240  250  253  258  265  266  271\n",
      "  273  274  276  277  282  303  313  314  317  318  322  325  328  330\n",
      "  333  337  339  351  356  362  373  374  375  382  390  394  398  406\n",
      "  410  411  413  424  425  432  433  437  438  444  460  468  472  479\n",
      "  487  490  493  504  511  513  515  521  525  530  537  541  550  552\n",
      "  558  565  566  569  576  588  593  603  605  617  619  634  641  647\n",
      "  648  661  665  672  677  679  680  683  684  688  690  693  695  700\n",
      "  705  707  709  711  712  719  721  729  733  735  744  746  751  754\n",
      "  763  769  771  775  783  787  795  798  811  817  829  835  838  840\n",
      "  842  844  847  848  859  868  869  884  891  902  915  916  917  927\n",
      "  933  935  940  952  953  955  956  963  983  989  998 1002 1004 1005\n",
      " 1007 1008 1009 1011 1012 1014 1015 1036 1037 1041 1050 1064 1067 1078\n",
      " 1084 1092 1102 1104 1118 1120 1122 1131 1137 1141 1146 1148 1152 1153\n",
      " 1160 1166 1167 1168 1170 1174 1177 1179 1181 1184 1186 1189 1193 1196\n",
      " 1204 1206 1208 1210 1212 1214 1221 1223 1224 1230 1234 1237 1243 1247\n",
      " 1250 1252 1261 1264 1268 1271 1274 1276 1279 1289 1291 1295 1308 1315\n",
      " 1320 1328 1329 1333 1334 1339 1347 1350 1355 1357 1365 1375 1379 1385\n",
      " 1405 1407 1412 1417 1420 1421 1423 1425 1435 1442 1450 1461 1465 1471\n",
      " 1479 1500 1501 1508 1519 1523 1526 1528 1532 1535 1540 1545 1546 1547\n",
      " 1556 1559 1560 1578 1582 1593 1612 1614 1623 1632 1637 1642 1644 1645\n",
      " 1650 1655 1658 1659 1660 1663 1666 1676 1678 1687 1688 1689 1690 1701\n",
      " 1709 1712 1715 1721 1725 1727 1733 1744 1745 1755 1756 1757 1764 1768\n",
      " 1774 1777 1779 1789 1795 1797 1801 1804 1805 1809 1815 1817 1819 1821\n",
      " 1829 1840 1848 1851 1860 1867 1869 1874 1877 1883 1888 1892 1896 1898\n",
      " 1902 1903 1910 1911 1916 1917 1920 1925 1928 1931 1940 1941 1945 1946\n",
      " 1955 1956 1964 1966 1969 1976 1985 1997]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3694 - acc: 0.8173\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3263 - acc: 0.8504\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3190 - acc: 0.8549\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3146 - acc: 0.8573\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3116 - acc: 0.8589\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3110 - acc: 0.8603\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.3081 - acc: 0.8617\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3073 - acc: 0.8621\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3059 - acc: 0.8625\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3038 - acc: 0.8641\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3026 - acc: 0.8645\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3018 - acc: 0.8650\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3012 - acc: 0.8658\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2995 - acc: 0.8664\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2985 - acc: 0.8672\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2953 - acc: 0.8687\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2953 - acc: 0.8690\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2956 - acc: 0.8690\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2915 - acc: 0.8711\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2916 - acc: 0.8710\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2887 - acc: 0.8727\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2856 - acc: 0.8744\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2823 - acc: 0.8759\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2814 - acc: 0.8770\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2789 - acc: 0.8777\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2771 - acc: 0.8788\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2767 - acc: 0.8792\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2749 - acc: 0.8798\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2745 - acc: 0.8802\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2729 - acc: 0.8807\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2733 - acc: 0.8806 0s - loss: 0.2754 - acc: 0.87\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2728 - acc: 0.8809\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2704 - acc: 0.8820\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2687 - acc: 0.8831\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2687 - acc: 0.8830\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2680 - acc: 0.8833\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2673 - acc: 0.8837\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2661 - acc: 0.8844\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2659 - acc: 0.8842\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2654 - acc: 0.8848\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2659 - acc: 0.8845\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2641 - acc: 0.8853\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2630 - acc: 0.8859\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2621 - acc: 0.8863\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2621 - acc: 0.8865\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2605 - acc: 0.8872\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2592 - acc: 0.8880\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2601 - acc: 0.8872\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2583 - acc: 0.8881\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2573 - acc: 0.8886\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2570 - acc: 0.8885\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2560 - acc: 0.8893\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2552 - acc: 0.8898\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2558 - acc: 0.8893\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2541 - acc: 0.8902\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2540 - acc: 0.8902\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2524 - acc: 0.8910\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2523 - acc: 0.8912\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2514 - acc: 0.8915\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2500 - acc: 0.8921\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2490 - acc: 0.8926\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2491 - acc: 0.8924\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2484 - acc: 0.8928\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2473 - acc: 0.8931\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2470 - acc: 0.8936\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2454 - acc: 0.8943\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2444 - acc: 0.8948\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2435 - acc: 0.8951\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2428 - acc: 0.8955\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2422 - acc: 0.8960\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2417 - acc: 0.8959\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2401 - acc: 0.8968\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2390 - acc: 0.8974\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2384 - acc: 0.8975\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2381 - acc: 0.8980\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2380 - acc: 0.8978\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2372 - acc: 0.8980\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2352 - acc: 0.8990\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2351 - acc: 0.8990\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2333 - acc: 0.8999\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2326 - acc: 0.9003\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2320 - acc: 0.9003\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2307 - acc: 0.9012\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2301 - acc: 0.9015\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2294 - acc: 0.9020\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2283 - acc: 0.9024\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2273 - acc: 0.9027\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2281 - acc: 0.9023\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2269 - acc: 0.9031 1s - \n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2247 - acc: 0.9040\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2260 - acc: 0.9032\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2235 - acc: 0.9045\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2221 - acc: 0.9053\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2217 - acc: 0.9056\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2213 - acc: 0.9056\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2201 - acc: 0.9062\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2195 - acc: 0.9064\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2181 - acc: 0.9072\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.2180 - acc: 0.9069\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.2167 - acc: 0.9078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69     40293\n",
      "           1       0.66      0.57      0.61     22064\n",
      "           2       0.72      0.75      0.73     36393\n",
      "\n",
      "    accuracy                           0.69     98750\n",
      "   macro avg       0.68      0.67      0.68     98750\n",
      "weighted avg       0.69      0.69      0.69     98750\n",
      "\n",
      "Acur√°cia\n",
      "0.6705714837414837\n",
      "Precisao\n",
      "0.6857671329768725\n",
      "Recall\n",
      "0.6868962025316455\n",
      "F1\n",
      "0.6853645038522663\n",
      "[[28172  4391  7730]\n",
      " [ 6685 12485  2894]\n",
      " [ 7089  2130 27174]]\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_16 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 700, 3)            603       \n",
      "=================================================================\n",
      "Total params: 73,803\n",
      "Trainable params: 73,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acur√°cias total\n",
      "[0.6738402696371918, 0.6498970169348053, 0.6640544256228496, 0.659925548401875, 0.6705714837414837]\n",
      "0.6636577488676411\n",
      "Precision total\n",
      "[0.6895582119388497, 0.6689888931631459, 0.6835225598777734, 0.6798842758876843, 0.6857671329768725]\n",
      "0.6815442147688652\n",
      "Recalls total\n",
      "[0.6903471409319392, 0.6698707659570565, 0.6849786972709477, 0.679600626468285, 0.6868962025316455]\n",
      "0.6823386866319747\n",
      "F1 total\n",
      "[0.6892006410460636, 0.6678184817798573, 0.6823857269560915, 0.676919795809103, 0.6853645038522663]\n",
      "0.6803378298886763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(8)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ8[train_index],\n",
    "                           previsores[test_index], classesQ8[test_index], 8)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(3)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ3[train_index],\n",
    "                           previsores[test_index], classesQ3[test_index], 3)\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
