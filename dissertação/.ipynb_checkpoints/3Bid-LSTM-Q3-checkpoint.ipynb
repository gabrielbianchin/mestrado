{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 28:31].values\n",
    "classes = np.reshape(classes, (2000, 700, 3))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(LSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn = criarRede, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 50, verbose = 1, batch_size = 32)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 3))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 3))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "previsores_trei_vald, previsores_testes, classes_trei_vald, classes_testes = train_test_split(previsores, classes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 142s 111ms/step - loss: 0.9902 - acc: 0.5154\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 142s 111ms/step - loss: 0.8867 - acc: 0.5930\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 135s 105ms/step - loss: 0.8542 - acc: 0.6157\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 145s 113ms/step - loss: 0.8366 - acc: 0.6237\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 222s 174ms/step - loss: 0.8253 - acc: 0.6311\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.8166 - acc: 0.6366\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.8082 - acc: 0.6398\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.8040 - acc: 0.6423\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.7970 - acc: 0.6458\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 203s 159ms/step - loss: 0.7890 - acc: 0.6499\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 248s 193ms/step - loss: 0.7832 - acc: 0.6527\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 248s 193ms/step - loss: 0.7771 - acc: 0.6569\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.7751 - acc: 0.6581\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7741 - acc: 0.6584\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.7717 - acc: 0.6591\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.7676 - acc: 0.6621\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7655 - acc: 0.6628\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.7567 - acc: 0.6670\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.7539 - acc: 0.6687\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.7536 - acc: 0.6695\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7450 - acc: 0.6728\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 243s 189ms/step - loss: 0.7405 - acc: 0.6758\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7443 - acc: 0.6733\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 242s 189ms/step - loss: 0.7394 - acc: 0.6756\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7382 - acc: 0.6767\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.7310 - acc: 0.6801\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7274 - acc: 0.6821\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.7373 - acc: 0.6760\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7716 - acc: 0.6601\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.7715 - acc: 0.6591\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.7419 - acc: 0.6748\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.7376 - acc: 0.6774\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.7249 - acc: 0.6832\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7180 - acc: 0.6869\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.7168 - acc: 0.6876\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.7074 - acc: 0.6922\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.6998 - acc: 0.6955\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.6986 - acc: 0.6968\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.6921 - acc: 0.6993\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.6846 - acc: 0.7023\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.6746 - acc: 0.7079\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.6712 - acc: 0.7092\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.6671 - acc: 0.7108\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.6626 - acc: 0.7135\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 242s 189ms/step - loss: 0.6538 - acc: 0.7174\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.6547 - acc: 0.7176\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.6447 - acc: 0.7207\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.6386 - acc: 0.7247\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.6310 - acc: 0.7284\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.6316 - acc: 0.7274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69     32952\n",
      "           1       0.62      0.55      0.58     17321\n",
      "           2       0.73      0.65      0.69     29872\n",
      "\n",
      "    accuracy                           0.67     80145\n",
      "   macro avg       0.66      0.65      0.65     80145\n",
      "weighted avg       0.67      0.67      0.66     80145\n",
      "\n",
      "Acur√°cia\n",
      "0.6473946667363092\n",
      "Precisao\n",
      "0.6690809453328159\n",
      "Recall\n",
      "0.6662549129702414\n",
      "F1\n",
      "0.6649989207643964\n",
      "[[24399  3577  4976]\n",
      " [ 5516  9523  2282]\n",
      " [ 8095  2302 19475]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.6741 - acc: 0.7102\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 248s 194ms/step - loss: 0.6704 - acc: 0.7111\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.6650 - acc: 0.7135\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.6499 - acc: 0.7193\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.6405 - acc: 0.7244\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.6368 - acc: 0.7254\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 249s 195ms/step - loss: 0.6331 - acc: 0.7266\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 249s 195ms/step - loss: 0.6267 - acc: 0.7307\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.6210 - acc: 0.7329\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.6246 - acc: 0.7305\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 246s 193ms/step - loss: 0.6087 - acc: 0.7376\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.6002 - acc: 0.7423\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.5943 - acc: 0.7448\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.5904 - acc: 0.7465\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.5900 - acc: 0.7475\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.5801 - acc: 0.7514\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5727 - acc: 0.7545\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5680 - acc: 0.7573\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.5661 - acc: 0.7588\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.5627 - acc: 0.7601\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.5613 - acc: 0.7603\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.5612 - acc: 0.7601\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5522 - acc: 0.7639\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.5516 - acc: 0.7641\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.5480 - acc: 0.7664\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.5415 - acc: 0.7687\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.5369 - acc: 0.7708\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5548 - acc: 0.7633\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5511 - acc: 0.7642\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5326 - acc: 0.7727\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5252 - acc: 0.7759\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.5186 - acc: 0.7787\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.5166 - acc: 0.7796\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5171 - acc: 0.7802\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.5105 - acc: 0.7821\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5043 - acc: 0.7852\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.4997 - acc: 0.7867\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.4996 - acc: 0.7870\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 248s 194ms/step - loss: 0.4990 - acc: 0.7879\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.4881 - acc: 0.7925\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.4864 - acc: 0.7937\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4864 - acc: 0.7942\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4834 - acc: 0.7947\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 246s 193ms/step - loss: 0.4845 - acc: 0.7937\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4840 - acc: 0.7947\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.4747 - acc: 0.7978\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4731 - acc: 0.7991\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.4697 - acc: 0.8009\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4668 - acc: 0.8021\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4631 - acc: 0.8043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70     33716\n",
      "           1       0.69      0.57      0.63     18212\n",
      "           2       0.75      0.76      0.75     30707\n",
      "\n",
      "    accuracy                           0.71     82635\n",
      "   macro avg       0.71      0.69      0.70     82635\n",
      "weighted avg       0.71      0.71      0.71     82635\n",
      "\n",
      "Acur√°cia\n",
      "0.6882602757284172\n",
      "Precisao\n",
      "0.7070986126428073\n",
      "Recall\n",
      "0.70691595570884\n",
      "F1\n",
      "0.7053501118078253\n",
      "[[24592  3308  5816]\n",
      " [ 5659 10468  2085]\n",
      " [ 6053  1298 23356]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5566 - acc: 0.7678\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 248s 193ms/step - loss: 0.5389 - acc: 0.7734\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 248s 194ms/step - loss: 0.5288 - acc: 0.7776\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.5114 - acc: 0.7844\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.5037 - acc: 0.7871\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4986 - acc: 0.7897\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4946 - acc: 0.7919\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4890 - acc: 0.7937\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4872 - acc: 0.7942\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4863 - acc: 0.7947\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4785 - acc: 0.7986\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4752 - acc: 0.7988\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.4764 - acc: 0.7986\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4707 - acc: 0.8026\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4656 - acc: 0.8038\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4593 - acc: 0.8063\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.4566 - acc: 0.8075\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.4560 - acc: 0.8076\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4498 - acc: 0.8103\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4506 - acc: 0.8096\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4465 - acc: 0.8113\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 246s 193ms/step - loss: 0.4389 - acc: 0.8151\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4431 - acc: 0.8127\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4354 - acc: 0.8162\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4389 - acc: 0.8148\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.4331 - acc: 0.8169\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 248s 194ms/step - loss: 0.4254 - acc: 0.8203\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4257 - acc: 0.8204\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.4253 - acc: 0.8201\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.4263 - acc: 0.8210\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.4288 - acc: 0.8188\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.4225 - acc: 0.8217\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4211 - acc: 0.8223\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.4110 - acc: 0.8269\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4130 - acc: 0.8263\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4098 - acc: 0.8275\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 250s 195ms/step - loss: 0.4087 - acc: 0.8278\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4061 - acc: 0.8298\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.4078 - acc: 0.8284\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4036 - acc: 0.8299\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4031 - acc: 0.8307\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4135 - acc: 0.8253\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 250s 195ms/step - loss: 0.4029 - acc: 0.8305\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.3953 - acc: 0.8335\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3909 - acc: 0.8352\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.3912 - acc: 0.8352\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.3933 - acc: 0.8342\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.3901 - acc: 0.8362\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3883 - acc: 0.8369\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.3866 - acc: 0.8379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75     34923\n",
      "           1       0.76      0.65      0.70     17914\n",
      "           2       0.82      0.82      0.82     32102\n",
      "\n",
      "    accuracy                           0.77     84939\n",
      "   macro avg       0.77      0.75      0.76     84939\n",
      "weighted avg       0.77      0.77      0.77     84939\n",
      "\n",
      "Acur√°cia\n",
      "0.7490641663703226\n",
      "Precisao\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7676551666584432\n",
      "Recall\n",
      "0.7666442976724472\n",
      "F1\n",
      "0.7658850092897471\n",
      "[[27068  3131  4724]\n",
      " [ 5288 11626  1000]\n",
      " [ 5095   583 26424]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4817 - acc: 0.8011\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4541 - acc: 0.8103\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.4369 - acc: 0.8166\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 249s 194ms/step - loss: 0.4236 - acc: 0.8222\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.4171 - acc: 0.8251\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4126 - acc: 0.8267\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4108 - acc: 0.8279\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4098 - acc: 0.8283\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.4130 - acc: 0.8266\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.4139 - acc: 0.8267\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.4050 - acc: 0.8306\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3953 - acc: 0.8350\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.3952 - acc: 0.8346\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.3921 - acc: 0.8349\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 254s 198ms/step - loss: 0.4103 - acc: 0.8274\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3919 - acc: 0.8360\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.3849 - acc: 0.8390\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3831 - acc: 0.8396\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3787 - acc: 0.8420\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.3753 - acc: 0.8430\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3751 - acc: 0.8432\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3741 - acc: 0.8433\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3738 - acc: 0.8435\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3741 - acc: 0.8439\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 254s 198ms/step - loss: 0.3788 - acc: 0.8413\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3689 - acc: 0.8461\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.3703 - acc: 0.8457\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 253s 197ms/step - loss: 0.3681 - acc: 0.8458\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3620 - acc: 0.8494\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3624 - acc: 0.8487\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3620 - acc: 0.8489\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3589 - acc: 0.8506\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3550 - acc: 0.8519\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.3554 - acc: 0.8510\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3567 - acc: 0.8516\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.3533 - acc: 0.8523\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 251s 196ms/step - loss: 0.3528 - acc: 0.8534\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 252s 197ms/step - loss: 0.3502 - acc: 0.8539\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.3491 - acc: 0.8549\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 256s 200ms/step - loss: 0.3458 - acc: 0.8563\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 175s 136ms/step - loss: 0.3503 - acc: 0.8543\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 143s 112ms/step - loss: 0.3755 - acc: 0.8436\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 141s 110ms/step - loss: 0.3632 - acc: 0.8484\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 142s 111ms/step - loss: 0.3507 - acc: 0.8547\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 142s 111ms/step - loss: 0.3418 - acc: 0.8579\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 141s 111ms/step - loss: 0.3410 - acc: 0.8573\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 141s 110ms/step - loss: 0.3381 - acc: 0.8593\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 142s 111ms/step - loss: 0.3375 - acc: 0.8595\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 141s 110ms/step - loss: 0.3344 - acc: 0.8611\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 188s 147ms/step - loss: 0.3342 - acc: 0.8611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79     34375\n",
      "           1       0.80      0.73      0.76     19063\n",
      "           2       0.87      0.84      0.85     28668\n",
      "\n",
      "    accuracy                           0.81     82106\n",
      "   macro avg       0.81      0.80      0.80     82106\n",
      "weighted avg       0.81      0.81      0.81     82106\n",
      "\n",
      "Acur√°cia\n",
      "0.7964158854092279\n",
      "Precisao\n",
      "0.8078801527871436\n",
      "Recall\n",
      "0.8059337929018586\n",
      "F1\n",
      "0.8060095657814925\n",
      "[[28199  3044  3132]\n",
      " [ 4626 13902   535]\n",
      " [ 4155   442 24071]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 273s 213ms/step - loss: 0.3984 - acc: 0.8352\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 250s 196ms/step - loss: 0.3885 - acc: 0.8384\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3824 - acc: 0.8407\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.3737 - acc: 0.8451\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3598 - acc: 0.8502\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3545 - acc: 0.8525\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.3547 - acc: 0.8528\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 248s 194ms/step - loss: 0.3553 - acc: 0.8523\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3489 - acc: 0.8549\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.3502 - acc: 0.8543\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3475 - acc: 0.8559\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3439 - acc: 0.8574\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.3426 - acc: 0.8575\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.3396 - acc: 0.8588\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 248s 194ms/step - loss: 0.3372 - acc: 0.8599\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.3361 - acc: 0.8604\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3336 - acc: 0.8612\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.3349 - acc: 0.8613\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.3323 - acc: 0.8619\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.3318 - acc: 0.8629\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3300 - acc: 0.8634\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3273 - acc: 0.8637\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3269 - acc: 0.8644\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.3256 - acc: 0.8655\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.3229 - acc: 0.8665\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3214 - acc: 0.8676\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3222 - acc: 0.8660\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 246s 193ms/step - loss: 0.3190 - acc: 0.8678\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3194 - acc: 0.8679\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3214 - acc: 0.8672\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.3225 - acc: 0.8662\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 246s 193ms/step - loss: 0.3193 - acc: 0.8677\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3163 - acc: 0.8692\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3186 - acc: 0.8689\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 248s 194ms/step - loss: 0.3121 - acc: 0.8709\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.3121 - acc: 0.8710\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 248s 194ms/step - loss: 0.3109 - acc: 0.8717\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.3066 - acc: 0.8732\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.3082 - acc: 0.8733\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 245s 192ms/step - loss: 0.3079 - acc: 0.8726\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 247s 193ms/step - loss: 0.3096 - acc: 0.8718\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 245s 191ms/step - loss: 0.3043 - acc: 0.8746\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 244s 191ms/step - loss: 0.3031 - acc: 0.8754\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 246s 192ms/step - loss: 0.3042 - acc: 0.8743\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 240s 188ms/step - loss: 0.3035 - acc: 0.8748\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 139s 109ms/step - loss: 0.3035 - acc: 0.8750\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 140s 109ms/step - loss: 0.3013 - acc: 0.8755\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 139s 109ms/step - loss: 0.3033 - acc: 0.8746\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 139s 109ms/step - loss: 0.2999 - acc: 0.8761\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 139s 109ms/step - loss: 0.2971 - acc: 0.8771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81     33727\n",
      "           1       0.84      0.76      0.80     19802\n",
      "           2       0.89      0.88      0.89     29092\n",
      "\n",
      "    accuracy                           0.84     82621\n",
      "   macro avg       0.84      0.83      0.83     82621\n",
      "weighted avg       0.84      0.84      0.84     82621\n",
      "\n",
      "Acur√°cia\n",
      "0.8275798259707511\n",
      "Precisao\n",
      "0.8370266034131235\n",
      "Recall\n",
      "0.8356350080488012\n",
      "F1\n",
      "0.8355449734367949\n",
      "[[28280  2593  2854]\n",
      " [ 4329 15077   396]\n",
      " [ 3181   227 25684]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "model = criarRede()\n",
    "\n",
    "for train_index, test_index in kf.split(previsores_trei_vald):\n",
    "  \n",
    "  train_and_evaluate_model(model, previsores_trei_vald[train_index], classes_trei_vald[train_index],\n",
    "                           previsores_trei_vald[test_index], classes_trei_vald[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_4 (Masking)          (None, 700, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 700, 200)          96800     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 700, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 700, 3)            603       \n",
      "=================================================================\n",
      "Total params: 338,203\n",
      "Trainable params: 338,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cias total\n",
      "[0.503315111011828, 0.5990307849722795, 0.5866511972327715, 0.5952740402931717, 0.6081572812176277, 0.6191726398417333, 0.6473946667363092, 0.6882602757284172, 0.7490641663703226, 0.7964158854092279, 0.8275798259707511]\n",
      "Precision total\n",
      "[0.5739233565567848, 0.6188970090200986, 0.6270047110777255, 0.6315038050600584, 0.6351568842328316, 0.6415376209528113, 0.6690809453328159, 0.7070986126428073, 0.7676551666584432, 0.8078801527871436, 0.8370266034131235]\n",
      "Recalls total\n",
      "[0.5652728791535178, 0.6186420919588186, 0.6260855102937857, 0.6287526892235478, 0.6361455265563115, 0.6416768251388325, 0.6662549129702414, 0.70691595570884, 0.7666442976724472, 0.8059337929018586, 0.8356350080488012]\n",
      "F1 total\n",
      "[0.529087256992765, 0.6165655746411155, 0.616008406576305, 0.6200986419314473, 0.6308283745200992, 0.6390557058419195, 0.6649989207643964, 0.7053501118078253, 0.7658850092897471, 0.8060095657814925, 0.8355449734367949]\n"
     ]
    }
   ],
   "source": [
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "print('F1 total')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 184s 115ms/step - loss: 0.3380 - acc: 0.8615\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3355 - acc: 0.8613\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 175s 109ms/step - loss: 0.3374 - acc: 0.8608\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3255 - acc: 0.8650\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3209 - acc: 0.8676\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3164 - acc: 0.8690\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 175s 109ms/step - loss: 0.3098 - acc: 0.8720\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3159 - acc: 0.8693\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3201 - acc: 0.8669\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3119 - acc: 0.8711\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3090 - acc: 0.8724\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3136 - acc: 0.8709\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3085 - acc: 0.8721\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3067 - acc: 0.8730\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3013 - acc: 0.8757\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3036 - acc: 0.8752\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3041 - acc: 0.8746\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3055 - acc: 0.8742\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 175s 109ms/step - loss: 0.3029 - acc: 0.8752\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3008 - acc: 0.8763\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2992 - acc: 0.8765\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2983 - acc: 0.8769\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 175s 109ms/step - loss: 0.2952 - acc: 0.8784\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2965 - acc: 0.8778\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2998 - acc: 0.8762\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.3004 - acc: 0.8760\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2973 - acc: 0.8769\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2926 - acc: 0.8793\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2940 - acc: 0.8790\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2920 - acc: 0.8799\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2920 - acc: 0.8798\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2898 - acc: 0.8807\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 174s 109ms/step - loss: 0.2889 - acc: 0.8807\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 177s 111ms/step - loss: 0.2886 - acc: 0.8810\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 181s 113ms/step - loss: 0.2880 - acc: 0.8816\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 180s 113ms/step - loss: 0.2863 - acc: 0.8822\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 181s 113ms/step - loss: 0.2849 - acc: 0.8824\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 190s 119ms/step - loss: 0.2851 - acc: 0.8827\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 183s 114ms/step - loss: 0.2826 - acc: 0.8839\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 184s 115ms/step - loss: 0.2839 - acc: 0.8830\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 196s 122ms/step - loss: 0.2851 - acc: 0.8827\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 191s 119ms/step - loss: 0.2858 - acc: 0.8821\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 190s 119ms/step - loss: 0.2862 - acc: 0.8824\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 189s 118ms/step - loss: 0.2855 - acc: 0.8825\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 296s 185ms/step - loss: 0.2844 - acc: 0.8832\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 308s 192ms/step - loss: 0.2825 - acc: 0.8840\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 320s 200ms/step - loss: 0.2809 - acc: 0.8844\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 304s 190ms/step - loss: 0.2800 - acc: 0.8851\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 307s 192ms/step - loss: 0.2781 - acc: 0.8864\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 302s 189ms/step - loss: 0.2776 - acc: 0.8860\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68     41905\n",
      "           1       0.63      0.57      0.60     22884\n",
      "           2       0.72      0.69      0.71     38573\n",
      "\n",
      "    accuracy                           0.67    103362\n",
      "   macro avg       0.67      0.66      0.66    103362\n",
      "weighted avg       0.67      0.67      0.67    103362\n",
      "\n",
      "Acur√°cia\n",
      "0.6588301759778695\n",
      "Precisao\n",
      "0.6744478562038533\n",
      "Recall\n",
      "0.6737001992995492\n",
      "F1\n",
      "0.6730661098262607\n",
      "[[29869  4767  7269]\n",
      " [ 6854 13097  2933]\n",
      " [ 9060  2844 26669]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(model, previsores_trei_vald, classes_trei_vald,\n",
    "                           previsores_testes, classes_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
