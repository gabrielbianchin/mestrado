{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 20:28].values\n",
    "classes = np.reshape(classes, (2000, 700, 8))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    #model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(8, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuq8 = []\n",
    "precisionsq8 = []\n",
    "recallsq8 = []\n",
    "f1q8 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 50, verbose = 1, batch_size = 32)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 8))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 8))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accuq8.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisionsq8.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recallsq8.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1q8.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "previsores_trei_vald, previsores_testes, classes_trei_vald, classes_testes = train_test_split(previsores, classes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 14:42:53.199236 11928 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 14:42:53.212200 11928 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 14:42:53.214196 11928 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 14:42:53.217187 11928 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 14:42:54.811254 11928 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 29s 23ms/sample - loss: 0.6151 - acc: 0.1449\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.5704 - acc: 0.1541\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.5501 - acc: 0.1634\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.5288 - acc: 0.1722\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.5183 - acc: 0.1769\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.5112 - acc: 0.1798\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.5044 - acc: 0.1833\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4999 - acc: 0.1852\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4957 - acc: 0.1867\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4954 - acc: 0.1867\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4911 - acc: 0.1886\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4901 - acc: 0.1892\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.4876 - acc: 0.1902\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4787 - acc: 0.1936\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4788 - acc: 0.1934\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4744 - acc: 0.1951\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4696 - acc: 0.1970\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4661 - acc: 0.1984\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4613 - acc: 0.2003\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4604 - acc: 0.2001\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4545 - acc: 0.2027\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4512 - acc: 0.2039\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.4447 - acc: 0.2060\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4366 - acc: 0.2090\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.4302 - acc: 0.2119\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4266 - acc: 0.2120\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4191 - acc: 0.2148\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4139 - acc: 0.2168\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4076 - acc: 0.2189\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.4019 - acc: 0.2208\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3961 - acc: 0.2226\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3879 - acc: 0.2252\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3822 - acc: 0.2273\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3780 - acc: 0.2283\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3727 - acc: 0.2302\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3665 - acc: 0.2323\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3612 - acc: 0.2339\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3556 - acc: 0.2357\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.3500 - acc: 0.2378\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3454 - acc: 0.2392\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3494 - acc: 0.2375\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3448 - acc: 0.2393\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3339 - acc: 0.2429\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3279 - acc: 0.2450\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.3232 - acc: 0.2466\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3199 - acc: 0.2474\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3190 - acc: 0.2477\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3142 - acc: 0.2490\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3119 - acc: 0.2498\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3082 - acc: 0.2512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1020\n",
      "           1       0.61      0.59      0.60     18140\n",
      "           2       0.30      0.23      0.26      3400\n",
      "           3       0.64      0.78      0.70     26172\n",
      "           4       0.34      0.15      0.21       525\n",
      "           5       0.42      0.52      0.47     17194\n",
      "           6       0.34      0.10      0.15      7565\n",
      "           7       0.40      0.34      0.37      9912\n",
      "\n",
      "    accuracy                           0.54     83928\n",
      "   macro avg       0.51      0.34      0.34     83928\n",
      "weighted avg       0.52      0.54      0.51     83928\n",
      "\n",
      "Acur√°cia\n",
      "0.3379048683428947\n",
      "Precisao\n",
      "0.5213905001483021\n",
      "Recall\n",
      "0.5352683252311505\n",
      "F1\n",
      "0.5124309445024305\n",
      "[[    1   191    30   197     0   457    43   101]\n",
      " [    0 10644   212  3098    14  3294   191   687]\n",
      " [    0   342   799   970     7   845    47   390]\n",
      " [    0  1985   459 20424    90  2030   120  1064]\n",
      " [    0    54     6   314    78    40     3    30]\n",
      " [    0  2487   503  3076    14  8906   618  1590]\n",
      " [    0   920   246  1399    10  3097   727  1166]\n",
      " [    0   908   433  2404    16  2388   418  3345]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3739 - acc: 0.2310\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.3526 - acc: 0.2365\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.3387 - acc: 0.2407\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3326 - acc: 0.2423\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3272 - acc: 0.2438\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.3225 - acc: 0.2449\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3193 - acc: 0.2462\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.3148 - acc: 0.2472\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3090 - acc: 0.2490\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3050 - acc: 0.2501\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.3009 - acc: 0.2515\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2993 - acc: 0.2520\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2970 - acc: 0.2528\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2935 - acc: 0.2539\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2892 - acc: 0.2553\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.2867 - acc: 0.2562\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2842 - acc: 0.2567\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2813 - acc: 0.2577\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2782 - acc: 0.2590\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2765 - acc: 0.2595\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2728 - acc: 0.2609\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2715 - acc: 0.2612\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2696 - acc: 0.2617\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2669 - acc: 0.2626\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2659 - acc: 0.2631\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2640 - acc: 0.2635\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2600 - acc: 0.2648\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2576 - acc: 0.2659\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2573 - acc: 0.2661\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2560 - acc: 0.2662\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2526 - acc: 0.2677\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2520 - acc: 0.2678\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2501 - acc: 0.2686\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2493 - acc: 0.2686\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2488 - acc: 0.2687\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2448 - acc: 0.2706\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2439 - acc: 0.2706\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2425 - acc: 0.2711\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.2419 - acc: 0.2714\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2404 - acc: 0.2720\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2371 - acc: 0.2729\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.2358 - acc: 0.2733\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2352 - acc: 0.2736\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2339 - acc: 0.2744\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2328 - acc: 0.2744\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2309 - acc: 0.2751\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2294 - acc: 0.2760\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2285 - acc: 0.2761\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2276 - acc: 0.2764\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2277 - acc: 0.2767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.04      0.07      1036\n",
      "           1       0.72      0.77      0.74     18593\n",
      "           2       0.39      0.35      0.37      3272\n",
      "           3       0.82      0.86      0.84     27768\n",
      "           4       0.63      0.37      0.46       573\n",
      "           5       0.50      0.56      0.53     17625\n",
      "           6       0.37      0.18      0.24      7676\n",
      "           7       0.43      0.45      0.44      9629\n",
      "\n",
      "    accuracy                           0.64     86172\n",
      "   macro avg       0.55      0.45      0.46     86172\n",
      "weighted avg       0.63      0.64      0.63     86172\n",
      "\n",
      "Acur√°cia\n",
      "0.4473455534558037\n",
      "Precisao\n",
      "0.6270746956503312\n",
      "Recall\n",
      "0.6411015178944437\n",
      "F1\n",
      "0.6275312310484158\n",
      "[[   37   185    37    94     1   492    67   123]\n",
      " [    4 14303   138   745     3  2413   322   665]\n",
      " [    1   282  1159   477     7   679   132   535]\n",
      " [    0   765   345 23952    77  1308   160  1161]\n",
      " [    0    28     6   228   210    47     4    50]\n",
      " [   15  2641   552  1607    11  9867  1059  1873]\n",
      " [    6   900   269   688     3  3070  1398  1342]\n",
      " [    5   706   456  1582    21  1905   635  4319]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2915 - acc: 0.2608\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2744 - acc: 0.2649\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2639 - acc: 0.2682\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2588 - acc: 0.2697\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2557 - acc: 0.2706\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2526 - acc: 0.2713\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2495 - acc: 0.2726\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2454 - acc: 0.2738\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2451 - acc: 0.2740\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2435 - acc: 0.2741\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2421 - acc: 0.2747\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.2407 - acc: 0.2753\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2363 - acc: 0.2766\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2358 - acc: 0.2769\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2343 - acc: 0.2773\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2325 - acc: 0.2780\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2303 - acc: 0.2786\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2305 - acc: 0.2786\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2273 - acc: 0.2797\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2253 - acc: 0.2805\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2252 - acc: 0.2808\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2235 - acc: 0.2814\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2218 - acc: 0.2819\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2202 - acc: 0.2825\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2204 - acc: 0.2822\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2192 - acc: 0.2830\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2197 - acc: 0.2826\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2165 - acc: 0.2836\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2152 - acc: 0.2842\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2166 - acc: 0.2835\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2146 - acc: 0.2845\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2138 - acc: 0.2850\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2132 - acc: 0.2848\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2130 - acc: 0.2852\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2123 - acc: 0.2851\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2103 - acc: 0.2860\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2091 - acc: 0.2864\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2074 - acc: 0.2869\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2064 - acc: 0.2872\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2063 - acc: 0.2874\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2045 - acc: 0.2880\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2040 - acc: 0.2882\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2029 - acc: 0.2885\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2027 - acc: 0.2887\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2023 - acc: 0.2888\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2007 - acc: 0.2896\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2006 - acc: 0.2897\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2017 - acc: 0.2890\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2005 - acc: 0.2895\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.1994 - acc: 0.2899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.04      0.08       939\n",
      "           1       0.81      0.86      0.83     17763\n",
      "           2       0.65      0.55      0.60      3217\n",
      "           3       0.89      0.92      0.91     27694\n",
      "           4       0.80      0.56      0.66       528\n",
      "           5       0.57      0.62      0.59     16714\n",
      "           6       0.45      0.29      0.35      7385\n",
      "           7       0.55      0.58      0.56      9424\n",
      "\n",
      "    accuracy                           0.73     83664\n",
      "   macro avg       0.66      0.55      0.57     83664\n",
      "weighted avg       0.72      0.73      0.72     83664\n",
      "\n",
      "Acur√°cia\n",
      "0.5531732120682435\n",
      "Precisao\n",
      "0.7180825716290151\n",
      "Recall\n",
      "0.7283180340409257\n",
      "F1\n",
      "0.7184737473027467\n",
      "[[   40   113    18    40     0   548    80   100]\n",
      " [   10 15290    66   193     0  1539   275   390]\n",
      " [    1   128  1780   237     7   558   128   378]\n",
      " [    0   266   134 25584    45   717    82   866]\n",
      " [    1     7    11   156   296    20     5    32]\n",
      " [   11  2013   299   946     2 10406  1450  1587]\n",
      " [    9   685   160   429     3  2886  2110  1103]\n",
      " [    3   436   255  1051    19  1628   604  5428]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2416 - acc: 0.2808\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2350 - acc: 0.2823\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.2276 - acc: 0.2846\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2243 - acc: 0.2857\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2208 - acc: 0.2869\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.2181 - acc: 0.2880\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2178 - acc: 0.2879\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2160 - acc: 0.2883\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2141 - acc: 0.2891\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2112 - acc: 0.2898\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2116 - acc: 0.2898\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2100 - acc: 0.2906\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2076 - acc: 0.2914\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2088 - acc: 0.2909\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2084 - acc: 0.2912\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2073 - acc: 0.2913\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2050 - acc: 0.2921\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2044 - acc: 0.2924\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.2033 - acc: 0.2930\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2016 - acc: 0.2932\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2006 - acc: 0.2939\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2001 - acc: 0.2939\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1997 - acc: 0.2943\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.1983 - acc: 0.2943\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1982 - acc: 0.2949\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1982 - acc: 0.2946\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1968 - acc: 0.2949\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1963 - acc: 0.2952\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1963 - acc: 0.2955\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1932 - acc: 0.2965\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1929 - acc: 0.2966\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1923 - acc: 0.2968\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1925 - acc: 0.2967\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1934 - acc: 0.2963\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1913 - acc: 0.2971\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1904 - acc: 0.2974\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1904 - acc: 0.2974\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.1899 - acc: 0.2978\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1891 - acc: 0.2979\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1885 - acc: 0.2982\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1877 - acc: 0.2985\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1867 - acc: 0.2989\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1855 - acc: 0.2994\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1860 - acc: 0.2990\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1864 - acc: 0.2992\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1844 - acc: 0.2997\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1857 - acc: 0.2994\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1845 - acc: 0.2997\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1830 - acc: 0.3004\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1825 - acc: 0.3003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.06      0.11       961\n",
      "           1       0.85      0.91      0.88     16852\n",
      "           2       0.75      0.73      0.74      3063\n",
      "           3       0.91      0.95      0.93     26519\n",
      "           4       0.90      0.74      0.81       616\n",
      "           5       0.64      0.69      0.67     16067\n",
      "           6       0.57      0.36      0.44      6965\n",
      "           7       0.65      0.65      0.65      8847\n",
      "\n",
      "    accuracy                           0.79     79890\n",
      "   macro avg       0.75      0.64      0.65     79890\n",
      "weighted avg       0.78      0.79      0.78     79890\n",
      "\n",
      "Acur√°cia\n",
      "0.6377059471123951\n",
      "Precisao\n",
      "0.777091910619682\n",
      "Recall\n",
      "0.785717862060333\n",
      "F1\n",
      "0.7754780940196784\n",
      "[[   60    84    25    50     0   573    71    98]\n",
      " [    2 15339    39   107     0  1024   140   201]\n",
      " [    0    71  2246   155     2   273    56   260]\n",
      " [    0   134   116 25318    34   416    49   452]\n",
      " [    0     0     9   115   455     9    15    13]\n",
      " [   15  1591   235   813     0 11060  1155  1198]\n",
      " [    7   528    99   321     5  2652  2509   844]\n",
      " [    1   339   228   908     8  1175   404  5784]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2123 - acc: 0.2922\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2059 - acc: 0.2938\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.2041 - acc: 0.2940\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1998 - acc: 0.2957\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1982 - acc: 0.2962\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1940 - acc: 0.2978\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1953 - acc: 0.2973\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1935 - acc: 0.2977\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1919 - acc: 0.2983\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1929 - acc: 0.2982\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1919 - acc: 0.2985\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1886 - acc: 0.2994\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1881 - acc: 0.2995\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1873 - acc: 0.2998\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1857 - acc: 0.3005\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1862 - acc: 0.3003\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1862 - acc: 0.3004\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1846 - acc: 0.3011\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1834 - acc: 0.3015\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1824 - acc: 0.3018\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1817 - acc: 0.3021\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1823 - acc: 0.3020\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1803 - acc: 0.3024\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1785 - acc: 0.3030\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1792 - acc: 0.3031\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1793 - acc: 0.3030\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1788 - acc: 0.3031\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1783 - acc: 0.3033\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1771 - acc: 0.3039\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1761 - acc: 0.3043\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1761 - acc: 0.3039\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1761 - acc: 0.3042\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1755 - acc: 0.3044\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1748 - acc: 0.3048\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1753 - acc: 0.3045\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1737 - acc: 0.3050\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1729 - acc: 0.3053\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1746 - acc: 0.3047\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1725 - acc: 0.3054\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1709 - acc: 0.3062\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1702 - acc: 0.3064\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1716 - acc: 0.3061\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1703 - acc: 0.3063\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 11s 8ms/sample - loss: 0.1708 - acc: 0.3066\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 12s 9ms/sample - loss: 0.1704 - acc: 0.3062\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1693 - acc: 0.3069\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1695 - acc: 0.3067\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1700 - acc: 0.3066\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1686 - acc: 0.3071\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 11s 9ms/sample - loss: 0.1686 - acc: 0.3071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.11      0.19       989\n",
      "           1       0.89      0.91      0.90     16019\n",
      "           2       0.79      0.77      0.78      2775\n",
      "           3       0.93      0.96      0.94     26561\n",
      "           4       0.89      0.77      0.82       552\n",
      "           5       0.68      0.73      0.70     16022\n",
      "           6       0.62      0.42      0.50      6983\n",
      "           7       0.68      0.74      0.71      8891\n",
      "\n",
      "    accuracy                           0.81     78792\n",
      "   macro avg       0.76      0.68      0.69     78792\n",
      "weighted avg       0.81      0.81      0.80     78792\n",
      "\n",
      "Acur√°cia\n",
      "0.675252176308612\n",
      "Precisao\n",
      "0.8050013226219256\n",
      "Recall\n",
      "0.8110087318509493\n",
      "F1\n",
      "0.803644884223513\n",
      "[[  108    60    14    34     0   588    72   113]\n",
      " [    1 14562    33   118     0   969   151   185]\n",
      " [    0    44  2126   126     3   214    48   214]\n",
      " [    2    52    75 25546    37   296    47   506]\n",
      " [    0     2     0   100   425     6     4    15]\n",
      " [   46  1136   177   642     4 11629  1194  1194]\n",
      " [    9   328    90   260     4  2541  2963   788]\n",
      " [    6   169   173   764     6   930   301  6542]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "model = criarRede()\n",
    "\n",
    "for train_index, test_index in kf.split(previsores_trei_vald):\n",
    "  \n",
    "  train_and_evaluate_model(model, previsores_trei_vald[train_index], classes_trei_vald[train_index],\n",
    "                           previsores_trei_vald[test_index], classes_trei_vald[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 700, 200)          97600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 1,065,608\n",
      "Trainable params: 1,065,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cias total\n",
      "[0.3379048683428947, 0.4473455534558037, 0.5531732120682435, 0.6377059471123951, 0.675252176308612]\n",
      "Precision total\n",
      "[0.5213905001483021, 0.6270746956503312, 0.7180825716290151, 0.777091910619682, 0.8050013226219256]\n",
      "Recalls total\n",
      "[0.5352683252311505, 0.6411015178944437, 0.7283180340409257, 0.785717862060333, 0.8110087318509493]\n",
      "F1 total\n",
      "[0.5124309445024305, 0.6275312310484158, 0.7184737473027467, 0.7754780940196784, 0.803644884223513]\n"
     ]
    }
   ],
   "source": [
    "print('Acur√°cias total')\n",
    "print(accuq8)\n",
    "print('Precision total')\n",
    "print(precisionsq8)\n",
    "print('Recalls total')\n",
    "print(recallsq8)\n",
    "print('F1 total')\n",
    "print(f1q8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1866 - acc: 0.2970\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1824 - acc: 0.2982\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1803 - acc: 0.2991\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1786 - acc: 0.2993\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1775 - acc: 0.3000\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1748 - acc: 0.3010\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1744 - acc: 0.3010\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1731 - acc: 0.3015\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1721 - acc: 0.3018\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1729 - acc: 0.3015\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1725 - acc: 0.3018\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1719 - acc: 0.3019\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1729 - acc: 0.3014\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1727 - acc: 0.3017\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1714 - acc: 0.3021\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1698 - acc: 0.3027\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1703 - acc: 0.3026\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1697 - acc: 0.3027\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 13s 8ms/sample - loss: 0.1694 - acc: 0.3026\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 13s 8ms/sample - loss: 0.1689 - acc: 0.3031\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 13s 8ms/sample - loss: 0.1687 - acc: 0.3031\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1677 - acc: 0.3031\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1684 - acc: 0.3030\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 15s 9ms/sample - loss: 0.1671 - acc: 0.3037\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1676 - acc: 0.3034\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1676 - acc: 0.3033\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1672 - acc: 0.3037\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 13s 8ms/sample - loss: 0.1669 - acc: 0.3036\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1666 - acc: 0.3038\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1667 - acc: 0.3040\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1656 - acc: 0.3042\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1654 - acc: 0.3042\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1649 - acc: 0.3046\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1658 - acc: 0.3040\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1649 - acc: 0.3044\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1658 - acc: 0.3041\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1655 - acc: 0.3042\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1633 - acc: 0.3050\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1630 - acc: 0.3052\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1632 - acc: 0.3051\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1651 - acc: 0.3044\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1651 - acc: 0.3042\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1641 - acc: 0.3048\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1623 - acc: 0.3055\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1620 - acc: 0.3057\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1613 - acc: 0.3059\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1607 - acc: 0.3062\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1611 - acc: 0.3059\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 14s 9ms/sample - loss: 0.1602 - acc: 0.3062\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 14s 8ms/sample - loss: 0.1602 - acc: 0.3062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.07      0.12      1319\n",
      "           1       0.64      0.62      0.63     21565\n",
      "           2       0.41      0.26      0.32      4144\n",
      "           3       0.71      0.75      0.73     34429\n",
      "           4       0.54      0.27      0.36       723\n",
      "           5       0.46      0.51      0.48     20463\n",
      "           6       0.34      0.26      0.30      9014\n",
      "           7       0.39      0.42      0.41     11705\n",
      "\n",
      "    accuracy                           0.57    103362\n",
      "   macro avg       0.50      0.40      0.42    103362\n",
      "weighted avg       0.56      0.57      0.56    103362\n",
      "\n",
      "Acur√°cia\n",
      "0.39632695368158144\n",
      "Precisao\n",
      "0.5600226661903157\n",
      "Recall\n",
      "0.5655366575724154\n",
      "F1\n",
      "0.5587352848449452\n",
      "[[   92   216    19   231     1   486   108   166]\n",
      " [   26 13447   214  2829    17  3257   665  1110]\n",
      " [    3   419  1059   990    18   808   261   586]\n",
      " [    7  2402   422 25836   101  2848   692  2121]\n",
      " [    0    59     9   304   196    70    21    64]\n",
      " [   48  2628   332  2826    10 10487  1874  2258]\n",
      " [    8   967   173  1181     4  2828  2386  1467]\n",
      " [    6   866   344  2229    14  2239  1055  4952]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(model, previsores_trei_vald, classes_trei_vald,\n",
    "                           previsores_testes, classes_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
