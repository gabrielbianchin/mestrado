{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 20:28].values\n",
    "classes = np.reshape(classes, (2000, 700, 8))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(LSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(8, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn = criarRede, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 50, verbose = 1, batch_size = 32)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 8))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 8))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "previsores_trei_vald, previsores_testes, classes_trei_vald, classes_testes = train_test_split(previsores, classes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 22:01:06.451225  5948 deprecation_wrapper.py:119] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0807 22:01:06.508074  5948 deprecation_wrapper.py:119] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0807 22:01:06.516053  5948 deprecation_wrapper.py:119] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0807 22:01:06.861130  5948 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0807 22:01:07.316911  5948 deprecation_wrapper.py:119] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0807 22:01:07.322897  5948 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0807 22:01:09.413310  5948 deprecation_wrapper.py:119] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0807 22:01:09.565902  5948 deprecation_wrapper.py:119] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 296s 232ms/step - loss: 1.7148 - acc: 0.3455\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 333s 260ms/step - loss: 1.5560 - acc: 0.4206\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 371s 290ms/step - loss: 1.4853 - acc: 0.4503\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 368s 287ms/step - loss: 1.4419 - acc: 0.4665\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 370s 289ms/step - loss: 1.4157 - acc: 0.4796\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 273s 213ms/step - loss: 1.3961 - acc: 0.4886\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 1.3862 - acc: 0.4929\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 1.3777 - acc: 0.4971\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 1.3637 - acc: 0.5037\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 1.3612 - acc: 0.5053\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 1.3465 - acc: 0.5107\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 1.3442 - acc: 0.5116\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 1.3352 - acc: 0.5152\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 1.3224 - acc: 0.5209\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 239s 186ms/step - loss: 1.3156 - acc: 0.5238\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 1.3096 - acc: 0.5262\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 1.3036 - acc: 0.5280\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 1.2961 - acc: 0.5313\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 1.2846 - acc: 0.5362\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 1.2877 - acc: 0.5353\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 1.2742 - acc: 0.5398\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 235s 183ms/step - loss: 1.2707 - acc: 0.5403\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 1.2600 - acc: 0.5455\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 1.2496 - acc: 0.5495\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 1.2406 - acc: 0.5519\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 1.2294 - acc: 0.5562\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 1.2309 - acc: 0.5550\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 235s 183ms/step - loss: 1.2209 - acc: 0.5592\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 1.2061 - acc: 0.5642\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 234s 182ms/step - loss: 1.1982 - acc: 0.5672\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 1.1823 - acc: 0.5728\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 231s 181ms/step - loss: 1.1682 - acc: 0.5772\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 231s 181ms/step - loss: 1.1753 - acc: 0.5750\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 1.1576 - acc: 0.5814\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 1.1381 - acc: 0.5882\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 1.1284 - acc: 0.5907\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 1.1157 - acc: 0.5966\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 1.1028 - acc: 0.5998\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 1.0952 - acc: 0.6024\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 1.0866 - acc: 0.6050\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 1.0693 - acc: 0.6110\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 231s 181ms/step - loss: 1.0564 - acc: 0.6160\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 229s 179ms/step - loss: 1.0480 - acc: 0.6195\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 231s 181ms/step - loss: 1.0331 - acc: 0.6231\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 231s 180ms/step - loss: 1.0302 - acc: 0.6235\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 231s 180ms/step - loss: 1.0133 - acc: 0.6294\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 231s 181ms/step - loss: 1.0112 - acc: 0.6303\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 1.0016 - acc: 0.6340\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.9806 - acc: 0.6400\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.9690 - acc: 0.6440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       904\n",
      "           1       0.58      0.61      0.59     17306\n",
      "           2       0.33      0.14      0.20      2997\n",
      "           3       0.65      0.80      0.72     27027\n",
      "           4       0.33      0.09      0.14       459\n",
      "           5       0.43      0.50      0.46     16418\n",
      "           6       0.30      0.04      0.07      7055\n",
      "           7       0.38      0.33      0.35      9222\n",
      "\n",
      "    accuracy                           0.54     81388\n",
      "   macro avg       0.37      0.32      0.32     81388\n",
      "weighted avg       0.51      0.54      0.51     81388\n",
      "\n",
      "Acur√°cia\n",
      "0.31537607917312127\n",
      "Precisao\n",
      "0.5088110623346124\n",
      "Recall\n",
      "0.5449697744139185\n",
      "F1\n",
      "0.5128386127378469\n",
      "[[    0   199    19   192     1   380    14    99]\n",
      " [    0 10524    99  3265    16  2624    75   703]\n",
      " [    0   375   426   911     2   839    42   402]\n",
      " [    0  1968   177 21723    39  2093    46   981]\n",
      " [    0    57     0   300    42    34     1    25]\n",
      " [    0  2887   231  3154    13  8291   274  1568]\n",
      " [    0  1058   109  1396     6  3001   284  1201]\n",
      " [    0  1022   228  2459     9  2235   205  3064]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 224s 175ms/step - loss: 1.0815 - acc: 0.6137\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 231s 181ms/step - loss: 1.0528 - acc: 0.6207\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 1.0215 - acc: 0.6305\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 1.0383 - acc: 0.6227\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 1.0337 - acc: 0.6256\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.9937 - acc: 0.6381\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 0.9796 - acc: 0.6428\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.9625 - acc: 0.6479\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.9479 - acc: 0.6529\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 235s 183ms/step - loss: 0.9394 - acc: 0.6548\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.9274 - acc: 0.6583\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.9248 - acc: 0.6595\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.9210 - acc: 0.6611\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.9070 - acc: 0.6645\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 237s 186ms/step - loss: 0.8955 - acc: 0.6687\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.8906 - acc: 0.6694\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.8857 - acc: 0.6711\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 239s 186ms/step - loss: 0.8750 - acc: 0.6744\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 239s 186ms/step - loss: 0.8642 - acc: 0.6781\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 239s 186ms/step - loss: 0.8583 - acc: 0.6803\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.8547 - acc: 0.6818\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.8511 - acc: 0.6820\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.8459 - acc: 0.6840\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.8352 - acc: 0.6883\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 239s 186ms/step - loss: 0.8337 - acc: 0.6878\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 240s 188ms/step - loss: 0.8262 - acc: 0.6906\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.8216 - acc: 0.6924\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.8158 - acc: 0.6931\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 240s 188ms/step - loss: 0.8130 - acc: 0.6951\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.8045 - acc: 0.6978\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.8022 - acc: 0.6976\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.7986 - acc: 0.6997\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 241s 189ms/step - loss: 0.7983 - acc: 0.6994\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.8029 - acc: 0.6985\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.7831 - acc: 0.7049\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 240s 188ms/step - loss: 0.7788 - acc: 0.7063\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7751 - acc: 0.7074\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.7704 - acc: 0.7094\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7633 - acc: 0.7118\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.7628 - acc: 0.7121\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.7586 - acc: 0.7128\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7580 - acc: 0.7132\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.7505 - acc: 0.7151\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 242s 189ms/step - loss: 0.7440 - acc: 0.7185\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.7441 - acc: 0.7181\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.7382 - acc: 0.7198\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7395 - acc: 0.7201\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7325 - acc: 0.7220\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7327 - acc: 0.7221\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.7972 - acc: 0.7012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01      1076\n",
      "           1       0.67      0.71      0.69     17671\n",
      "           2       0.33      0.29      0.31      3221\n",
      "           3       0.75      0.84      0.79     25950\n",
      "           4       0.63      0.21      0.32       664\n",
      "           5       0.46      0.54      0.49     17401\n",
      "           6       0.37      0.08      0.13      7592\n",
      "           7       0.40      0.42      0.41      9689\n",
      "\n",
      "    accuracy                           0.59     83264\n",
      "   macro avg       0.58      0.39      0.39     83264\n",
      "weighted avg       0.58      0.59      0.57     83264\n",
      "\n",
      "Acur√°cia\n",
      "0.3864829473648025\n",
      "Precisao\n",
      "0.5821151779666907\n",
      "Recall\n",
      "0.5936058800922367\n",
      "F1\n",
      "0.5702792099292736\n",
      "[[    4   212    44   141     0   508    29   138]\n",
      " [    0 12546   232  1244     5  2754   115   775]\n",
      " [    0   328   926   698     3   707    53   506]\n",
      " [    0   834   382 21718    51  1682    65  1218]\n",
      " [    0    45    22   347   141    59     4    46]\n",
      " [    0  2875   555  2059     7  9406   473  2026]\n",
      " [    0  1068   247   888     6  3292   608  1483]\n",
      " [    0   827   414  1852    10  2228   281  4077]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.9039 - acc: 0.6720\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.8589 - acc: 0.6846\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.8311 - acc: 0.6928\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.8121 - acc: 0.6987\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.8009 - acc: 0.7019\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.7876 - acc: 0.7053\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.7813 - acc: 0.7082\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7757 - acc: 0.7095\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 240s 188ms/step - loss: 0.7698 - acc: 0.7116\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7698 - acc: 0.7108\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7617 - acc: 0.7133\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.7571 - acc: 0.7155\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7525 - acc: 0.7164\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 239s 186ms/step - loss: 0.7498 - acc: 0.7176\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.7480 - acc: 0.7175\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7400 - acc: 0.7205\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.7349 - acc: 0.7217\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.7311 - acc: 0.7236\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 235s 183ms/step - loss: 0.7280 - acc: 0.7246\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.7260 - acc: 0.7247\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.7233 - acc: 0.7258\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.7157 - acc: 0.7287\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.7146 - acc: 0.7286\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.7141 - acc: 0.7291\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.7095 - acc: 0.7312\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.7065 - acc: 0.7314\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.7033 - acc: 0.7327\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6961 - acc: 0.7353\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6963 - acc: 0.7345\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 0.6963 - acc: 0.7355\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 0.6979 - acc: 0.7351\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.6979 - acc: 0.7341\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6896 - acc: 0.7373\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6843 - acc: 0.7387\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6825 - acc: 0.7395\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6786 - acc: 0.7413\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 237s 186ms/step - loss: 0.6762 - acc: 0.7416\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6761 - acc: 0.7424\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6689 - acc: 0.7439\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6698 - acc: 0.7440\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6702 - acc: 0.7439\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6659 - acc: 0.7461\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6646 - acc: 0.7464\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6639 - acc: 0.7461\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6646 - acc: 0.7472\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6607 - acc: 0.7476\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6586 - acc: 0.7481\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6515 - acc: 0.7510\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.6515 - acc: 0.7512\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.6489 - acc: 0.7511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.01      0.02       994\n",
      "           1       0.77      0.82      0.79     17455\n",
      "           2       0.55      0.46      0.50      3020\n",
      "           3       0.87      0.90      0.88     26388\n",
      "           4       0.85      0.51      0.64       516\n",
      "           5       0.52      0.62      0.57     16060\n",
      "           6       0.39      0.16      0.22      7106\n",
      "           7       0.48      0.51      0.50      9004\n",
      "\n",
      "    accuracy                           0.69     80543\n",
      "   macro avg       0.62      0.50      0.51     80543\n",
      "weighted avg       0.67      0.69      0.67     80543\n",
      "\n",
      "Acur√°cia\n",
      "0.4986691076502354\n",
      "Precisao\n",
      "0.674893923057731\n",
      "Recall\n",
      "0.6886756142681549\n",
      "F1\n",
      "0.6724192839105866\n",
      "[[    8   139    40    67     0   564    61   115]\n",
      " [    0 14295    94   347     0  1998   200   521]\n",
      " [    0   199  1382   309     1   583    84   462]\n",
      " [    0   328   166 23831    32  1026    74   931]\n",
      " [    0     4     7   199   265    17     3    21]\n",
      " [    6  2312   340  1045     0  9983   813  1561]\n",
      " [    0   829   181   458     4  3208  1111  1315]\n",
      " [    1   574   325  1238     9  1797   467  4593]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.7492 - acc: 0.7213\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.7303 - acc: 0.7250\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.7159 - acc: 0.7298\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 235s 183ms/step - loss: 0.7180 - acc: 0.7292\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 0.7023 - acc: 0.7340\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6945 - acc: 0.7369\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6868 - acc: 0.7392\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6859 - acc: 0.7389\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 240s 188ms/step - loss: 0.6789 - acc: 0.7420\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6741 - acc: 0.7434\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6682 - acc: 0.7450\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6701 - acc: 0.7446\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6677 - acc: 0.7457\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 235s 183ms/step - loss: 0.6615 - acc: 0.7480\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6601 - acc: 0.7484\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6578 - acc: 0.7489\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6569 - acc: 0.7497\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 234s 182ms/step - loss: 0.6525 - acc: 0.7505\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6483 - acc: 0.7527\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.6474 - acc: 0.7530\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6498 - acc: 0.7515\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6482 - acc: 0.7532\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.6413 - acc: 0.7549\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.6380 - acc: 0.7561\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.6361 - acc: 0.7564\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 235s 183ms/step - loss: 0.6461 - acc: 0.7530\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6414 - acc: 0.7557\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6356 - acc: 0.7567\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 0.6293 - acc: 0.7596\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6279 - acc: 0.7597\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 0.6268 - acc: 0.7604\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 0.6259 - acc: 0.7609\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6273 - acc: 0.7601\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.6252 - acc: 0.7606\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 231s 181ms/step - loss: 0.6187 - acc: 0.7629\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.6167 - acc: 0.7639\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6124 - acc: 0.7654\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 233s 182ms/step - loss: 0.6153 - acc: 0.7651\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6138 - acc: 0.7643\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 234s 182ms/step - loss: 0.6134 - acc: 0.7644\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6128 - acc: 0.7658\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 234s 182ms/step - loss: 0.6090 - acc: 0.7662\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 232s 181ms/step - loss: 0.6157 - acc: 0.7640\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6142 - acc: 0.7652\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6047 - acc: 0.7679\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 231s 181ms/step - loss: 0.6036 - acc: 0.7692\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.6026 - acc: 0.7686\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6078 - acc: 0.7666\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 235s 183ms/step - loss: 0.6055 - acc: 0.7669\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.5988 - acc: 0.7705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.01      0.02       989\n",
      "           1       0.82      0.87      0.85     16907\n",
      "           2       0.65      0.60      0.63      3061\n",
      "           3       0.90      0.93      0.91     26863\n",
      "           4       0.82      0.64      0.72       556\n",
      "           5       0.57      0.68      0.62     16479\n",
      "           6       0.52      0.21      0.30      7056\n",
      "           7       0.57      0.59      0.58      9147\n",
      "\n",
      "    accuracy                           0.74     81058\n",
      "   macro avg       0.69      0.57      0.58     81058\n",
      "weighted avg       0.73      0.74      0.73     81058\n",
      "\n",
      "Acur√°cia\n",
      "0.5676833708461824\n",
      "Precisao\n",
      "0.7328438637369354\n",
      "Recall\n",
      "0.7422339559327888\n",
      "F1\n",
      "0.7267450513549606\n",
      "[[    9   105    19    48     1   637    49   121]\n",
      " [    0 14766    55   216     0  1458   115   297]\n",
      " [    1   114  1847   208     2   445    73   371]\n",
      " [    0   169   160 25101    52   661    40   680]\n",
      " [    0     2    16   143   356    24     2    13]\n",
      " [    2  1840   328   885     5 11187   762  1470]\n",
      " [    0   581   123   389     9  3402  1479  1073]\n",
      " [    2   403   298  1047     7  1643   328  5419]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6743 - acc: 0.7474\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.6571 - acc: 0.7517\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.6490 - acc: 0.7540\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6401 - acc: 0.7572\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6304 - acc: 0.7596\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6280 - acc: 0.7611\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 0.6221 - acc: 0.7625\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6173 - acc: 0.7651\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.6165 - acc: 0.7652\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.6114 - acc: 0.7664\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6132 - acc: 0.7658\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.6078 - acc: 0.7673\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.6074 - acc: 0.7674\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.6013 - acc: 0.7701\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.6015 - acc: 0.7707\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.6021 - acc: 0.7697\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.5958 - acc: 0.7718\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.5951 - acc: 0.7723\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.5922 - acc: 0.7739\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 239s 187ms/step - loss: 0.5925 - acc: 0.7729\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.5954 - acc: 0.7725\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.5923 - acc: 0.7738\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.5909 - acc: 0.7732\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.5866 - acc: 0.7758\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 235s 184ms/step - loss: 0.5831 - acc: 0.7765\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 234s 183ms/step - loss: 0.5849 - acc: 0.7754\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 0.5842 - acc: 0.7758\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 237s 185ms/step - loss: 0.5791 - acc: 0.7775\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 236s 185ms/step - loss: 0.5791 - acc: 0.7777\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.5772 - acc: 0.7793\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 236s 184ms/step - loss: 0.5752 - acc: 0.7791\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 238s 186ms/step - loss: 0.5781 - acc: 0.7791\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 258s 202ms/step - loss: 0.5733 - acc: 0.7800\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.5737 - acc: 0.7806\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.5754 - acc: 0.7797\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 241s 189ms/step - loss: 0.5715 - acc: 0.7806\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 240s 188ms/step - loss: 0.5690 - acc: 0.7821\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 241s 189ms/step - loss: 0.5700 - acc: 0.7817\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 240s 187ms/step - loss: 0.5640 - acc: 0.7831\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.5635 - acc: 0.7837\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.5646 - acc: 0.7841\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.5617 - acc: 0.7842\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.5626 - acc: 0.7846\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 241s 188ms/step - loss: 0.5577 - acc: 0.7855\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 244s 190ms/step - loss: 0.5590 - acc: 0.7854\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.5585 - acc: 0.7851\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 241s 189ms/step - loss: 0.5581 - acc: 0.7862\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 243s 190ms/step - loss: 0.5601 - acc: 0.7850\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 242s 189ms/step - loss: 0.5535 - acc: 0.7880\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 242s 189ms/step - loss: 0.5515 - acc: 0.7884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.02      0.05       982\n",
      "           1       0.83      0.89      0.86     18028\n",
      "           2       0.73      0.64      0.68      3428\n",
      "           3       0.91      0.95      0.93     28486\n",
      "           4       0.85      0.69      0.76       599\n",
      "           5       0.60      0.68      0.63     17264\n",
      "           6       0.53      0.25      0.34      7765\n",
      "           7       0.59      0.64      0.61      9641\n",
      "\n",
      "    accuracy                           0.76     86193\n",
      "   macro avg       0.71      0.60      0.61     86193\n",
      "weighted avg       0.75      0.76      0.75     86193\n",
      "\n",
      "Acur√°cia\n",
      "0.5959346723734855\n",
      "Precisao\n",
      "0.7509210562556903\n",
      "Recall\n",
      "0.7597136658429339\n",
      "F1\n",
      "0.7462755937828685\n",
      "[[   23    85    26    46     0   609    78   115]\n",
      " [    2 16112    28   108     0  1325   133   320]\n",
      " [    0    76  2210   209     4   446    58   425]\n",
      " [    0   151    89 26961    50   577    56   602]\n",
      " [    0     3     4   136   416    12     1    27]\n",
      " [    6  1965   262   775     3 11658  1009  1586]\n",
      " [    2   588   149   323     9  3528  1957  1209]\n",
      " [    1   381   271  1001     9  1438   395  6145]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "model = criarRede()\n",
    "\n",
    "for train_index, test_index in kf.split(previsores_trei_vald):\n",
    "  \n",
    "  train_and_evaluate_model(model, previsores_trei_vald[train_index], classes_trei_vald[train_index],\n",
    "                           previsores_trei_vald[test_index], classes_trei_vald[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 700, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 700, 200)          96800     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 700, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 700, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 580,008\n",
      "Trainable params: 580,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cias total\n",
      "[0.31537607917312127, 0.3864829473648025, 0.4986691076502354, 0.5676833708461824, 0.5959346723734855]\n",
      "Precision total\n",
      "[0.5088110623346124, 0.5821151779666907, 0.674893923057731, 0.7328438637369354, 0.7509210562556903]\n",
      "Recalls total\n",
      "[0.5449697744139185, 0.5936058800922367, 0.6886756142681549, 0.7422339559327888, 0.7597136658429339]\n",
      "F1 total\n",
      "[0.5128386127378469, 0.5702792099292736, 0.6724192839105866, 0.7267450513549606, 0.7462755937828685]\n"
     ]
    }
   ],
   "source": [
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "print('F1 total')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 310s 194ms/step - loss: 0.6156 - acc: 0.7678\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 301s 188ms/step - loss: 0.6018 - acc: 0.7715\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 303s 190ms/step - loss: 0.5914 - acc: 0.7741\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5881 - acc: 0.7758\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 300s 188ms/step - loss: 0.5800 - acc: 0.7783\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 303s 189ms/step - loss: 0.5793 - acc: 0.7794\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5746 - acc: 0.7807\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5752 - acc: 0.7799\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 301s 188ms/step - loss: 0.5753 - acc: 0.7797\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 303s 190ms/step - loss: 0.5737 - acc: 0.7803\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 306s 191ms/step - loss: 0.5742 - acc: 0.7795\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 304s 190ms/step - loss: 0.5710 - acc: 0.7817\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 300s 188ms/step - loss: 0.5694 - acc: 0.7822\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 301s 188ms/step - loss: 0.5710 - acc: 0.7812\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 302s 189ms/step - loss: 0.5669 - acc: 0.7828\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 300s 187ms/step - loss: 0.5640 - acc: 0.7839\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 298s 187ms/step - loss: 0.5652 - acc: 0.7838\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5640 - acc: 0.7836\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 298s 186ms/step - loss: 0.5633 - acc: 0.7839\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 300s 188ms/step - loss: 0.5634 - acc: 0.7843\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 300s 188ms/step - loss: 0.5632 - acc: 0.7840\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 302s 188ms/step - loss: 0.5626 - acc: 0.7841\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 300s 187ms/step - loss: 0.5567 - acc: 0.7861\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 300s 187ms/step - loss: 0.5583 - acc: 0.7854\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 300s 187ms/step - loss: 0.5566 - acc: 0.7868\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5533 - acc: 0.7875\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 300s 187ms/step - loss: 0.5568 - acc: 0.7866\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 296s 185ms/step - loss: 0.5557 - acc: 0.7867\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 296s 185ms/step - loss: 0.5537 - acc: 0.7876\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 297s 185ms/step - loss: 0.5570 - acc: 0.7870\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 296s 185ms/step - loss: 0.5535 - acc: 0.7879\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 301s 188ms/step - loss: 0.5529 - acc: 0.7876\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5509 - acc: 0.7882\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 298s 186ms/step - loss: 0.5468 - acc: 0.7904\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5489 - acc: 0.7899\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 301s 188ms/step - loss: 0.5476 - acc: 0.7904\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5456 - acc: 0.7906\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5469 - acc: 0.7895\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 299s 187ms/step - loss: 0.5467 - acc: 0.7902\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 306s 192ms/step - loss: 0.5483 - acc: 0.7897\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 0.5480 - acc: 0.7901\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 490s 306ms/step - loss: 0.5448 - acc: 0.7910\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 388s 242ms/step - loss: 0.5418 - acc: 0.7917\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 302s 189ms/step - loss: 0.5495 - acc: 0.7901\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 302s 189ms/step - loss: 0.5469 - acc: 0.7902\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 304s 190ms/step - loss: 0.5408 - acc: 0.7929\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 302s 189ms/step - loss: 0.5394 - acc: 0.7925\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 302s 189ms/step - loss: 0.5408 - acc: 0.7932\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 304s 190ms/step - loss: 0.5383 - acc: 0.7931\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 303s 189ms/step - loss: 0.5374 - acc: 0.7941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.02      0.03      1319\n",
      "           1       0.60      0.65      0.63     21565\n",
      "           2       0.35      0.26      0.30      4144\n",
      "           3       0.72      0.72      0.72     34429\n",
      "           4       0.59      0.27      0.37       723\n",
      "           5       0.43      0.53      0.47     20463\n",
      "           6       0.32      0.18      0.23      9014\n",
      "           7       0.38      0.40      0.39     11705\n",
      "\n",
      "    accuracy                           0.55    103362\n",
      "   macro avg       0.48      0.38      0.39    103362\n",
      "weighted avg       0.55      0.55      0.54    103362\n",
      "\n",
      "Acur√°cia\n",
      "0.3777934770037362\n",
      "Precisao\n",
      "0.5470067028319298\n",
      "Recall\n",
      "0.5521371490489735\n",
      "F1\n",
      "0.5431311983289892\n",
      "[[   21   238    25   183     1   614    82   155]\n",
      " [    7 14012   241  2326     6  3518   468   987]\n",
      " [    0   468  1075   893     6   866   202   634]\n",
      " [    3  3123   570 24640   105  3459   438  2091]\n",
      " [    0    49    22   279   196    86    11    80]\n",
      " [    9  3162   448  2585     5 10789  1385  2080]\n",
      " [    0  1143   272  1058     1  3424  1641  1475]\n",
      " [    4  1065   413  2111    13  2561   842  4696]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(model, previsores_trei_vald, classes_trei_vald,\n",
    "                           previsores_testes, classes_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
