{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 20:28].values\n",
    "classes = np.reshape(classes, (2000, 700, 8))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    #model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(8, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuq8 = []\n",
    "precisionsq8 = []\n",
    "recallsq8 = []\n",
    "f1q8 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 50, verbose = 1, batch_size = 32)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 8))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 8))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accuq8.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisionsq8.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recallsq8.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1q8.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "previsores_trei_vald, previsores_testes, classes_trei_vald, classes_testes = train_test_split(previsores, classes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 15:49:26.862586  4328 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 15:49:26.868573  4328 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 15:49:26.869570  4328 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 15:49:26.870568  4328 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 15:49:28.671671  4328 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 28s 22ms/sample - loss: 0.6260 - acc: 0.1412\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5810 - acc: 0.1536\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5631 - acc: 0.1628\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5402 - acc: 0.1731\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5255 - acc: 0.1792\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5179 - acc: 0.1824\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5145 - acc: 0.1844\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5101 - acc: 0.1862\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5053 - acc: 0.1883\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.5012 - acc: 0.1900\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4993 - acc: 0.1908\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4952 - acc: 0.1922\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4965 - acc: 0.1914\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4915 - acc: 0.1942\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4856 - acc: 0.1965\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4819 - acc: 0.1973\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4771 - acc: 0.1994\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4751 - acc: 0.2006\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4681 - acc: 0.2029\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4680 - acc: 0.2029\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4584 - acc: 0.2069\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4503 - acc: 0.2088\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4448 - acc: 0.2117\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4412 - acc: 0.2126\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4344 - acc: 0.2149\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4261 - acc: 0.2183\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4238 - acc: 0.2190\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4177 - acc: 0.2206\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4076 - acc: 0.2237\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.4006 - acc: 0.2259\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3955 - acc: 0.2277\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3885 - acc: 0.2300\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3839 - acc: 0.2309\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3778 - acc: 0.2329\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3702 - acc: 0.2356\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3674 - acc: 0.2364\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3608 - acc: 0.2391\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3569 - acc: 0.2418\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3517 - acc: 0.2418\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3454 - acc: 0.2448\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3453 - acc: 0.2444\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3391 - acc: 0.2458\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3414 - acc: 0.2451\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3465 - acc: 0.2435\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.3325 - acc: 0.2485\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.3228 - acc: 0.2516\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 13s 11ms/sample - loss: 0.3188 - acc: 0.2527\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3159 - acc: 0.2534\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3112 - acc: 0.2547\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3081 - acc: 0.2558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.02       911\n",
      "           1       0.59      0.68      0.63     16618\n",
      "           2       0.28      0.29      0.28      2921\n",
      "           3       0.71      0.74      0.73     26319\n",
      "           4       0.41      0.28      0.33       606\n",
      "           5       0.43      0.52      0.47     16065\n",
      "           6       0.38      0.08      0.14      6827\n",
      "           7       0.39      0.36      0.37      8823\n",
      "\n",
      "    accuracy                           0.55     79090\n",
      "   macro avg       0.46      0.37      0.37     79090\n",
      "weighted avg       0.54      0.55      0.54     79090\n",
      "\n",
      "Acur√°cia\n",
      "0.36913744110934216\n",
      "Precisao\n",
      "0.5420563258863694\n",
      "Recall\n",
      "0.5542167151346568\n",
      "F1\n",
      "0.5356439560967332\n",
      "[[    9   201    35   128     3   430    22    83]\n",
      " [    0 11294   244  2086    27  2323   106   538]\n",
      " [    2   376   839   600     8   663    50   383]\n",
      " [    3  2368   592 19477   146  2330    78  1325]\n",
      " [    0    68    13   275   168    36     4    42]\n",
      " [    2  2930   573  2260    23  8323   419  1535]\n",
      " [    1  1020   257   891     9  3011   575  1063]\n",
      " [    1   996   452  1675    26  2247   278  3148]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3701 - acc: 0.2395\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3503 - acc: 0.2448\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.3400 - acc: 0.2478\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3325 - acc: 0.2499\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 13s 11ms/sample - loss: 0.3261 - acc: 0.2513\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.3216 - acc: 0.2522\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3164 - acc: 0.2537\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.3128 - acc: 0.2550\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.3080 - acc: 0.2556\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3044 - acc: 0.2567\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.3010 - acc: 0.2585\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2973 - acc: 0.2590\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2942 - acc: 0.2598\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2914 - acc: 0.2608\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2906 - acc: 0.2610\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2853 - acc: 0.2631\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2826 - acc: 0.2636\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2793 - acc: 0.2648\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2765 - acc: 0.2658\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.2763 - acc: 0.2662\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.2752 - acc: 0.2660\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.2739 - acc: 0.2666\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.2707 - acc: 0.2678\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.2667 - acc: 0.2691\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2672 - acc: 0.2689\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 0.2660 - acc: 0.2694\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2618 - acc: 0.2712\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2598 - acc: 0.2720\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2566 - acc: 0.2727\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2537 - acc: 0.2737\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2528 - acc: 0.2739\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2519 - acc: 0.2744\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2500 - acc: 0.2750\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2486 - acc: 0.2754\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2469 - acc: 0.2760\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2453 - acc: 0.2766\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2443 - acc: 0.2771\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2418 - acc: 0.2776\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2405 - acc: 0.2784\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2393 - acc: 0.2789\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2384 - acc: 0.2794\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2367 - acc: 0.2794\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2366 - acc: 0.2793\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2338 - acc: 0.2803\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2322 - acc: 0.2808\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2313 - acc: 0.2812\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2296 - acc: 0.2821\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2298 - acc: 0.2819\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2292 - acc: 0.2819\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2286 - acc: 0.2821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.04      0.07       993\n",
      "           1       0.71      0.82      0.76     17071\n",
      "           2       0.49      0.37      0.42      3250\n",
      "           3       0.84      0.87      0.86     25686\n",
      "           4       0.67      0.43      0.52       487\n",
      "           5       0.51      0.57      0.54     16484\n",
      "           6       0.41      0.19      0.26      7302\n",
      "           7       0.45      0.45      0.45      9073\n",
      "\n",
      "    accuracy                           0.66     80346\n",
      "   macro avg       0.59      0.47      0.49     80346\n",
      "weighted avg       0.64      0.66      0.64     80346\n",
      "\n",
      "Acur√°cia\n",
      "0.4687064699370618\n",
      "Precisao\n",
      "0.6440556154881631\n",
      "Recall\n",
      "0.6585019789410799\n",
      "F1\n",
      "0.6424546593813666\n",
      "[[   36   202    41    60     0   468    80   106]\n",
      " [    0 14063    71   497     8  1776   232   424]\n",
      " [    0   296  1204   397     6   735   114   498]\n",
      " [    0   760   174 22468    58  1114   120   992]\n",
      " [    0    34    13   182   209    16     4    29]\n",
      " [   15  2652   383  1305     7  9433   979  1710]\n",
      " [    0   992   200   546    10  2960  1398  1196]\n",
      " [    3   857   392  1306    16  1882   520  4097]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2749 - acc: 0.2627\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2629 - acc: 0.2653\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2530 - acc: 0.2689\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2488 - acc: 0.2697\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2442 - acc: 0.2712\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2404 - acc: 0.2723\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2387 - acc: 0.2730\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2377 - acc: 0.2732\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2343 - acc: 0.2741\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2329 - acc: 0.2745\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2315 - acc: 0.2751\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2293 - acc: 0.2758\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2283 - acc: 0.2758\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2257 - acc: 0.2770\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2245 - acc: 0.2776\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2234 - acc: 0.2774\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2220 - acc: 0.2780\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2215 - acc: 0.2784\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2198 - acc: 0.2788\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2167 - acc: 0.2800\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2158 - acc: 0.2801\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2152 - acc: 0.2804\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2148 - acc: 0.2806\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2135 - acc: 0.2809\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2116 - acc: 0.2817\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2096 - acc: 0.2826\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2086 - acc: 0.2825\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2080 - acc: 0.2832\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2088 - acc: 0.2828\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2078 - acc: 0.2833\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2057 - acc: 0.2840\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2052 - acc: 0.2841\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2037 - acc: 0.2844\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2036 - acc: 0.2849\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2024 - acc: 0.2851\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2006 - acc: 0.2860\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1982 - acc: 0.2866\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1991 - acc: 0.2862\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1981 - acc: 0.2865\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1966 - acc: 0.2874\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1966 - acc: 0.2871\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1962 - acc: 0.2874\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1962 - acc: 0.2873\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1938 - acc: 0.2885\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1939 - acc: 0.2884\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1933 - acc: 0.2886\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1915 - acc: 0.2890\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1910 - acc: 0.2890\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1910 - acc: 0.2894\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1912 - acc: 0.2891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.05      0.09      1106\n",
      "           1       0.82      0.85      0.84     19038\n",
      "           2       0.66      0.57      0.61      3131\n",
      "           3       0.89      0.93      0.91     27284\n",
      "           4       0.81      0.57      0.67       625\n",
      "           5       0.56      0.65      0.60     17651\n",
      "           6       0.46      0.30      0.36      7797\n",
      "           7       0.58      0.55      0.56     10033\n",
      "\n",
      "    accuracy                           0.73     86665\n",
      "   macro avg       0.68      0.56      0.58     86665\n",
      "weighted avg       0.72      0.73      0.72     86665\n",
      "\n",
      "Acur√°cia\n",
      "0.5582109996717883\n",
      "Precisao\n",
      "0.718783921752657\n",
      "Recall\n",
      "0.7265793572953326\n",
      "F1\n",
      "0.7167011003199442\n",
      "[[   54   108    22    67     1   627   106   121]\n",
      " [    2 16215    64   212     0  1888   292   365]\n",
      " [    1   119  1792   236     2   532    88   361]\n",
      " [    4   261   123 25277    58   827   108   626]\n",
      " [    0    10     3   200   356    25     5    26]\n",
      " [   19  1947   297   939     1 11402  1508  1538]\n",
      " [    3   628   156   426     6  3208  2312  1058]\n",
      " [    2   463   261  1139    13  1994   600  5561]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2363 - acc: 0.2796\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2266 - acc: 0.2823\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2196 - acc: 0.2843\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2173 - acc: 0.2853\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2123 - acc: 0.2867\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2104 - acc: 0.2873\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2107 - acc: 0.2871\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2070 - acc: 0.2884\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2077 - acc: 0.2885\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2036 - acc: 0.2897\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2029 - acc: 0.2899\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2021 - acc: 0.2902\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2005 - acc: 0.2907\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1999 - acc: 0.2910\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1974 - acc: 0.2920\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1966 - acc: 0.2922\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1960 - acc: 0.2925\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1978 - acc: 0.2916\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1969 - acc: 0.2923\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1957 - acc: 0.2922\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1921 - acc: 0.2937\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1937 - acc: 0.2931\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1934 - acc: 0.2930\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1899 - acc: 0.2948\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1886 - acc: 0.2948\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1904 - acc: 0.2943\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1888 - acc: 0.2948\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1882 - acc: 0.2952\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1870 - acc: 0.2957\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1857 - acc: 0.2960\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1852 - acc: 0.2962\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1849 - acc: 0.2961\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1847 - acc: 0.2962\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1840 - acc: 0.2966\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1827 - acc: 0.2972\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1834 - acc: 0.2973\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1821 - acc: 0.2973\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1812 - acc: 0.2978\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1798 - acc: 0.2984\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1802 - acc: 0.2982\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1796 - acc: 0.2983\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1780 - acc: 0.2988\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1788 - acc: 0.2987\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1789 - acc: 0.2986\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1772 - acc: 0.2994\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1782 - acc: 0.2990\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1764 - acc: 0.2996\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1751 - acc: 0.3000\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1753 - acc: 0.2999\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1749 - acc: 0.3001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.10      0.16      1007\n",
      "           1       0.86      0.90      0.88     17292\n",
      "           2       0.76      0.74      0.75      3204\n",
      "           3       0.91      0.96      0.94     26732\n",
      "           4       0.88      0.80      0.84       563\n",
      "           5       0.65      0.70      0.67     16831\n",
      "           6       0.56      0.39      0.46      7486\n",
      "           7       0.67      0.67      0.67      9264\n",
      "\n",
      "    accuracy                           0.79     82379\n",
      "   macro avg       0.74      0.66      0.67     82379\n",
      "weighted avg       0.78      0.79      0.78     82379\n",
      "\n",
      "Acur√°cia\n",
      "0.6555165826685201\n",
      "Precisao\n",
      "0.7793767344002924\n",
      "Recall\n",
      "0.788137753553697\n",
      "F1\n",
      "0.77973566764677\n",
      "[[   96    93    24    41     0   561    91   101]\n",
      " [    2 15563    50   104     0  1163   186   224]\n",
      " [    0    69  2356   174     1   290    67   247]\n",
      " [    0    78    84 25600    41   361    95   473]\n",
      " [    0     0     2    90   449     5     5    12]\n",
      " [   45  1489   242   757     6 11713  1424  1155]\n",
      " [    7   477   134   336     5  2694  2917   916]\n",
      " [    9   245   221   910     8  1189   450  6232]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.2040 - acc: 0.2889\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1979 - acc: 0.2907\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1941 - acc: 0.2917\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1913 - acc: 0.2926\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1896 - acc: 0.2930\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1883 - acc: 0.2939\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1859 - acc: 0.2946\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1840 - acc: 0.2953\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1854 - acc: 0.2946\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1822 - acc: 0.2957\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1811 - acc: 0.2961\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1798 - acc: 0.2969\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1795 - acc: 0.2971\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1789 - acc: 0.2971\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1781 - acc: 0.2974\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1775 - acc: 0.2978\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1766 - acc: 0.2982\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1753 - acc: 0.2985\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1748 - acc: 0.2991\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1750 - acc: 0.2986\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1756 - acc: 0.2983\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1743 - acc: 0.2989\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1738 - acc: 0.2991\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1720 - acc: 0.2998\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1701 - acc: 0.3001\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1709 - acc: 0.3001\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1712 - acc: 0.3000\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1717 - acc: 0.2996\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1693 - acc: 0.3007\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1681 - acc: 0.3014\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1682 - acc: 0.3014\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1686 - acc: 0.3011\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1693 - acc: 0.3009\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1677 - acc: 0.3017\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1669 - acc: 0.3018\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1654 - acc: 0.3023\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1651 - acc: 0.3031\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1653 - acc: 0.3031\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1644 - acc: 0.3035\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1637 - acc: 0.3038\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1644 - acc: 0.3040\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1642 - acc: 0.3035\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1636 - acc: 0.3037\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1622 - acc: 0.3043\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1613 - acc: 0.3041\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1613 - acc: 0.3047\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1606 - acc: 0.3057\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1595 - acc: 0.3065\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1604 - acc: 0.3068\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 13s 10ms/sample - loss: 0.1607 - acc: 0.3061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.12      0.21       928\n",
      "           1       0.90      0.92      0.91     17348\n",
      "           2       0.83      0.81      0.82      3221\n",
      "           3       0.93      0.97      0.95     28693\n",
      "           4       0.86      0.84      0.85       513\n",
      "           5       0.68      0.74      0.71     16591\n",
      "           6       0.60      0.43      0.50      7162\n",
      "           7       0.74      0.73      0.74      9510\n",
      "\n",
      "    accuracy                           0.82     83966\n",
      "   macro avg       0.77      0.70      0.71     83966\n",
      "weighted avg       0.82      0.82      0.82     83966\n",
      "\n",
      "Acur√°cia\n",
      "0.6950903677805752\n",
      "Precisao\n",
      "0.8164463207707093\n",
      "Recall\n",
      "0.823035514374866\n",
      "F1\n",
      "0.8165005847888871\n",
      "[[  116    46    20    37     0   565    62    82]\n",
      " [    5 15882    22    74     0  1041   172   152]\n",
      " [    1    29  2616    89     1   232    53   200]\n",
      " [    1    73    94 27716    50   324    71   364]\n",
      " [    0     0     7    65   429     1     0    11]\n",
      " [   54  1146   181   632     2 12279  1343   954]\n",
      " [    7   355    88   312     9  2578  3103   710]\n",
      " [   13   188   133   830     8  1034   338  6966]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "model = criarRede()\n",
    "\n",
    "for train_index, test_index in kf.split(previsores_trei_vald):\n",
    "  \n",
    "  train_and_evaluate_model(model, previsores_trei_vald[train_index], classes_trei_vald[train_index],\n",
    "                           previsores_trei_vald[test_index], classes_trei_vald[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 700, 200)          97600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 1,307,208\n",
      "Trainable params: 1,307,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cias total\n",
      "[0.36913744110934216, 0.4687064699370618, 0.5582109996717883, 0.6555165826685201, 0.6950903677805752]\n",
      "Precision total\n",
      "[0.5420563258863694, 0.6440556154881631, 0.718783921752657, 0.7793767344002924, 0.8164463207707093]\n",
      "Recalls total\n",
      "[0.5542167151346568, 0.6585019789410799, 0.7265793572953326, 0.788137753553697, 0.823035514374866]\n",
      "F1 total\n",
      "[0.5356439560967332, 0.6424546593813666, 0.7167011003199442, 0.77973566764677, 0.8165005847888871]\n"
     ]
    }
   ],
   "source": [
    "print('Acur√°cias total')\n",
    "print(accuq8)\n",
    "print('Precision total')\n",
    "print(precisionsq8)\n",
    "print('Recalls total')\n",
    "print(recallsq8)\n",
    "print('F1 total')\n",
    "print(f1q8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1810 - acc: 0.3005\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1773 - acc: 0.3012\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1742 - acc: 0.3022\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1731 - acc: 0.3031\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1720 - acc: 0.3048\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1725 - acc: 0.3031\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1720 - acc: 0.3031\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1697 - acc: 0.3036\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1678 - acc: 0.3040\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1679 - acc: 0.3043\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1675 - acc: 0.3043\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1657 - acc: 0.3048\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1647 - acc: 0.3050\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1642 - acc: 0.3053\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1650 - acc: 0.3050\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1644 - acc: 0.3056\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1652 - acc: 0.3061\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1648 - acc: 0.3060\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1655 - acc: 0.3051\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1643 - acc: 0.3053\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1636 - acc: 0.3055\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1613 - acc: 0.3068\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1625 - acc: 0.3069\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1623 - acc: 0.3064\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1599 - acc: 0.3075\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1598 - acc: 0.3074\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1611 - acc: 0.3066\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1617 - acc: 0.3062\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1624 - acc: 0.3057\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1601 - acc: 0.3069\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1593 - acc: 0.3067\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1586 - acc: 0.3073\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1582 - acc: 0.3072\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1588 - acc: 0.3075\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1583 - acc: 0.3078\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1590 - acc: 0.3075\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1582 - acc: 0.3078\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1583 - acc: 0.3079\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1568 - acc: 0.3084\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1564 - acc: 0.3090\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1564 - acc: 0.3084\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1573 - acc: 0.3081\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1570 - acc: 0.3093\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1559 - acc: 0.3096\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1562 - acc: 0.3096\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1563 - acc: 0.3100\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1556 - acc: 0.3096\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1553 - acc: 0.3084\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1542 - acc: 0.3094\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 16s 10ms/sample - loss: 0.1551 - acc: 0.3096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.09      0.15      1319\n",
      "           1       0.61      0.67      0.64     21565\n",
      "           2       0.40      0.27      0.32      4144\n",
      "           3       0.73      0.74      0.73     34429\n",
      "           4       0.57      0.27      0.37       723\n",
      "           5       0.46      0.52      0.49     20463\n",
      "           6       0.34      0.26      0.30      9014\n",
      "           7       0.41      0.40      0.41     11705\n",
      "\n",
      "    accuracy                           0.57    103362\n",
      "   macro avg       0.51      0.40      0.43    103362\n",
      "weighted avg       0.57      0.57      0.56    103362\n",
      "\n",
      "Acur√°cia\n",
      "0.4032878110188133\n",
      "Precisao\n",
      "0.5653594881288028\n",
      "Recall\n",
      "0.572415394438962\n",
      "F1\n",
      "0.5647358875917484\n",
      "[[  118   268    27   177     1   505   117   106]\n",
      " [   17 14508   199  2316     2  3011   654   858]\n",
      " [    1   464  1102   936     4   782   267   588]\n",
      " [    9  3017   451 25525   111  2816   707  1793]\n",
      " [    0    65    19   277   198    80    20    64]\n",
      " [   46  3113   367  2587    12 10695  1767  1876]\n",
      " [   15  1154   200  1126     5  2849  2373  1292]\n",
      " [   12  1109   375  2160    14  2382  1006  4647]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(model, previsores_trei_vald, classes_trei_vald,\n",
    "                           previsores_testes, classes_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
