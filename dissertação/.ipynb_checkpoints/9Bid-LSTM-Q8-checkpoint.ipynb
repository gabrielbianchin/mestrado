{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 20:28].values\n",
    "classes = np.reshape(classes, (2000, 700, 8))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    #model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(8, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuq8 = []\n",
    "precisionsq8 = []\n",
    "recallsq8 = []\n",
    "f1q8 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 50, verbose = 1, batch_size = 32)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 8))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 8))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accuq8.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisionsq8.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recallsq8.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1q8.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acurácia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "previsores_trei_vald, previsores_testes, classes_trei_vald, classes_testes = train_test_split(previsores, classes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 21:12:34.202016  2864 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 21:12:34.215978  2864 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 21:12:34.217945  2864 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 21:12:34.220934  2864 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 21:12:36.397671  2864 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 29s 23ms/sample - loss: 0.6340 - acc: 0.1227\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6312 - acc: 0.1163\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6200 - acc: 0.1195\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6191 - acc: 0.1196\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6183 - acc: 0.1203\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6176 - acc: 0.1203\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6174 - acc: 0.1201\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6166 - acc: 0.1207\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6163 - acc: 0.1209\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6161 - acc: 0.1209\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6159 - acc: 0.1212\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6167 - acc: 0.1207\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6160 - acc: 0.1209\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6157 - acc: 0.1210\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6156 - acc: 0.1210\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6157 - acc: 0.1209\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6156 - acc: 0.1210\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6155 - acc: 0.1212\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6154 - acc: 0.1212\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6154 - acc: 0.1214\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1219\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6146 - acc: 0.1220\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6159 - acc: 0.1205\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6154 - acc: 0.1206\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6153 - acc: 0.1209\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6153 - acc: 0.1210\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6153 - acc: 0.1209\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6153 - acc: 0.1209\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6152 - acc: 0.1209\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6154 - acc: 0.1209\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6152 - acc: 0.1209\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6153 - acc: 0.1209\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6149 - acc: 0.1209\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6150 - acc: 0.1209\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6149 - acc: 0.1210\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6148 - acc: 0.1209\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6147 - acc: 0.1210\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6149 - acc: 0.1210\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6147 - acc: 0.1209\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6146 - acc: 0.1210\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6147 - acc: 0.1210\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6146 - acc: 0.1210\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6149 - acc: 0.1209\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6147 - acc: 0.1210\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6145 - acc: 0.1209\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6147 - acc: 0.1209\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6146 - acc: 0.1210\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6146 - acc: 0.1210\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6146 - acc: 0.1210\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6144 - acc: 0.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       969\n",
      "           1       0.32      0.02      0.03     17842\n",
      "           2       0.00      0.00      0.00      3178\n",
      "           3       0.35      0.99      0.51     29213\n",
      "           4       0.00      0.00      0.00       634\n",
      "           5       0.58      0.04      0.08     16824\n",
      "           6       0.00      0.00      0.00      7459\n",
      "           7       0.00      0.00      0.00      9397\n",
      "\n",
      "    accuracy                           0.35     85516\n",
      "   macro avg       0.16      0.13      0.08     85516\n",
      "weighted avg       0.30      0.35      0.20     85516\n",
      "\n",
      "Acurácia\n",
      "0.13094704089132886\n",
      "Precisao\n",
      "0.29851584920454743\n",
      "Recall\n",
      "0.34920950465409983\n",
      "F1\n",
      "0.19789863864135665\n",
      "[[    0    13     0   943     0    13     0     0]\n",
      " [    0   307     0 17321     0   214     0     0]\n",
      " [    0    39     0  3105     0    34     0     0]\n",
      " [    0   249     0 28817     0   147     0     0]\n",
      " [    0     0     0   634     0     0     0     0]\n",
      " [    0   208     0 15877     0   739     0     0]\n",
      " [    0    74     0  7321     0    64     0     0]\n",
      " [    0    70     0  9258     0    69     0     0]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6210 - acc: 0.1243\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6209 - acc: 0.1243\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6211 - acc: 0.1243\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6210 - acc: 0.1243\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6212 - acc: 0.1243\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6212 - acc: 0.1242\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6211 - acc: 0.1243\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6208 - acc: 0.1242\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6211 - acc: 0.1243\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6211 - acc: 0.1243\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6210 - acc: 0.1243\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6209 - acc: 0.1243\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6209 - acc: 0.1243\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6208 - acc: 0.1242\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6206 - acc: 0.1243\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6209 - acc: 0.1243\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1243\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6209 - acc: 0.1243\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6209 - acc: 0.1243\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6207 - acc: 0.1243\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6206 - acc: 0.1243\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1243\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1242\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1242\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1243\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1243\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1243\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1243\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1243\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1242\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1243\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1243\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1243\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1243\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1243\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       983\n",
      "           1       0.37      0.02      0.04     17425\n",
      "           2       0.00      0.00      0.00      3120\n",
      "           3       0.33      0.99      0.49     26056\n",
      "           4       0.00      0.00      0.00       480\n",
      "           5       0.60      0.05      0.08     16815\n",
      "           6       0.00      0.00      0.00      7175\n",
      "           7       0.00      0.00      0.00      9388\n",
      "\n",
      "    accuracy                           0.33     81442\n",
      "   macro avg       0.16      0.13      0.08     81442\n",
      "weighted avg       0.31      0.33      0.18     81442\n",
      "\n",
      "Acurácia\n",
      "0.13193412164267995\n",
      "Precisao\n",
      "0.30795483643234256\n",
      "Recall\n",
      "0.3303332432897031\n",
      "F1\n",
      "0.18251690185554503\n",
      "[[    0    10     0   956     0    17     0     0]\n",
      " [    0   356     0 16855     0   214     0     0]\n",
      " [    0    31     0  3058     0    31     0     0]\n",
      " [    0   177     0 25779     0   100     0     0]\n",
      " [    0     0     0   480     0     0     0     0]\n",
      " [    0   246     0 15801     0   768     0     0]\n",
      " [    0    77     0  7018     0    80     0     0]\n",
      " [    0    58     0  9262     0    68     0     0]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1230\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1230\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1231\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1231\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6209 - acc: 0.1231\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1230\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1232\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1231\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1229\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1230\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1230\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1231\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1232\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1230\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1230\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1232\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1230\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1230\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1231\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1232\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1232\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6208 - acc: 0.1230\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6206 - acc: 0.1231\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1230\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1231\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6205 - acc: 0.1231\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6207 - acc: 0.1230\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       954\n",
      "           1       0.32      0.02      0.04     16710\n",
      "           2       0.00      0.00      0.00      3234\n",
      "           3       0.34      0.98      0.51     27365\n",
      "           4       0.00      0.00      0.00       572\n",
      "           5       0.58      0.05      0.08     16458\n",
      "           6       0.00      0.00      0.00      6988\n",
      "           7       0.00      0.00      0.00      9280\n",
      "\n",
      "    accuracy                           0.34     81561\n",
      "   macro avg       0.16      0.13      0.08     81561\n",
      "weighted avg       0.30      0.34      0.19     81561\n",
      "\n",
      "Acurácia\n",
      "0.13112104505219294\n",
      "Precisao\n",
      "0.29829421366808384\n",
      "Recall\n",
      "0.34343620112553797\n",
      "F1\n",
      "0.19375253246362892\n",
      "[[    0    16     0   920     0    18     0     0]\n",
      " [    0   311     0 16188     0   211     0     0]\n",
      " [    0    31     0  3171     0    32     0     0]\n",
      " [    0   261     0 26952     0   152     0     0]\n",
      " [    0     0     0   572     0     0     0     0]\n",
      " [    0   215     0 15495     0   748     0     0]\n",
      " [    0    49     0  6880     0    59     0     0]\n",
      " [    0    77     0  9143     0    60     0     0]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1235\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6151 - acc: 0.1234\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6152 - acc: 0.1233\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 20s 16ms/sample - loss: 0.6151 - acc: 0.1235\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6150 - acc: 0.1233\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6153 - acc: 0.1234\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6152 - acc: 0.1233\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 19s 14ms/sample - loss: 0.6150 - acc: 0.1233\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 20s 16ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6150 - acc: 0.1233\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6152 - acc: 0.1233\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6152 - acc: 0.1233\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6150 - acc: 0.1235\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6154 - acc: 0.1231\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1234\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6152 - acc: 0.1233\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6150 - acc: 0.1233\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6152 - acc: 0.1233\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 19s 15ms/sample - loss: 0.6151 - acc: 0.1234\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6150 - acc: 0.1234\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6153 - acc: 0.1233\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6151 - acc: 0.1234\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1234\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1233\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1233\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6152 - acc: 0.1233\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1234\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1235\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1232\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1234\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1234\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1234\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1234\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1234\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6150 - acc: 0.1233\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 18s 14ms/sample - loss: 0.6150 - acc: 0.1234\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6150 - acc: 0.1233\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6149 - acc: 0.1234\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1234\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6152 - acc: 0.1233\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6151 - acc: 0.1233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1052\n",
      "           1       0.34      0.02      0.04     17790\n",
      "           2       0.00      0.00      0.00      3329\n",
      "           3       0.33      0.99      0.49     26962\n",
      "           4       0.00      0.00      0.00       596\n",
      "           5       0.63      0.05      0.09     16899\n",
      "           6       0.00      0.00      0.00      7567\n",
      "           7       0.00      0.00      0.00      9604\n",
      "\n",
      "    accuracy                           0.33     83799\n",
      "   macro avg       0.16      0.13      0.08     83799\n",
      "weighted avg       0.31      0.33      0.18     83799\n",
      "\n",
      "Acurácia\n",
      "0.13170843836900695\n",
      "Precisao\n",
      "0.3054612400477828\n",
      "Recall\n",
      "0.331268869556916\n",
      "F1\n",
      "0.18318473464767399\n",
      "[[    0    11     0  1021     0    20     0     0]\n",
      " [    0   329     0 17256     0   205     0     0]\n",
      " [    0    57     0  3241     0    31     0     0]\n",
      " [    0   218     0 26626     0   118     0     0]\n",
      " [    0     0     0   596     0     0     0     0]\n",
      " [    0   214     0 15880     0   805     0     0]\n",
      " [    0    53     0  7458     0    56     0     0]\n",
      " [    0    72     0  9491     0    41     0     0]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6224 - acc: 0.1257\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6224 - acc: 0.1256\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6224 - acc: 0.1256\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6224 - acc: 0.1256\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1255\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1255\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6224 - acc: 0.1257\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1255\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1257\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6224 - acc: 0.1257\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1257\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6224 - acc: 0.1255\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1255\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1257\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6224 - acc: 0.1254\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1257\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1256\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1255\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1256\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1257\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1255\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6226 - acc: 0.1256\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1256\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1256\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1257\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1256\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 17s 14ms/sample - loss: 0.6223 - acc: 0.1255\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1257\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1257\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1257\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6223 - acc: 0.1256\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1257\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1255\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 17s 13ms/sample - loss: 0.6222 - acc: 0.1256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       987\n",
      "           1       0.30      0.04      0.07     17600\n",
      "           2       0.00      0.00      0.00      2866\n",
      "           3       0.32      0.97      0.48     25118\n",
      "           4       0.00      0.00      0.00       512\n",
      "           5       0.69      0.04      0.08     16626\n",
      "           6       0.00      0.00      0.00      7385\n",
      "           7       0.00      0.00      0.00      9034\n",
      "\n",
      "    accuracy                           0.32     80128\n",
      "   macro avg       0.16      0.13      0.08     80128\n",
      "weighted avg       0.31      0.32      0.18     80128\n",
      "\n",
      "Acurácia\n",
      "0.13134998783597843\n",
      "Precisao\n",
      "0.3101978941359645\n",
      "Recall\n",
      "0.32156050319488816\n",
      "F1\n",
      "0.18068724505843126\n",
      "[[    0    21     0   948     0    18     0     0]\n",
      " [    0   675     0 16805     0   120     0     0]\n",
      " [    0    60     0  2794     0    12     0     0]\n",
      " [    0   611     0 24426     0    81     0     0]\n",
      " [    0    10     0   501     0     1     0     0]\n",
      " [    0   488     0 15473     0   665     0     0]\n",
      " [    0   165     0  7187     0    33     0     0]\n",
      " [    0   184     0  8820     0    30     0     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "model = criarRede()\n",
    "\n",
    "for train_index, test_index in kf.split(previsores_trei_vald):\n",
    "  \n",
    "  train_and_evaluate_model(model, previsores_trei_vald[train_index], classes_trei_vald[train_index],\n",
    "                           previsores_trei_vald[test_index], classes_trei_vald[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 700, 200)          97600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 1,790,408\n",
      "Trainable params: 1,790,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácias total\n",
      "[0.13094704089132886, 0.13193412164267995, 0.13112104505219294, 0.13170843836900695, 0.13134998783597843]\n",
      "Precision total\n",
      "[0.29851584920454743, 0.30795483643234256, 0.29829421366808384, 0.3054612400477828, 0.3101978941359645]\n",
      "Recalls total\n",
      "[0.34920950465409983, 0.3303332432897031, 0.34343620112553797, 0.331268869556916, 0.32156050319488816]\n",
      "F1 total\n",
      "[0.19789863864135665, 0.18251690185554503, 0.19375253246362892, 0.18318473464767399, 0.18068724505843126]\n"
     ]
    }
   ],
   "source": [
    "print('Acurácias total')\n",
    "print(accuq8)\n",
    "print('Precision total')\n",
    "print(precisionsq8)\n",
    "print('Recalls total')\n",
    "print(recallsq8)\n",
    "print('F1 total')\n",
    "print(f1q8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1236\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 22s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6184 - acc: 0.1234\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 22s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 22s 13ms/sample - loss: 0.6184 - acc: 0.1236\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6184 - acc: 0.1233\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1234\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 22s 13ms/sample - loss: 0.6184 - acc: 0.1235\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6186 - acc: 0.1235\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 22s 13ms/sample - loss: 0.6183 - acc: 0.1236\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 22s 13ms/sample - loss: 0.6182 - acc: 0.1236\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 22s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1236\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1234\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1236\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 22s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1236\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 22s 14ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6182 - acc: 0.1235\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1236\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.6183 - acc: 0.1235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1319\n",
      "           1       0.29      0.05      0.08     21565\n",
      "           2       0.00      0.00      0.00      4144\n",
      "           3       0.34      0.97      0.50     34429\n",
      "           4       0.00      0.00      0.00       723\n",
      "           5       0.68      0.04      0.08     20463\n",
      "           6       0.00      0.00      0.00      9014\n",
      "           7       0.00      0.00      0.00     11705\n",
      "\n",
      "    accuracy                           0.34    103362\n",
      "   macro avg       0.16      0.13      0.08    103362\n",
      "weighted avg       0.31      0.34      0.20    103362\n",
      "\n",
      "Acurácia\n",
      "0.13214091809729842\n",
      "Precisao\n",
      "0.30773856672887984\n",
      "Recall\n",
      "0.3408989764129951\n",
      "F1\n",
      "0.19898481131298673\n",
      "[[    0    44     0  1258     0    17     0     0]\n",
      " [    0  1005     0 20408     0   152     0     0]\n",
      " [    0   139     0  3977     0    28     0     0]\n",
      " [    0   938     0 33410     0    81     0     0]\n",
      " [    0    15     0   708     0     0     0     0]\n",
      " [    0   773     0 18869     0   821     0     0]\n",
      " [    0   325     0  8637     0    52     0     0]\n",
      " [    0   287     0 11369     0    49     0     0]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(model, previsores_trei_vald, classes_trei_vald,\n",
    "                           previsores_testes, classes_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
