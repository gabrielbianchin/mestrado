{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 20:28].values\n",
    "classes = np.reshape(classes, (2000, 700, 8))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(LSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(8, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn = criarRede, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 50, verbose = 1, batch_size = 32)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 8))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 8))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "previsores_trei_vald, previsores_testes, classes_trei_vald, classes_testes = train_test_split(previsores, classes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 177s 138ms/step - loss: 1.7337 - acc: 0.3348\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 173s 135ms/step - loss: 1.5521 - acc: 0.4259\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 175s 137ms/step - loss: 1.4790 - acc: 0.4512\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.4353 - acc: 0.4691\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.4169 - acc: 0.4783\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 173s 135ms/step - loss: 1.3996 - acc: 0.4873\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 173s 135ms/step - loss: 1.3865 - acc: 0.4935\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 174s 136ms/step - loss: 1.3728 - acc: 0.5004\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 174s 136ms/step - loss: 1.3639 - acc: 0.5042\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 173s 135ms/step - loss: 1.3490 - acc: 0.5106\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 174s 136ms/step - loss: 1.3525 - acc: 0.5089\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 173s 135ms/step - loss: 1.3425 - acc: 0.5128\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 174s 136ms/step - loss: 1.3433 - acc: 0.5126\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.3293 - acc: 0.5172\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 172s 135ms/step - loss: 1.3279 - acc: 0.5188\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 172s 135ms/step - loss: 1.3212 - acc: 0.5210\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 173s 135ms/step - loss: 1.3130 - acc: 0.5235\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 172s 135ms/step - loss: 1.3071 - acc: 0.5261\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.3084 - acc: 0.5261\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.3039 - acc: 0.5283\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 172s 135ms/step - loss: 1.2958 - acc: 0.5300\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 171s 133ms/step - loss: 1.2930 - acc: 0.5327\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.2861 - acc: 0.5340\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.2875 - acc: 0.5336\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.2776 - acc: 0.5383\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.2722 - acc: 0.5404\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.2691 - acc: 0.5419\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.2598 - acc: 0.5454\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 173s 135ms/step - loss: 1.2551 - acc: 0.5472\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.2518 - acc: 0.5479\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 170s 133ms/step - loss: 1.2429 - acc: 0.5507\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.2400 - acc: 0.5529\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.2382 - acc: 0.5524\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.2281 - acc: 0.5569\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.2219 - acc: 0.5604\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.2133 - acc: 0.5616\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 172s 135ms/step - loss: 1.2074 - acc: 0.5643\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.2001 - acc: 0.5658\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.1925 - acc: 0.5699\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.1802 - acc: 0.5739\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.1686 - acc: 0.5782\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.1630 - acc: 0.5807\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 172s 134ms/step - loss: 1.1572 - acc: 0.5828\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 172s 135ms/step - loss: 1.1479 - acc: 0.5849\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 171s 134ms/step - loss: 1.1368 - acc: 0.5892\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 172s 135ms/step - loss: 1.1276 - acc: 0.5918\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 173s 135ms/step - loss: 1.1251 - acc: 0.5931\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 174s 136ms/step - loss: 1.1156 - acc: 0.5957\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 174s 136ms/step - loss: 1.1089 - acc: 0.5982\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 175s 136ms/step - loss: 1.1157 - acc: 0.5963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       960\n",
      "           1       0.56      0.63      0.59     16710\n",
      "           2       0.29      0.06      0.10      3008\n",
      "           3       0.64      0.81      0.71     26918\n",
      "           4       0.49      0.08      0.14       518\n",
      "           5       0.42      0.48      0.45     15797\n",
      "           6       0.35      0.02      0.04      6993\n",
      "           7       0.38      0.33      0.35      9015\n",
      "\n",
      "    accuracy                           0.54     79919\n",
      "   macro avg       0.39      0.30      0.30     79919\n",
      "weighted avg       0.50      0.54      0.50     79919\n",
      "\n",
      "Acur√°cia\n",
      "0.3016716546874587\n",
      "Precisao\n",
      "0.5026077335455061\n",
      "Recall\n",
      "0.5414231909808681\n",
      "F1\n",
      "0.5012748091991024\n",
      "[[    0   263    10   216     0   371    13    87]\n",
      " [    0 10512    42  3251     9  2224    45   627]\n",
      " [    0   448   177  1046     0   854    11   472]\n",
      " [    0  2099   110 21792    22  1926    19   950]\n",
      " [    0    55    12   348    42    37     1    23]\n",
      " [    0  3043   109  3442     2  7607   127  1467]\n",
      " [    0  1142    49  1566     2  2876   154  1204]\n",
      " [    1  1120   108  2642     8  2074    76  2986]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 174s 136ms/step - loss: 1.1774 - acc: 0.5776\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 176s 137ms/step - loss: 1.1535 - acc: 0.5848\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 176s 137ms/step - loss: 1.1358 - acc: 0.5908\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 176s 137ms/step - loss: 1.1216 - acc: 0.5952\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 176s 137ms/step - loss: 1.1105 - acc: 0.5991\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 177s 138ms/step - loss: 1.0982 - acc: 0.6034\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 176s 138ms/step - loss: 1.0914 - acc: 0.6049\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 176s 137ms/step - loss: 1.0868 - acc: 0.6063\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.0798 - acc: 0.6086\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 180s 141ms/step - loss: 1.0685 - acc: 0.6119\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.0634 - acc: 0.6140\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.0510 - acc: 0.6180\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 177s 138ms/step - loss: 1.0446 - acc: 0.6196\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.0352 - acc: 0.6234\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.0387 - acc: 0.6218\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.0281 - acc: 0.6246\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 1.0176 - acc: 0.6288\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 1.0118 - acc: 0.6309\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.0121 - acc: 0.6307\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.0036 - acc: 0.6329\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9960 - acc: 0.6350\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 177s 138ms/step - loss: 0.9815 - acc: 0.6397\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 177s 138ms/step - loss: 0.9821 - acc: 0.6395\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9735 - acc: 0.6431\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 179s 139ms/step - loss: 0.9680 - acc: 0.6446\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9619 - acc: 0.6458\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9578 - acc: 0.6477\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9573 - acc: 0.6475\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9548 - acc: 0.6481\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9463 - acc: 0.6507\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9427 - acc: 0.6534\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9351 - acc: 0.6553\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 0.9287 - acc: 0.6568\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9351 - acc: 0.6558\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9244 - acc: 0.6581\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9197 - acc: 0.6602\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9160 - acc: 0.6601\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9081 - acc: 0.6644\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9036 - acc: 0.6646\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8999 - acc: 0.6656\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 177s 138ms/step - loss: 0.8935 - acc: 0.6680\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9008 - acc: 0.6657\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8921 - acc: 0.6690\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8845 - acc: 0.6712\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 177s 139ms/step - loss: 0.8806 - acc: 0.6719\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8762 - acc: 0.6736\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8713 - acc: 0.6758\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8722 - acc: 0.6750\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8729 - acc: 0.6746\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8648 - acc: 0.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       950\n",
      "           1       0.62      0.71      0.66     17200\n",
      "           2       0.36      0.19      0.25      2969\n",
      "           3       0.74      0.81      0.78     26411\n",
      "           4       0.56      0.35      0.43       433\n",
      "           5       0.44      0.54      0.49     16656\n",
      "           6       0.38      0.06      0.10      7212\n",
      "           7       0.39      0.38      0.39      8985\n",
      "\n",
      "    accuracy                           0.59     80816\n",
      "   macro avg       0.44      0.38      0.39     80816\n",
      "weighted avg       0.56      0.59      0.56     80816\n",
      "\n",
      "Acur√°cia\n",
      "0.3813488113397844\n",
      "Precisao\n",
      "0.5594777164259992\n",
      "Recall\n",
      "0.5852801425460304\n",
      "F1\n",
      "0.5583299999422009\n",
      "[[    0   261    14   129     0   433    20    93]\n",
      " [    0 12188   127  1541    13  2572    66   693]\n",
      " [    0   395   570   637     3   872    37   455]\n",
      " [    0  1460   185 21487    72  1895    34  1278]\n",
      " [    0    24    10   173   153    53     1    19]\n",
      " [    0  3215   268  2208    14  9053   268  1630]\n",
      " [    0  1152   153   985     3  3290   416  1213]\n",
      " [    0   980   264  1792    17  2259   240  3433]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9850 - acc: 0.6437\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9605 - acc: 0.6483\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 177s 139ms/step - loss: 0.9870 - acc: 0.6401\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9515 - acc: 0.6508\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9215 - acc: 0.6606\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9057 - acc: 0.6662\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9025 - acc: 0.6669\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8936 - acc: 0.6687\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8868 - acc: 0.6713\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.8911 - acc: 0.6692\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8806 - acc: 0.6733\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8748 - acc: 0.6740\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 0.8734 - acc: 0.6759\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8690 - acc: 0.6776\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8735 - acc: 0.6751\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8674 - acc: 0.6766\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8642 - acc: 0.6787\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8559 - acc: 0.6805\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8460 - acc: 0.6842\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8453 - acc: 0.6844\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8426 - acc: 0.6849\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8431 - acc: 0.6845\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8362 - acc: 0.6879\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 179s 139ms/step - loss: 0.8312 - acc: 0.6884\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8359 - acc: 0.6877\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 0.8325 - acc: 0.6877\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 177s 138ms/step - loss: 0.8239 - acc: 0.6908\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 179s 139ms/step - loss: 0.8227 - acc: 0.6916\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.3228 - acc: 0.5383\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.4320 - acc: 0.4823\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.3425 - acc: 0.5165\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.3045 - acc: 0.5307\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.2820 - acc: 0.5400\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 1.2604 - acc: 0.5462\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.2389 - acc: 0.5531\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.2302 - acc: 0.5575\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.2210 - acc: 0.5605\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 180s 141ms/step - loss: 1.2032 - acc: 0.5661\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.1860 - acc: 0.5719\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.1813 - acc: 0.5729\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.1670 - acc: 0.5777\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 1.1476 - acc: 0.5850\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.1313 - acc: 0.5903\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.1223 - acc: 0.5935\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.1092 - acc: 0.5976\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.0920 - acc: 0.6027\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 1.0740 - acc: 0.6088\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 1.0470 - acc: 0.6188\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 1.0316 - acc: 0.6224\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 180s 141ms/step - loss: 1.0037 - acc: 0.6315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1030\n",
      "           1       0.65      0.68      0.67     17050\n",
      "           2       0.43      0.17      0.25      3367\n",
      "           3       0.72      0.86      0.79     27914\n",
      "           4       0.57      0.26      0.36       663\n",
      "           5       0.44      0.58      0.50     17299\n",
      "           6       0.37      0.04      0.07      7450\n",
      "           7       0.43      0.36      0.39      9733\n",
      "\n",
      "    accuracy                           0.60     84506\n",
      "   macro avg       0.45      0.37      0.38     84506\n",
      "weighted avg       0.56      0.60      0.56     84506\n",
      "\n",
      "Acur√°cia\n",
      "0.369693773261037\n",
      "Precisao\n",
      "0.5646484410093369\n",
      "Recall\n",
      "0.5958866826024187\n",
      "F1\n",
      "0.5614532833531092\n",
      "[[    0   193    12   180     1   552    12    80]\n",
      " [    0 11633    61  1846    11  2907    56   536]\n",
      " [    0   399   580   866     8  1008    34   472]\n",
      " [    0  1058   131 24082    70  1701    28   844]\n",
      " [    0    40    20   347   171    43     5    37]\n",
      " [    0  2637   226  2703    11 10101   196  1425]\n",
      " [    0   942   134  1029    13  3873   291  1168]\n",
      " [    0   925   199  2292    14  2635   170  3498]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 1.0270 - acc: 0.6268\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9864 - acc: 0.6392\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9564 - acc: 0.6480\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9305 - acc: 0.6569\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.9151 - acc: 0.6621\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.9013 - acc: 0.6667\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8860 - acc: 0.6703\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8691 - acc: 0.6771\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8637 - acc: 0.6783\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8535 - acc: 0.6820\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8463 - acc: 0.6842\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8399 - acc: 0.6865\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8362 - acc: 0.6875\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 0.8331 - acc: 0.6885\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 178s 139ms/step - loss: 0.8323 - acc: 0.6887\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8254 - acc: 0.6912\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 0.8185 - acc: 0.6938\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 179s 140ms/step - loss: 0.8129 - acc: 0.6953\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 180s 140ms/step - loss: 0.8092 - acc: 0.6962\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.8069 - acc: 0.6970\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.8037 - acc: 0.6979\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7981 - acc: 0.6999\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7945 - acc: 0.7016\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.7942 - acc: 0.7011\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7898 - acc: 0.7035\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7859 - acc: 0.7044\n",
      "Epoch 27/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7826 - acc: 0.7050\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7810 - acc: 0.7064\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7763 - acc: 0.7073\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.7744 - acc: 0.7082\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 185s 145ms/step - loss: 0.7723 - acc: 0.7094\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7735 - acc: 0.7074\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7645 - acc: 0.7112\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7616 - acc: 0.7122\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7615 - acc: 0.7124\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7610 - acc: 0.7119\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7608 - acc: 0.7128\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7581 - acc: 0.7138\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.7616 - acc: 0.7122\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.7510 - acc: 0.7158\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7520 - acc: 0.7157\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 184s 143ms/step - loss: 0.7509 - acc: 0.7162\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7439 - acc: 0.7181\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7418 - acc: 0.7191\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 181s 142ms/step - loss: 0.7417 - acc: 0.7198\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 181s 142ms/step - loss: 0.7390 - acc: 0.7203\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7423 - acc: 0.7189\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7340 - acc: 0.7216\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 184s 143ms/step - loss: 0.7334 - acc: 0.7225\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7309 - acc: 0.7227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1027\n",
      "           1       0.73      0.81      0.76     17644\n",
      "           2       0.48      0.39      0.43      3061\n",
      "           3       0.83      0.88      0.86     25536\n",
      "           4       0.76      0.33      0.46       559\n",
      "           5       0.48      0.61      0.54     16709\n",
      "           6       0.42      0.09      0.15      7500\n",
      "           7       0.44      0.45      0.44      9018\n",
      "\n",
      "    accuracy                           0.65     81054\n",
      "   macro avg       0.52      0.44      0.46     81054\n",
      "weighted avg       0.63      0.65      0.63     81054\n",
      "\n",
      "Acur√°cia\n",
      "0.4445714801649382\n",
      "Precisao\n",
      "0.6323630327798831\n",
      "Recall\n",
      "0.6534779282947171\n",
      "F1\n",
      "0.6301756463084252\n",
      "[[    0   174    28    97     0   593    39    96]\n",
      " [    0 14212   113   364     5  2260   104   586]\n",
      " [    0   263  1194   382     6   738    31   447]\n",
      " [    0   558   186 22448    39  1338    38   929]\n",
      " [    0     7    15   290   186    38     0    23]\n",
      " [    0  2688   376  1338     3 10219   454  1631]\n",
      " [    0   942   226   585     4  3669   693  1381]\n",
      " [    0   728   358  1402     3  2237   275  4015]]\n",
      "Epoch 1/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.8286 - acc: 0.6931\n",
      "Epoch 2/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.8098 - acc: 0.6976\n",
      "Epoch 3/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7901 - acc: 0.7033\n",
      "Epoch 4/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.7848 - acc: 0.7052\n",
      "Epoch 5/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.7723 - acc: 0.7094\n",
      "Epoch 6/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7640 - acc: 0.7119\n",
      "Epoch 7/50\n",
      "1280/1280 [==============================] - 184s 143ms/step - loss: 0.7612 - acc: 0.7131\n",
      "Epoch 8/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7578 - acc: 0.7140\n",
      "Epoch 9/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7588 - acc: 0.7130\n",
      "Epoch 10/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.7511 - acc: 0.7169\n",
      "Epoch 11/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7505 - acc: 0.7162\n",
      "Epoch 12/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7469 - acc: 0.7174\n",
      "Epoch 13/50\n",
      "1280/1280 [==============================] - 184s 143ms/step - loss: 0.7424 - acc: 0.7188\n",
      "Epoch 14/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7374 - acc: 0.7204\n",
      "Epoch 15/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7373 - acc: 0.7204\n",
      "Epoch 16/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7313 - acc: 0.7218\n",
      "Epoch 17/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7342 - acc: 0.7211\n",
      "Epoch 18/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7311 - acc: 0.7225\n",
      "Epoch 19/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7305 - acc: 0.7224\n",
      "Epoch 20/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.7239 - acc: 0.7252\n",
      "Epoch 21/50\n",
      "1280/1280 [==============================] - 182s 143ms/step - loss: 0.7224 - acc: 0.7264\n",
      "Epoch 22/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7215 - acc: 0.7257\n",
      "Epoch 23/50\n",
      "1280/1280 [==============================] - 184s 143ms/step - loss: 0.7175 - acc: 0.7281\n",
      "Epoch 24/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7147 - acc: 0.7285\n",
      "Epoch 25/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7140 - acc: 0.7287\n",
      "Epoch 26/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7129 - acc: 0.7291\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7089 - acc: 0.7302\n",
      "Epoch 28/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7100 - acc: 0.7296\n",
      "Epoch 29/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7071 - acc: 0.7310\n",
      "Epoch 30/50\n",
      "1280/1280 [==============================] - 184s 143ms/step - loss: 0.7046 - acc: 0.7316\n",
      "Epoch 31/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.7039 - acc: 0.7323\n",
      "Epoch 32/50\n",
      "1280/1280 [==============================] - 182s 143ms/step - loss: 0.7034 - acc: 0.7321\n",
      "Epoch 33/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.6969 - acc: 0.7352\n",
      "Epoch 34/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.6991 - acc: 0.7330\n",
      "Epoch 35/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.6969 - acc: 0.7347\n",
      "Epoch 36/50\n",
      "1280/1280 [==============================] - 184s 143ms/step - loss: 0.6943 - acc: 0.7350\n",
      "Epoch 37/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.6991 - acc: 0.7342\n",
      "Epoch 38/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.7009 - acc: 0.7331\n",
      "Epoch 39/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.6962 - acc: 0.7353\n",
      "Epoch 40/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.6904 - acc: 0.7370\n",
      "Epoch 41/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.6865 - acc: 0.7382\n",
      "Epoch 42/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.6837 - acc: 0.7395\n",
      "Epoch 43/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.6815 - acc: 0.7402\n",
      "Epoch 44/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.6785 - acc: 0.7415\n",
      "Epoch 45/50\n",
      "1280/1280 [==============================] - 182s 142ms/step - loss: 0.6829 - acc: 0.7396\n",
      "Epoch 46/50\n",
      "1280/1280 [==============================] - 184s 143ms/step - loss: 0.6807 - acc: 0.7401\n",
      "Epoch 47/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.6789 - acc: 0.7410\n",
      "Epoch 48/50\n",
      "1280/1280 [==============================] - 183s 143ms/step - loss: 0.6788 - acc: 0.7412\n",
      "Epoch 49/50\n",
      "1280/1280 [==============================] - 184s 144ms/step - loss: 0.6750 - acc: 0.7427\n",
      "Epoch 50/50\n",
      "1280/1280 [==============================] - 187s 146ms/step - loss: 0.6709 - acc: 0.7439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       978\n",
      "           1       0.79      0.81      0.80     18763\n",
      "           2       0.56      0.44      0.49      3322\n",
      "           3       0.87      0.92      0.89     27935\n",
      "           4       0.82      0.49      0.62       621\n",
      "           5       0.51      0.64      0.57     17161\n",
      "           6       0.42      0.13      0.20      7419\n",
      "           7       0.49      0.51      0.50      9952\n",
      "\n",
      "    accuracy                           0.69     86151\n",
      "   macro avg       0.68      0.49      0.51     86151\n",
      "weighted avg       0.69      0.69      0.67     86151\n",
      "\n",
      "Acur√°cia\n",
      "0.4931443108034468\n",
      "Precisao\n",
      "0.6858590284729423\n",
      "Recall\n",
      "0.6931666492553772\n",
      "F1\n",
      "0.6746136756916806\n",
      "[[    1   125    26    67     0   583    42   134]\n",
      " [    0 15158    94   404     1  2417   110   579]\n",
      " [    0   167  1474   311     2   694    55   619]\n",
      " [    0   176   145 25754    44   904    45   867]\n",
      " [    0     6    18   230   306    40     1    20]\n",
      " [    0  2229   360  1150     1 11019   678  1724]\n",
      " [    0   772   165   533     6  3709   944  1290]\n",
      " [    0   572   352  1323    12  2272   360  5061]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "model = criarRede()\n",
    "\n",
    "for train_index, test_index in kf.split(previsores_trei_vald):\n",
    "  \n",
    "  train_and_evaluate_model(model, previsores_trei_vald[train_index], classes_trei_vald[train_index],\n",
    "                           previsores_trei_vald[test_index], classes_trei_vald[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_2 (Masking)          (None, 700, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 700, 200)          96800     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 700, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 339,208\n",
      "Trainable params: 339,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cias total\n",
      "[0.3016716546874587, 0.3813488113397844, 0.369693773261037, 0.4445714801649382, 0.4931443108034468]\n",
      "Precision total\n",
      "[0.5026077335455061, 0.5594777164259992, 0.5646484410093369, 0.6323630327798831, 0.6858590284729423]\n",
      "Recalls total\n",
      "[0.5414231909808681, 0.5852801425460304, 0.5958866826024187, 0.6534779282947171, 0.6931666492553772]\n",
      "F1 total\n",
      "[0.5012748091991024, 0.5583299999422009, 0.5614532833531092, 0.6301756463084252, 0.6746136756916806]\n"
     ]
    }
   ],
   "source": [
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "print('F1 total')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 232s 145ms/step - loss: 0.7444 - acc: 0.7213\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 246s 153ms/step - loss: 0.7343 - acc: 0.7234\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.7242 - acc: 0.7265\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 222s 139ms/step - loss: 0.7082 - acc: 0.7315\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.7017 - acc: 0.7340\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 222s 139ms/step - loss: 0.7008 - acc: 0.7344\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.7013 - acc: 0.7341\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 222s 138ms/step - loss: 0.6978 - acc: 0.7357\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 226s 141ms/step - loss: 0.6947 - acc: 0.7358\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 222s 139ms/step - loss: 0.6942 - acc: 0.7366\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 222s 138ms/step - loss: 0.6909 - acc: 0.7372\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6857 - acc: 0.7393\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6869 - acc: 0.7384\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6870 - acc: 0.7387\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 0.6828 - acc: 0.7402\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 0.6846 - acc: 0.7393\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6813 - acc: 0.7407\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6803 - acc: 0.7405\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6813 - acc: 0.7400\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 222s 139ms/step - loss: 0.6796 - acc: 0.7413\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6756 - acc: 0.7424\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 0.6727 - acc: 0.7436\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 222s 139ms/step - loss: 0.6716 - acc: 0.7445\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 222s 139ms/step - loss: 0.6770 - acc: 0.7425\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6734 - acc: 0.7430\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6702 - acc: 0.7448\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6709 - acc: 0.7441\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 222s 139ms/step - loss: 0.6684 - acc: 0.7453\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6694 - acc: 0.7450\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6661 - acc: 0.7464\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6636 - acc: 0.7473\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6645 - acc: 0.7461\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6631 - acc: 0.7473\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 0.6637 - acc: 0.7464\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6615 - acc: 0.7476\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6571 - acc: 0.7495\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6580 - acc: 0.7488\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6578 - acc: 0.7489\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6581 - acc: 0.7492\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6567 - acc: 0.7495\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6533 - acc: 0.7507\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 225s 141ms/step - loss: 0.6677 - acc: 0.7456\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6682 - acc: 0.7451\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6523 - acc: 0.7514\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 222s 139ms/step - loss: 0.6531 - acc: 0.7505\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 223s 139ms/step - loss: 0.6515 - acc: 0.7518\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 223s 140ms/step - loss: 0.6550 - acc: 0.7502\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6511 - acc: 0.7511\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6458 - acc: 0.7534\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 224s 140ms/step - loss: 0.6444 - acc: 0.7537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.00      1319\n",
      "           1       0.61      0.61      0.61     21565\n",
      "           2       0.34      0.24      0.28      4144\n",
      "           3       0.71      0.73      0.72     34429\n",
      "           4       0.52      0.25      0.34       723\n",
      "           5       0.40      0.56      0.47     20463\n",
      "           6       0.34      0.10      0.15      9014\n",
      "           7       0.36      0.40      0.38     11705\n",
      "\n",
      "    accuracy                           0.54    103362\n",
      "   macro avg       0.47      0.36      0.37    103362\n",
      "weighted avg       0.54      0.54      0.53    103362\n",
      "\n",
      "Acur√°cia\n",
      "0.3595200731274654\n",
      "Precisao\n",
      "0.5393571029479564\n",
      "Recall\n",
      "0.5434105377217933\n",
      "F1\n",
      "0.5293724610068142\n",
      "[[    2   229    38   201     2   678    48   121]\n",
      " [    2 13071   236  2585    21  4326   196  1128]\n",
      " [    0   444   996   904     6  1000   104   690]\n",
      " [    0  2429   529 25015    86  3791   215  2364]\n",
      " [    0    60    21   293   181    76    13    79]\n",
      " [    0  2950   476  2736    26 11373   691  2211]\n",
      " [    0  1072   234  1096     8  4093   903  1608]\n",
      " [    0  1016   399  2290    19  2860   494  4627]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(model, previsores_trei_vald, classes_trei_vald,\n",
    "                           previsores_testes, classes_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
