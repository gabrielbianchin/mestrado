{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n",
      "(2000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classesQ8 = base.iloc[:1400000, 20:28].values\n",
    "classesQ8 = np.reshape(classesQ8, (2000, 700, 8))\n",
    "print(classesQ8.shape)\n",
    "\n",
    "classesQ3 = base.iloc[:1400000, 28:31].values\n",
    "classesQ3 = np.reshape(classesQ3, (2000, 700, 3))\n",
    "print(classesQ3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNGRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede(saida):\n",
    "    model = Sequential()\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(saida, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test, saida):\n",
    "    model.fit(x_train, y_train, epochs = 100, verbose = 1)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], saida))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], saida))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "    \n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0822 21:04:28.822488 13376 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0822 21:04:28.826449 13376 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0822 21:04:28.828444 13376 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0822 21:04:28.829442 13376 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    3 ... 1996 1998 1999] TEST: [   2   10   15   26   40   57   58   60   70   77   90   96  100  103\n",
      "  115  118  131  132  133  148  150  153  154  157  167  168  178  180\n",
      "  205  208  218  232  236  249  255  257  262  265  270  272  275  276\n",
      "  277  279  290  292  296  303  306  310  311  317  318  321  322  323\n",
      "  324  328  331  338  339  351  355  362  363  369  370  389  393  396\n",
      "  398  402  412  420  423  430  431  439  446  447  448  458  467  468\n",
      "  478  480  484  486  490  505  509  513  517  521  524  528  535  538\n",
      "  540  548  552  557  561  563  569  572  575  577  583  586  589  590\n",
      "  593  603  611  619  622  623  631  632  634  638  641  644  645  649\n",
      "  655  656  660  670  674  679  682  687  689  692  694  702  703  704\n",
      "  710  714  716  718  720  724  726  728  729  732  735  742  743  754\n",
      "  760  761  763  768  773  775  776  780  788  797  798  804  806  808\n",
      "  809  812  813  830  832  837  844  845  848  850  870  872  874  885\n",
      "  889  902  905  910  914  915  931  939  945  953  955  963  985  990\n",
      "  993 1002 1006 1008 1010 1011 1014 1024 1025 1028 1029 1051 1054 1057\n",
      " 1059 1062 1064 1065 1073 1076 1079 1083 1086 1102 1103 1104 1110 1112\n",
      " 1130 1131 1139 1142 1143 1145 1154 1158 1163 1165 1174 1179 1185 1203\n",
      " 1209 1212 1215 1222 1225 1226 1233 1242 1244 1245 1249 1257 1259 1261\n",
      " 1266 1272 1280 1281 1284 1286 1287 1297 1300 1302 1305 1317 1326 1335\n",
      " 1340 1342 1346 1349 1362 1365 1366 1373 1375 1384 1386 1392 1394 1395\n",
      " 1401 1408 1410 1420 1421 1425 1427 1428 1433 1434 1438 1439 1446 1449\n",
      " 1453 1461 1468 1481 1482 1483 1488 1490 1493 1494 1496 1503 1505 1533\n",
      " 1543 1546 1547 1553 1558 1559 1568 1571 1572 1576 1581 1593 1595 1599\n",
      " 1601 1616 1627 1633 1634 1635 1637 1638 1651 1652 1655 1663 1664 1675\n",
      " 1678 1687 1690 1694 1698 1707 1713 1720 1726 1730 1732 1733 1734 1735\n",
      " 1740 1744 1746 1749 1752 1758 1763 1765 1785 1787 1792 1795 1796 1802\n",
      " 1811 1816 1820 1821 1825 1838 1843 1858 1863 1868 1869 1871 1885 1893\n",
      " 1900 1906 1908 1909 1910 1917 1918 1919 1921 1926 1927 1934 1949 1951\n",
      " 1960 1962 1965 1966 1980 1990 1994 1997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 21:04:30.591777 13376 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 21s 13ms/sample - loss: 0.5846 - acc: 0.1583\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.5318 - acc: 0.1714\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.5223 - acc: 0.1763\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.5159 - acc: 0.1790\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5096 - acc: 0.1820\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5072 - acc: 0.1830\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.5072 - acc: 0.1832\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5016 - acc: 0.1852\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4971 - acc: 0.1875\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4921 - acc: 0.1892\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4905 - acc: 0.1898\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4858 - acc: 0.1922\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4822 - acc: 0.1939\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4805 - acc: 0.1947\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4741 - acc: 0.1969\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4715 - acc: 0.1983\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4685 - acc: 0.1996\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4562 - acc: 0.2044\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4503 - acc: 0.2062\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4447 - acc: 0.2086\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4405 - acc: 0.2098\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4369 - acc: 0.2111\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4315 - acc: 0.2129\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4281 - acc: 0.2140\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4224 - acc: 0.2159\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4190 - acc: 0.2173\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4148 - acc: 0.2185\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4112 - acc: 0.2199\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4052 - acc: 0.2219\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4024 - acc: 0.2230\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3983 - acc: 0.2244\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3947 - acc: 0.2255\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3900 - acc: 0.2269\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3868 - acc: 0.2284\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3864 - acc: 0.2281\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3801 - acc: 0.2303\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3760 - acc: 0.2314\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3737 - acc: 0.2323\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3696 - acc: 0.2335\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3668 - acc: 0.2343\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3650 - acc: 0.2353\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3615 - acc: 0.2361\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3579 - acc: 0.2375\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3557 - acc: 0.2381\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3525 - acc: 0.2392\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3497 - acc: 0.2401\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3472 - acc: 0.2409\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3456 - acc: 0.2414\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3432 - acc: 0.2420\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3406 - acc: 0.2432\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3391 - acc: 0.2433\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3362 - acc: 0.2446\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3339 - acc: 0.2449\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3321 - acc: 0.2455\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3301 - acc: 0.2465\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3292 - acc: 0.2464\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3250 - acc: 0.2482\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3250 - acc: 0.2483\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3230 - acc: 0.2485\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3207 - acc: 0.2493\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3187 - acc: 0.2501\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3182 - acc: 0.2503\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3164 - acc: 0.2508\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3150 - acc: 0.2513\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3138 - acc: 0.2514\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3127 - acc: 0.2522\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3105 - acc: 0.2529\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3099 - acc: 0.2529\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3066 - acc: 0.2542\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3061 - acc: 0.2543\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3045 - acc: 0.2548\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3043 - acc: 0.2550\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3017 - acc: 0.2556\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3008 - acc: 0.2561\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2995 - acc: 0.2564\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2984 - acc: 0.2567\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2978 - acc: 0.2569\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2962 - acc: 0.2578\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2949 - acc: 0.2579\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2931 - acc: 0.2587\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2917 - acc: 0.2588\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2912 - acc: 0.2593\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2905 - acc: 0.2597\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2892 - acc: 0.2598\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2874 - acc: 0.2604\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2877 - acc: 0.2606\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2861 - acc: 0.2609\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2850 - acc: 0.2614\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2830 - acc: 0.2621\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2820 - acc: 0.2624\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2819 - acc: 0.2622\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2819 - acc: 0.2625\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2807 - acc: 0.2628\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2786 - acc: 0.2635\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2782 - acc: 0.2639\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2771 - acc: 0.2641\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2771 - acc: 0.2641\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2760 - acc: 0.2646\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2765 - acc: 0.2645\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2737 - acc: 0.2653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.01      0.01      1296\n",
      "           1       0.61      0.74      0.67     22038\n",
      "           2       0.38      0.31      0.34      3954\n",
      "           3       0.75      0.82      0.79     33024\n",
      "           4       0.50      0.26      0.34       616\n",
      "           5       0.48      0.51      0.49     21497\n",
      "           6       0.37      0.11      0.17      9453\n",
      "           7       0.43      0.42      0.43     11944\n",
      "\n",
      "    accuracy                           0.60    103822\n",
      "   macro avg       0.55      0.40      0.41    103822\n",
      "weighted avg       0.58      0.60      0.57    103822\n",
      "\n",
      "Acur√°cia\n",
      "0.3982141632003823\n",
      "Precisao\n",
      "0.5796781805448292\n",
      "Recall\n",
      "0.5966654466298087\n",
      "F1\n",
      "0.5741052451793729\n",
      "[[    9   359    30   128     1   578    54   137]\n",
      " [    0 16362   242  1737    21  2688   172   816]\n",
      " [    0   506  1234   866     4   700    80   564]\n",
      " [    0  2020   393 27211    88  1737   176  1399]\n",
      " [    0    68     7   292   160    48     3    38]\n",
      " [    1  4575   524  2525    13 10863   881  2115]\n",
      " [    0  1707   307  1197    10  3608  1079  1545]\n",
      " [    0  1406   485  2303    20  2226   475  5029]]\n",
      "TRAIN: [   0    2    3 ... 1996 1997 1998] TEST: [   1   12   14   19   20   21   22   27   33   35   42   43   46   48\n",
      "   53   54   59   61   67   92  102  109  117  119  122  123  134  137\n",
      "  139  140  146  159  162  172  177  189  217  219  223  229  234  235\n",
      "  242  247  252  266  273  278  281  283  286  289  293  300  301  302\n",
      "  304  308  314  316  320  326  343  344  346  347  348  358  365  379\n",
      "  380  382  386  397  400  405  418  424  426  427  428  436  443  444\n",
      "  449  463  465  466  471  481  482  489  495  511  515  516  518  519\n",
      "  520  523  531  532  534  537  545  550  553  556  560  574  585  587\n",
      "  588  592  595  596  600  615  620  621  627  630  633  636  640  642\n",
      "  651  664  671  676  677  690  700  701  705  709  715  731  733  737\n",
      "  748  749  750  759  770  771  783  792  814  824  831  842  847  854\n",
      "  855  858  866  876  883  887  893  894  899  901  904  906  913  916\n",
      "  920  924  925  927  928  932  936  937  938  942  947  949  959  961\n",
      "  965  966  975  977  980  986 1003 1004 1016 1018 1039 1041 1045 1048\n",
      " 1052 1053 1058 1069 1070 1074 1075 1091 1094 1098 1101 1109 1117 1120\n",
      " 1122 1124 1135 1138 1147 1149 1150 1152 1155 1161 1166 1171 1178 1180\n",
      " 1186 1189 1190 1193 1195 1202 1206 1210 1214 1216 1217 1221 1223 1227\n",
      " 1230 1231 1236 1237 1239 1240 1250 1258 1263 1270 1279 1282 1283 1291\n",
      " 1316 1320 1324 1329 1338 1344 1351 1357 1368 1369 1370 1371 1378 1382\n",
      " 1383 1404 1415 1419 1422 1424 1426 1430 1441 1444 1450 1454 1455 1458\n",
      " 1459 1464 1467 1473 1480 1486 1512 1513 1522 1523 1528 1529 1530 1531\n",
      " 1535 1537 1545 1548 1555 1561 1563 1564 1567 1580 1585 1586 1597 1608\n",
      " 1611 1614 1621 1626 1631 1636 1643 1653 1656 1657 1658 1660 1662 1669\n",
      " 1673 1676 1679 1681 1691 1692 1693 1695 1696 1700 1711 1717 1725 1728\n",
      " 1741 1748 1756 1761 1774 1778 1779 1783 1788 1791 1800 1804 1807 1810\n",
      " 1812 1814 1833 1834 1835 1836 1841 1842 1850 1853 1856 1859 1864 1876\n",
      " 1877 1879 1882 1884 1886 1887 1896 1902 1915 1916 1920 1924 1932 1933\n",
      " 1936 1938 1939 1947 1948 1954 1955 1958 1963 1967 1971 1972 1974 1979\n",
      " 1982 1985 1988 1991 1992 1993 1995 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.5875 - acc: 0.1579\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5312 - acc: 0.1718\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5190 - acc: 0.1777\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5137 - acc: 0.1796\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5108 - acc: 0.1816\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5052 - acc: 0.1839\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5046 - acc: 0.1840\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4981 - acc: 0.1874\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4927 - acc: 0.1892\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4927 - acc: 0.1892\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4891 - acc: 0.1904\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4868 - acc: 0.1915\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4806 - acc: 0.1942\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4782 - acc: 0.1950\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4738 - acc: 0.1973\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4711 - acc: 0.1984\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4627 - acc: 0.2019\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4612 - acc: 0.2020\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4511 - acc: 0.2059\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4454 - acc: 0.2078\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4422 - acc: 0.2090\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4413 - acc: 0.2089\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4321 - acc: 0.2125\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4285 - acc: 0.2136\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4241 - acc: 0.2154\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4202 - acc: 0.2165\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4167 - acc: 0.2176\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4123 - acc: 0.2193\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4096 - acc: 0.2202\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4053 - acc: 0.2215\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3995 - acc: 0.2235\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3972 - acc: 0.2242\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3921 - acc: 0.2256\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3895 - acc: 0.2265\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3852 - acc: 0.2282\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3836 - acc: 0.2288\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3788 - acc: 0.2305\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3745 - acc: 0.2315\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3716 - acc: 0.2324\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3690 - acc: 0.2334\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3658 - acc: 0.2343\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3617 - acc: 0.2362\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3604 - acc: 0.2359\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3578 - acc: 0.2373\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3545 - acc: 0.2379\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3529 - acc: 0.2383\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3513 - acc: 0.2392\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3475 - acc: 0.2403\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3461 - acc: 0.2408\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3436 - acc: 0.2415\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3398 - acc: 0.2429\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3383 - acc: 0.2431\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3376 - acc: 0.2437\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3347 - acc: 0.2442\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3323 - acc: 0.2453\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3297 - acc: 0.2460\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3284 - acc: 0.2465\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3264 - acc: 0.2472\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3250 - acc: 0.2477\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3226 - acc: 0.2485\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3210 - acc: 0.2489\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3199 - acc: 0.2492\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3180 - acc: 0.2497\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3167 - acc: 0.2504\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3156 - acc: 0.2507\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3151 - acc: 0.2510\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3123 - acc: 0.2518\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3109 - acc: 0.2523\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3095 - acc: 0.2527\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3076 - acc: 0.2531\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3064 - acc: 0.2537\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3056 - acc: 0.2540\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3031 - acc: 0.2549\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3022 - acc: 0.2551\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3012 - acc: 0.2554\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3003 - acc: 0.2559\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2987 - acc: 0.2562\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2968 - acc: 0.2569\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2961 - acc: 0.2571\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2956 - acc: 0.2573\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2938 - acc: 0.2577\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2922 - acc: 0.2586\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2919 - acc: 0.2585\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2918 - acc: 0.2586\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2906 - acc: 0.2590\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2886 - acc: 0.2596\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2880 - acc: 0.2602\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2871 - acc: 0.2600\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2853 - acc: 0.2607\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2845 - acc: 0.2612\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2833 - acc: 0.2615\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2829 - acc: 0.2616\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2811 - acc: 0.2624\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2808 - acc: 0.2624\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2803 - acc: 0.2628\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2794 - acc: 0.2631\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2777 - acc: 0.2634\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2763 - acc: 0.2637\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2770 - acc: 0.2640\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2767 - acc: 0.2639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.01      0.02      1264\n",
      "           1       0.65      0.69      0.67     21187\n",
      "           2       0.36      0.29      0.32      3926\n",
      "           3       0.74      0.83      0.78     35033\n",
      "           4       0.65      0.29      0.40       801\n",
      "           5       0.47      0.55      0.51     20775\n",
      "           6       0.38      0.12      0.18      9100\n",
      "           7       0.42      0.41      0.41     11843\n",
      "\n",
      "    accuracy                           0.60    103929\n",
      "   macro avg       0.52      0.40      0.41    103929\n",
      "weighted avg       0.58      0.60      0.58    103929\n",
      "\n",
      "Acur√°cia\n",
      "0.3985712512357744\n",
      "Precisao\n",
      "0.5822378374845061\n",
      "Recall\n",
      "0.600371407403131\n",
      "F1\n",
      "0.5800875869388132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   15   249    31   158     1   622    36   152]\n",
      " [    1 14710   230  2171    16  3052   214   793]\n",
      " [    0   400  1125   904     2   832    65   598]\n",
      " [    1  1735   413 28906    76  2257   166  1479]\n",
      " [    0    52     4   365   233    70    12    65]\n",
      " [    5  3208   532  2639     8 11486   776  2121]\n",
      " [    4  1258   299  1280     6  3627  1062  1564]\n",
      " [    3  1038   467  2567    17  2411   481  4859]]\n",
      "TRAIN: [   1    2    3 ... 1997 1998 1999] TEST: [   0    6    9   11   23   24   29   31   37   47   62   66   68   71\n",
      "   75   78   79   81   84   86   87   94   98  104  106  107  108  110\n",
      "  120  124  130  136  138  142  143  144  152  163  164  165  174  186\n",
      "  190  191  194  197  202  204  206  207  214  215  224  230  231  233\n",
      "  240  243  245  246  251  267  268  271  282  288  294  295  313  315\n",
      "  350  354  356  364  371  373  375  378  383  384  387  388  390  391\n",
      "  392  403  409  411  413  415  421  422  425  433  438  441  442  453\n",
      "  457  460  461  462  464  473  474  475  485  488  492  498  501  503\n",
      "  504  514  522  530  536  543  562  567  578  594  598  601  602  606\n",
      "  609  613  616  635  639  647  659  665  667  669  675  691  695  698\n",
      "  711  717  721  725  730  734  739  741  747  756  762  764  769  772\n",
      "  778  781  784  785  786  793  800  803  810  815  816  817  818  819\n",
      "  821  823  826  827  833  835  843  849  851  860  862  864  867  869\n",
      "  871  875  877  880  882  884  886  888  892  895  898  900  908  918\n",
      "  930  933  944  946  948  964  969  976  981  982  983  984  988  997\n",
      " 1000 1007 1009 1012 1017 1019 1021 1023 1026 1027 1031 1036 1037 1040\n",
      " 1042 1047 1049 1056 1060 1063 1066 1068 1078 1087 1090 1097 1100 1105\n",
      " 1106 1108 1128 1136 1144 1153 1156 1157 1159 1160 1169 1170 1175 1176\n",
      " 1187 1198 1205 1207 1213 1220 1241 1247 1252 1254 1255 1260 1269 1273\n",
      " 1294 1296 1306 1307 1308 1309 1313 1323 1330 1332 1336 1343 1350 1360\n",
      " 1364 1393 1396 1403 1405 1406 1409 1418 1423 1429 1436 1445 1457 1472\n",
      " 1476 1478 1484 1485 1489 1497 1499 1500 1514 1518 1519 1520 1521 1534\n",
      " 1538 1539 1540 1542 1549 1552 1562 1566 1573 1574 1575 1582 1588 1590\n",
      " 1598 1602 1606 1612 1613 1622 1623 1624 1628 1629 1630 1639 1641 1644\n",
      " 1645 1659 1661 1665 1674 1677 1680 1684 1688 1703 1708 1709 1712 1714\n",
      " 1715 1719 1722 1724 1742 1753 1755 1757 1759 1766 1767 1769 1770 1772\n",
      " 1780 1782 1786 1793 1794 1809 1813 1815 1822 1826 1830 1831 1849 1851\n",
      " 1857 1878 1883 1889 1890 1891 1901 1905 1907 1914 1923 1929 1930 1931\n",
      " 1935 1943 1952 1953 1957 1970 1977 1987]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.5753 - acc: 0.1600\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5299 - acc: 0.1690\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5172 - acc: 0.1750\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5100 - acc: 0.1780\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5086 - acc: 0.1791\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5013 - acc: 0.1823\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4981 - acc: 0.1837\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4950 - acc: 0.1851\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4923 - acc: 0.1861\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4887 - acc: 0.1877\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4832 - acc: 0.1902\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4816 - acc: 0.1907\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4779 - acc: 0.1924\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4758 - acc: 0.1931\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4730 - acc: 0.1941\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4684 - acc: 0.1959\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4650 - acc: 0.1980\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4625 - acc: 0.1987\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4596 - acc: 0.1997\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4519 - acc: 0.2031\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4453 - acc: 0.2053\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4399 - acc: 0.2071\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4337 - acc: 0.2094\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4288 - acc: 0.2111\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4252 - acc: 0.2124\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4209 - acc: 0.2139\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4183 - acc: 0.2147\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4129 - acc: 0.2166\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4088 - acc: 0.2180\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4048 - acc: 0.2193\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4006 - acc: 0.2207\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3967 - acc: 0.2219\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3940 - acc: 0.2228\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3924 - acc: 0.2234\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3862 - acc: 0.2254\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3816 - acc: 0.2266\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3786 - acc: 0.2275\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3759 - acc: 0.2287\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3722 - acc: 0.2300\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3705 - acc: 0.2304\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3664 - acc: 0.2314\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3634 - acc: 0.2326\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3611 - acc: 0.2334\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3576 - acc: 0.2344\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3557 - acc: 0.2351\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3540 - acc: 0.2357\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3518 - acc: 0.2361\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3484 - acc: 0.2372\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3447 - acc: 0.2388\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3431 - acc: 0.2390\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3411 - acc: 0.2392\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3386 - acc: 0.2404\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3379 - acc: 0.2407\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3341 - acc: 0.2420\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3336 - acc: 0.2419\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3303 - acc: 0.2433\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3275 - acc: 0.2442\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3275 - acc: 0.2441\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3267 - acc: 0.2443\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.3235 - acc: 0.2454\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.3215 - acc: 0.2460\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3211 - acc: 0.2462\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3200 - acc: 0.2462\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3167 - acc: 0.2476\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3148 - acc: 0.2480\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3142 - acc: 0.2485\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3123 - acc: 0.2489\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3110 - acc: 0.2493\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3108 - acc: 0.2495\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3079 - acc: 0.2505\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3068 - acc: 0.2506\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3048 - acc: 0.2516\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3044 - acc: 0.2515\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3031 - acc: 0.2519\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3010 - acc: 0.2529\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3001 - acc: 0.2530\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2991 - acc: 0.2537\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2962 - acc: 0.2545\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2953 - acc: 0.2545\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2941 - acc: 0.2550\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2933 - acc: 0.2555\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2924 - acc: 0.2559\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2913 - acc: 0.2562\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2905 - acc: 0.2566\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2893 - acc: 0.2564\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2893 - acc: 0.2568\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2881 - acc: 0.2569\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2862 - acc: 0.2577\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2851 - acc: 0.2582\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2838 - acc: 0.2586\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2831 - acc: 0.2590\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2821 - acc: 0.2590\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2813 - acc: 0.2594\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2806 - acc: 0.2597\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2804 - acc: 0.2597\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2785 - acc: 0.2607\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2770 - acc: 0.2608\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2775 - acc: 0.2609\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2770 - acc: 0.2609\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2763 - acc: 0.2609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.01      0.01      1353\n",
      "           1       0.61      0.71      0.66     22140\n",
      "           2       0.32      0.30      0.31      4074\n",
      "           3       0.75      0.81      0.78     35746\n",
      "           4       0.56      0.26      0.35       847\n",
      "           5       0.49      0.50      0.50     21491\n",
      "           6       0.36      0.16      0.22      9318\n",
      "           7       0.42      0.42      0.42     12041\n",
      "\n",
      "    accuracy                           0.59    107010\n",
      "   macro avg       0.52      0.40      0.41    107010\n",
      "weighted avg       0.58      0.59      0.58    107010\n",
      "\n",
      "Acur√°cia\n",
      "0.39594272033844163\n",
      "Precisao\n",
      "0.5777476412105153\n",
      "Recall\n",
      "0.59339314082796\n",
      "F1\n",
      "0.5766514088601246\n",
      "[[    8   353    37   191     1   540    70   153]\n",
      " [    3 15797   291  2013    11  2848   327   850]\n",
      " [    0   578  1219   897     3   657   142   578]\n",
      " [    0  2251   631 28852   105  1951   291  1665]\n",
      " [    0    59     7   448   217    51     4    61]\n",
      " [    1  3983   654  2659    23 10834  1119  2218]\n",
      " [    0  1425   374  1179    14  3288  1469  1569]\n",
      " [    1  1264   635  2347    14  2046   631  5103]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   3    4    7   16   17   25   28   30   34   41   44   49   50   51\n",
      "   65   69   72   73   80   83   88   91   97  101  114  116  121  135\n",
      "  147  149  156  158  166  170  171  173  175  176  181  184  187  192\n",
      "  193  195  198  201  209  211  212  216  220  221  222  225  226  228\n",
      "  239  244  248  250  253  254  256  258  259  263  264  274  280  305\n",
      "  319  325  327  332  334  337  340  345  353  357  360  361  368  374\n",
      "  395  399  407  408  410  414  417  419  434  435  450  451  454  456\n",
      "  472  476  477  487  496  499  500  502  508  510  512  525  529  533\n",
      "  539  541  547  555  558  559  564  565  566  571  579  581  584  597\n",
      "  599  605  612  614  617  628  629  648  653  657  658  662  663  666\n",
      "  680  681  685  686  693  697  708  713  719  723  727  736  740  745\n",
      "  746  751  752  753  765  794  795  796  799  801  820  825  829  834\n",
      "  836  838  852  868  879  881  891  897  909  921  922  929  934  956\n",
      "  962  967  970  972  979  987  989  991  994  995  996  998  999 1013\n",
      " 1022 1033 1034 1044 1050 1061 1067 1072 1077 1092 1095 1115 1118 1123\n",
      " 1126 1137 1140 1151 1162 1173 1177 1184 1188 1191 1199 1200 1201 1204\n",
      " 1211 1218 1219 1228 1229 1232 1234 1235 1238 1243 1248 1251 1256 1262\n",
      " 1264 1271 1276 1277 1278 1285 1289 1293 1295 1298 1301 1303 1304 1311\n",
      " 1314 1315 1318 1321 1327 1328 1333 1345 1348 1352 1354 1355 1358 1363\n",
      " 1374 1376 1377 1379 1380 1381 1387 1390 1391 1398 1399 1402 1407 1411\n",
      " 1416 1437 1442 1443 1447 1448 1451 1462 1466 1469 1474 1475 1479 1487\n",
      " 1492 1498 1501 1502 1506 1524 1526 1532 1536 1541 1550 1554 1556 1557\n",
      " 1560 1565 1569 1583 1584 1589 1591 1592 1596 1600 1604 1609 1617 1618\n",
      " 1619 1632 1640 1646 1647 1654 1667 1670 1672 1682 1683 1686 1689 1697\n",
      " 1701 1702 1704 1718 1721 1723 1727 1729 1736 1738 1743 1745 1750 1751\n",
      " 1754 1768 1776 1777 1781 1784 1789 1790 1801 1808 1818 1819 1823 1824\n",
      " 1832 1837 1839 1844 1845 1848 1852 1854 1855 1860 1861 1862 1865 1870\n",
      " 1872 1874 1881 1892 1894 1898 1899 1904 1912 1940 1941 1942 1944 1945\n",
      " 1946 1959 1964 1969 1973 1976 1978 1986]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.5833 - acc: 0.1659\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5351 - acc: 0.1733\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5243 - acc: 0.1788\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5187 - acc: 0.1810\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5147 - acc: 0.1831\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5104 - acc: 0.1850\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5069 - acc: 0.1858\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5025 - acc: 0.1882\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4972 - acc: 0.1906\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4954 - acc: 0.1913\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4891 - acc: 0.1942\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4874 - acc: 0.1947\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4853 - acc: 0.1958\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4809 - acc: 0.1971\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4777 - acc: 0.1987\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4707 - acc: 0.2015\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4634 - acc: 0.2042\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4576 - acc: 0.2064\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4533 - acc: 0.2081\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4473 - acc: 0.2103\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4440 - acc: 0.2109\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4395 - acc: 0.2132\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4347 - acc: 0.2145\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4299 - acc: 0.2162\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4247 - acc: 0.2182\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4213 - acc: 0.2194\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4172 - acc: 0.2207\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4143 - acc: 0.2217\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4103 - acc: 0.2230\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4082 - acc: 0.2237\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4036 - acc: 0.2254\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3984 - acc: 0.2271\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3957 - acc: 0.2281\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3928 - acc: 0.2288\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3879 - acc: 0.2304\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3865 - acc: 0.2304\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3817 - acc: 0.2325\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3781 - acc: 0.2331\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3765 - acc: 0.2340\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3741 - acc: 0.2349\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3703 - acc: 0.2360\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3664 - acc: 0.2371\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3632 - acc: 0.2381\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3602 - acc: 0.2390\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3603 - acc: 0.2393\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3556 - acc: 0.2407\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3536 - acc: 0.2413\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3503 - acc: 0.2426\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3481 - acc: 0.2429\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3469 - acc: 0.2435\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3448 - acc: 0.2440\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3430 - acc: 0.2446\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3424 - acc: 0.2451\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3396 - acc: 0.2456\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3363 - acc: 0.2469\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3338 - acc: 0.2475\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3321 - acc: 0.2482\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3306 - acc: 0.2488\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3300 - acc: 0.2491\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3281 - acc: 0.2494\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3265 - acc: 0.2500\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3257 - acc: 0.2502\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3223 - acc: 0.2514\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3204 - acc: 0.2519\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3194 - acc: 0.2523\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3182 - acc: 0.2530\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3173 - acc: 0.2530\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3149 - acc: 0.2537\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3137 - acc: 0.2540\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3127 - acc: 0.2545\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3093 - acc: 0.2557\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3082 - acc: 0.2559\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3084 - acc: 0.2559\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3061 - acc: 0.2568\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3058 - acc: 0.2569\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3044 - acc: 0.2572\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3028 - acc: 0.2577\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3016 - acc: 0.2581\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3006 - acc: 0.2587\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2982 - acc: 0.2593\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2980 - acc: 0.2595\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2976 - acc: 0.2597\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2963 - acc: 0.2601\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2957 - acc: 0.2603\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2937 - acc: 0.2608\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2932 - acc: 0.2612\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2906 - acc: 0.2619\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2910 - acc: 0.2621\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2893 - acc: 0.2626\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2896 - acc: 0.2623\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2889 - acc: 0.2625\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2866 - acc: 0.2635\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2863 - acc: 0.2635\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2849 - acc: 0.2638\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2832 - acc: 0.2649\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2818 - acc: 0.2649\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2817 - acc: 0.2653\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2831 - acc: 0.2647\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2823 - acc: 0.2650\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2806 - acc: 0.2657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.01      0.02      1194\n",
      "           1       0.66      0.67      0.67     21618\n",
      "           2       0.37      0.30      0.33      3907\n",
      "           3       0.77      0.79      0.78     32837\n",
      "           4       0.38      0.26      0.31       667\n",
      "           5       0.47      0.56      0.51     20149\n",
      "           6       0.37      0.14      0.21      8870\n",
      "           7       0.40      0.46      0.43     11393\n",
      "\n",
      "    accuracy                           0.59    100635\n",
      "   macro avg       0.54      0.40      0.41    100635\n",
      "weighted avg       0.59      0.59      0.58    100635\n",
      "\n",
      "Acur√°cia\n",
      "0.4016089647286748\n",
      "Precisao\n",
      "0.5902075720346424\n",
      "Recall\n",
      "0.5939782381875093\n",
      "F1\n",
      "0.5811268820991494\n",
      "[[   13   231    37   135     1   561    60   156]\n",
      " [    0 14577   288  1764    20  3495   288  1186]\n",
      " [    0   344  1190   762    16   792    91   712]\n",
      " [    0  1896   494 25917   145  2476   201  1708]\n",
      " [    0    45     9   339   176    41    11    46]\n",
      " [    2  3046   482  1933    21 11354   956  2355]\n",
      " [    0  1032   274  1039    28  3480  1271  1746]\n",
      " [    0   949   474  1925    52  2203   513  5277]]\n",
      "TRAIN: [   0    1    2 ... 1995 1997 1999] TEST: [   5    8   13   18   32   36   38   39   45   52   55   56   63   64\n",
      "   74   76   82   85   89   93   95   99  105  111  112  113  125  126\n",
      "  127  128  129  141  145  151  155  160  161  169  179  182  183  185\n",
      "  188  196  199  200  203  210  213  227  237  238  241  260  261  269\n",
      "  284  285  287  291  297  298  299  307  309  312  329  330  333  335\n",
      "  336  341  342  349  352  359  366  367  372  376  377  381  385  394\n",
      "  401  404  406  416  429  432  437  440  445  452  455  459  469  470\n",
      "  479  483  491  493  494  497  506  507  526  527  542  544  546  549\n",
      "  551  554  568  570  573  576  580  582  591  604  607  608  610  618\n",
      "  624  625  626  637  643  646  650  652  654  661  668  672  673  678\n",
      "  683  684  688  696  699  706  707  712  722  738  744  755  757  758\n",
      "  766  767  774  777  779  782  787  789  790  791  802  805  807  811\n",
      "  822  828  839  840  841  846  853  856  857  859  861  863  865  873\n",
      "  878  890  896  903  907  911  912  917  919  923  926  935  940  941\n",
      "  943  950  951  952  954  957  958  960  968  971  973  974  978  992\n",
      " 1001 1005 1015 1020 1030 1032 1035 1038 1043 1046 1055 1071 1080 1081\n",
      " 1082 1084 1085 1088 1089 1093 1096 1099 1107 1111 1113 1114 1116 1119\n",
      " 1121 1125 1127 1129 1132 1133 1134 1141 1146 1148 1164 1167 1168 1172\n",
      " 1181 1182 1183 1192 1194 1196 1197 1208 1224 1246 1253 1265 1267 1268\n",
      " 1274 1275 1288 1290 1292 1299 1310 1312 1319 1322 1325 1331 1334 1337\n",
      " 1339 1341 1347 1353 1356 1359 1361 1367 1372 1385 1388 1389 1397 1400\n",
      " 1412 1413 1414 1417 1431 1432 1435 1440 1452 1456 1460 1463 1465 1470\n",
      " 1471 1477 1491 1495 1504 1507 1508 1509 1510 1511 1515 1516 1517 1525\n",
      " 1527 1544 1551 1570 1577 1578 1579 1587 1594 1603 1605 1607 1610 1615\n",
      " 1620 1625 1642 1648 1649 1650 1666 1668 1671 1685 1699 1705 1706 1710\n",
      " 1716 1731 1737 1739 1747 1760 1762 1764 1771 1773 1775 1797 1798 1799\n",
      " 1803 1805 1806 1817 1827 1828 1829 1840 1846 1847 1866 1867 1873 1875\n",
      " 1880 1888 1895 1897 1903 1911 1913 1922 1925 1928 1937 1950 1956 1961\n",
      " 1968 1975 1981 1983 1984 1989 1996 1998]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.5914 - acc: 0.1588\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5349 - acc: 0.1735\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5251 - acc: 0.1781\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.5220 - acc: 0.1800\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5150 - acc: 0.1829\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5148 - acc: 0.1828\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5097 - acc: 0.1851\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5043 - acc: 0.1874\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.5006 - acc: 0.1887\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4976 - acc: 0.1902\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4931 - acc: 0.1919\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4922 - acc: 0.1930\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4903 - acc: 0.1930\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4899 - acc: 0.1935\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4820 - acc: 0.1967\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4763 - acc: 0.1991\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4749 - acc: 0.1996\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4663 - acc: 0.2033\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4603 - acc: 0.2056\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4527 - acc: 0.2078\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4469 - acc: 0.2104\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4425 - acc: 0.2118\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4445 - acc: 0.2110\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4352 - acc: 0.2148\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4314 - acc: 0.2158\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4259 - acc: 0.2177\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4224 - acc: 0.2192\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4177 - acc: 0.2206\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4136 - acc: 0.2220\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4106 - acc: 0.2230\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4086 - acc: 0.2238\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.4049 - acc: 0.2248\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3988 - acc: 0.2268\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3965 - acc: 0.2276\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3919 - acc: 0.2292\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3890 - acc: 0.2300\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3853 - acc: 0.2316\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3816 - acc: 0.2329\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3783 - acc: 0.2336\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3743 - acc: 0.2348\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3720 - acc: 0.2356\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3702 - acc: 0.2363\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3658 - acc: 0.2375\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3642 - acc: 0.2380\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3617 - acc: 0.2389\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3574 - acc: 0.2405\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3572 - acc: 0.2402\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3535 - acc: 0.2416\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3504 - acc: 0.2427\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3478 - acc: 0.2434\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3455 - acc: 0.2441\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3434 - acc: 0.2449\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3415 - acc: 0.2455\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3394 - acc: 0.2458\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3374 - acc: 0.2466\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3353 - acc: 0.2475\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3343 - acc: 0.2480\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3317 - acc: 0.2485\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3289 - acc: 0.2491\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3279 - acc: 0.2497\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3266 - acc: 0.2502\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3260 - acc: 0.2506\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3238 - acc: 0.2511\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3202 - acc: 0.2524\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3201 - acc: 0.2523\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3189 - acc: 0.2525\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3177 - acc: 0.2532\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3153 - acc: 0.2540\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3140 - acc: 0.2547\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3143 - acc: 0.2545\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3109 - acc: 0.2554\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3092 - acc: 0.2560\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3080 - acc: 0.2563\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3070 - acc: 0.2569\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3057 - acc: 0.2570\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3052 - acc: 0.2573\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3029 - acc: 0.2581\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3013 - acc: 0.2587\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3003 - acc: 0.2588\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2988 - acc: 0.2591\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2984 - acc: 0.2596\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2979 - acc: 0.2597\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2959 - acc: 0.2605\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2943 - acc: 0.2611\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2934 - acc: 0.2615\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2926 - acc: 0.2616\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2910 - acc: 0.2620\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2910 - acc: 0.2623\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2886 - acc: 0.2631\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2881 - acc: 0.2631\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2872 - acc: 0.2634\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2858 - acc: 0.2640\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2865 - acc: 0.2640\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2860 - acc: 0.2635\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2835 - acc: 0.2644\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2818 - acc: 0.2650\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2825 - acc: 0.2650\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2826 - acc: 0.2649\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2802 - acc: 0.2658\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2796 - acc: 0.2659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.02      0.03      1157\n",
      "           1       0.67      0.70      0.68     21949\n",
      "           2       0.42      0.33      0.37      4010\n",
      "           3       0.75      0.84      0.79     32503\n",
      "           4       0.48      0.32      0.38       586\n",
      "           5       0.49      0.54      0.52     20173\n",
      "           6       0.37      0.16      0.23      8847\n",
      "           7       0.42      0.42      0.42     11187\n",
      "\n",
      "    accuracy                           0.61    100412\n",
      "   macro avg       0.54      0.42      0.43    100412\n",
      "weighted avg       0.59      0.61      0.59    100412\n",
      "\n",
      "Acur√°cia\n",
      "0.41583553376381116\n",
      "Precisao\n",
      "0.5942616219861002\n",
      "Recall\n",
      "0.6109229972513246\n",
      "F1\n",
      "0.593687426872469\n",
      "[[   19   257    22   140     0   520    72   127]\n",
      " [    0 15416   205  2040    17  3083   363   825]\n",
      " [    0   363  1305   910     3   757   118   554]\n",
      " [    0  1352   419 27351   124  1751   236  1270]\n",
      " [    0    63    15   246   186    38     7    31]\n",
      " [    3  3458   417  2297    17 10956  1051  1974]\n",
      " [    3  1148   279  1173    17  3212  1447  1568]\n",
      " [    2  1039   463  2385    24  2007   603  4664]]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_28 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_30 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_32 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_33 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_34 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 1,162,008\n",
      "Trainable params: 1,162,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acur√°cias total\n",
      "[0.3982141632003823, 0.3985712512357744, 0.39594272033844163, 0.4016089647286748, 0.41583553376381116]\n",
      "0.4020345266534169\n",
      "Precision total\n",
      "[0.5796781805448292, 0.5822378374845061, 0.5777476412105153, 0.5902075720346424, 0.5942616219861002]\n",
      "0.5848265706521186\n",
      "Recalls total\n",
      "[0.5966654466298087, 0.600371407403131, 0.59339314082796, 0.5939782381875093, 0.6109229972513246]\n",
      "0.5990662460599467\n",
      "F1 total\n",
      "[0.5741052451793729, 0.5800875869388132, 0.5766514088601246, 0.5811268820991494, 0.593687426872469]\n",
      "0.5811317099899858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    2    3 ... 1997 1998 1999] TEST: [   1    7   10   15   22   23   44   48   50   52   56   58   78   80\n",
      "   86   89   90  100  102  103  106  110  113  114  115  118  123  126\n",
      "  130  135  149  157  162  171  184  187  188  197  206  208  211  215\n",
      "  236  243  256  257  258  260  262  263  268  275  279  280  286  287\n",
      "  288  291  308  312  315  317  320  323  328  332  336  338  343  351\n",
      "  354  357  366  367  368  376  383  386  388  396  399  402  404  410\n",
      "  428  431  432  433  441  443  453  455  464  477  481  486  490  491\n",
      "  493  494  499  501  504  505  506  520  525  526  528  529  531  555\n",
      "  564  569  572  577  579  580  596  602  608  609  616  618  625  631\n",
      "  632  633  643  648  651  652  653  657  665  670  672  673  676  686\n",
      "  693  695  701  705  715  719  723  731  732  733  746  747  748  751\n",
      "  754  755  756  780  784  788  789  792  796  801  806  808  822  834\n",
      "  837  846  859  863  866  868  869  873  874  879  881  885  898  908\n",
      "  914  921  931  933  934  938  941  944  951  968  972  976  977  989\n",
      "  994  997  998 1006 1009 1013 1021 1025 1026 1041 1047 1056 1066 1070\n",
      " 1077 1079 1080 1082 1088 1089 1104 1107 1108 1118 1120 1126 1133 1134\n",
      " 1135 1137 1138 1141 1142 1148 1156 1159 1160 1166 1168 1171 1184 1196\n",
      " 1201 1202 1213 1214 1216 1218 1225 1228 1231 1236 1237 1238 1251 1254\n",
      " 1267 1278 1281 1286 1290 1291 1299 1300 1301 1307 1308 1310 1315 1316\n",
      " 1318 1322 1354 1356 1359 1368 1373 1374 1377 1380 1390 1393 1396 1406\n",
      " 1407 1416 1419 1423 1429 1434 1435 1455 1460 1462 1463 1467 1479 1480\n",
      " 1481 1489 1494 1497 1500 1501 1513 1540 1541 1546 1551 1552 1556 1563\n",
      " 1569 1572 1574 1578 1581 1584 1597 1603 1609 1632 1636 1640 1641 1644\n",
      " 1649 1665 1668 1671 1682 1683 1687 1690 1695 1696 1697 1702 1707 1709\n",
      " 1722 1724 1728 1730 1736 1738 1740 1742 1743 1755 1756 1767 1774 1775\n",
      " 1776 1793 1800 1801 1803 1805 1808 1811 1813 1826 1827 1831 1835 1844\n",
      " 1850 1855 1856 1858 1859 1860 1863 1865 1867 1873 1875 1884 1885 1887\n",
      " 1891 1895 1900 1906 1907 1910 1911 1913 1918 1920 1923 1926 1931 1950\n",
      " 1953 1955 1965 1966 1969 1976 1989 1991]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.3381 - acc: 0.8142\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3134 - acc: 0.8590\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3099 - acc: 0.8601\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3051 - acc: 0.8624\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3028 - acc: 0.8641\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3023 - acc: 0.8644\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3004 - acc: 0.8642\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2968 - acc: 0.8660\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2955 - acc: 0.8666\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2924 - acc: 0.8682\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2927 - acc: 0.8679\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2910 - acc: 0.8685\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2864 - acc: 0.8706\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2867 - acc: 0.8710\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2843 - acc: 0.8723\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2814 - acc: 0.8739\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2788 - acc: 0.8748\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2782 - acc: 0.8757\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2741 - acc: 0.8780\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2725 - acc: 0.8789\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2685 - acc: 0.8805\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2682 - acc: 0.8809\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2592 - acc: 0.8856\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2528 - acc: 0.8878\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2494 - acc: 0.8897\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2464 - acc: 0.8910\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2428 - acc: 0.8929\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2393 - acc: 0.8950\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2368 - acc: 0.8967\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2343 - acc: 0.8971\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2324 - acc: 0.8989\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2271 - acc: 0.9011\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2242 - acc: 0.9030\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2223 - acc: 0.9039\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2187 - acc: 0.9056\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2163 - acc: 0.9067\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2138 - acc: 0.9082\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2097 - acc: 0.9098\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2070 - acc: 0.9111\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2063 - acc: 0.9117\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2025 - acc: 0.9135\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2000 - acc: 0.9146\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1984 - acc: 0.9155\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1959 - acc: 0.9163\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1934 - acc: 0.9172\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1932 - acc: 0.9174\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1895 - acc: 0.9193\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1887 - acc: 0.9194\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1853 - acc: 0.9210\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1830 - acc: 0.9221\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1815 - acc: 0.9228\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1795 - acc: 0.9239\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1790 - acc: 0.9239\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1759 - acc: 0.9253\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1742 - acc: 0.9261\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1726 - acc: 0.9270\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1716 - acc: 0.9273\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1701 - acc: 0.9284\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1684 - acc: 0.9289\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1683 - acc: 0.9289\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1655 - acc: 0.9301\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1642 - acc: 0.9307\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1633 - acc: 0.9310\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1620 - acc: 0.9315\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1609 - acc: 0.9322\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1598 - acc: 0.9326\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1582 - acc: 0.9336\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1584 - acc: 0.9336\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1560 - acc: 0.9346\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1554 - acc: 0.9348\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1542 - acc: 0.9354\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1527 - acc: 0.9358\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1512 - acc: 0.9366\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1505 - acc: 0.9367\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1497 - acc: 0.9371\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1484 - acc: 0.9375\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1478 - acc: 0.9381\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1469 - acc: 0.9386\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1465 - acc: 0.9385\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1456 - acc: 0.9391\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1447 - acc: 0.9395\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1427 - acc: 0.9403\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1428 - acc: 0.9403\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1425 - acc: 0.9405\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1415 - acc: 0.9409\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1402 - acc: 0.9415\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1390 - acc: 0.9419\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1385 - acc: 0.9421\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1373 - acc: 0.9424\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1379 - acc: 0.9421\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1370 - acc: 0.9427\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.1351 - acc: 0.9434\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.1363 - acc: 0.9428\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 18s 11ms/sample - loss: 0.1351 - acc: 0.9435\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1340 - acc: 0.9442\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1336 - acc: 0.9441\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1329 - acc: 0.9446\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1312 - acc: 0.9451\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1315 - acc: 0.9450\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1310 - acc: 0.9456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73     42571\n",
      "           1       0.68      0.64      0.65     22635\n",
      "           2       0.78      0.76      0.77     36890\n",
      "\n",
      "    accuracy                           0.73    102096\n",
      "   macro avg       0.72      0.71      0.72    102096\n",
      "weighted avg       0.73      0.73      0.73    102096\n",
      "\n",
      "Acur√°cia\n",
      "0.7139502019340705\n",
      "Precisao\n",
      "0.7264754069853382\n",
      "Recall\n",
      "0.7265808650681711\n",
      "F1\n",
      "0.7262232244213146\n",
      "[[31660  4990  5921]\n",
      " [ 6012 14381  2242]\n",
      " [ 6835  1915 28140]]\n",
      "TRAIN: [   1    2    4 ... 1995 1998 1999] TEST: [   0    3    5   13   19   25   32   38   57   66   68   69   74   83\n",
      "   84   85  104  117  120  121  128  136  137  146  150  153  160  168\n",
      "  169  174  179  182  204  205  212  214  220  222  226  233  239  240\n",
      "  242  245  249  250  253  259  271  285  294  296  297  307  311  314\n",
      "  318  327  329  333  339  340  344  348  353  360  371  372  382  397\n",
      "  401  407  409  419  421  427  438  442  448  449  451  454  456  461\n",
      "  466  467  468  472  474  484  485  488  492  495  496  497  498  510\n",
      "  511  512  515  524  537  538  550  551  558  562  565  576  585  588\n",
      "  597  603  623  629  635  640  647  650  654  671  678  679  698  699\n",
      "  700  702  703  706  707  709  710  714  716  717  724  726  730  734\n",
      "  735  739  742  743  757  762  773  775  778  779  781  783  791  798\n",
      "  807  809  810  812  816  819  820  823  824  825  830  844  849  851\n",
      "  854  857  858  870  871  875  878  897  901  916  922  926  930  937\n",
      "  946  949  955  963  966  967  979  981  983  985  988  990  995 1001\n",
      " 1012 1017 1019 1022 1023 1028 1029 1033 1036 1038 1053 1055 1059 1069\n",
      " 1075 1078 1086 1090 1092 1097 1103 1105 1121 1123 1129 1140 1143 1147\n",
      " 1165 1167 1181 1186 1187 1192 1199 1203 1204 1207 1209 1217 1219 1227\n",
      " 1241 1242 1243 1246 1248 1253 1255 1258 1260 1264 1272 1280 1284 1287\n",
      " 1293 1296 1298 1303 1309 1319 1321 1333 1344 1350 1353 1355 1358 1363\n",
      " 1365 1369 1372 1381 1397 1398 1399 1401 1404 1410 1413 1415 1418 1425\n",
      " 1427 1428 1430 1432 1433 1436 1442 1444 1450 1457 1459 1464 1465 1468\n",
      " 1470 1474 1478 1488 1491 1493 1496 1498 1499 1508 1509 1514 1518 1519\n",
      " 1524 1528 1536 1538 1554 1560 1564 1575 1579 1580 1585 1586 1588 1592\n",
      " 1598 1613 1616 1617 1623 1628 1629 1637 1645 1647 1648 1658 1659 1667\n",
      " 1675 1678 1679 1680 1684 1686 1699 1711 1716 1718 1726 1731 1732 1734\n",
      " 1771 1773 1778 1784 1807 1809 1815 1816 1818 1819 1828 1830 1834 1837\n",
      " 1839 1841 1849 1853 1870 1872 1877 1878 1890 1897 1898 1899 1912 1921\n",
      " 1928 1929 1935 1936 1947 1951 1952 1956 1957 1960 1964 1968 1970 1973\n",
      " 1980 1982 1985 1988 1990 1993 1996 1997]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.3370 - acc: 0.8118\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3128 - acc: 0.8585\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3054 - acc: 0.8618\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3024 - acc: 0.8636\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3016 - acc: 0.8637\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2987 - acc: 0.8654\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2965 - acc: 0.8667\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2943 - acc: 0.8680\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2924 - acc: 0.8685\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2897 - acc: 0.8700\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2904 - acc: 0.8700\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2877 - acc: 0.8705\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2864 - acc: 0.8712\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2837 - acc: 0.8721\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2813 - acc: 0.8735\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2838 - acc: 0.8725\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2769 - acc: 0.8758\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2784 - acc: 0.8749\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2728 - acc: 0.8775\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2733 - acc: 0.8775\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2673 - acc: 0.8809\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2628 - acc: 0.8834\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2579 - acc: 0.8867\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2524 - acc: 0.8897\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2485 - acc: 0.8912\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2471 - acc: 0.8921\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2417 - acc: 0.8950\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2369 - acc: 0.8973\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2335 - acc: 0.8990\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2308 - acc: 0.9006\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2275 - acc: 0.9020\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2271 - acc: 0.9021\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2213 - acc: 0.9049\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2183 - acc: 0.9064\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2160 - acc: 0.9073\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2126 - acc: 0.9089\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2118 - acc: 0.9093\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2076 - acc: 0.9112\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2057 - acc: 0.9121\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2025 - acc: 0.9136\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1992 - acc: 0.9149\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1969 - acc: 0.9159\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1956 - acc: 0.9167\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1935 - acc: 0.9177\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1912 - acc: 0.9185\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1897 - acc: 0.9193\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1862 - acc: 0.9210\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1847 - acc: 0.9216\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1839 - acc: 0.9218\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1810 - acc: 0.9231\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1780 - acc: 0.9246\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1780 - acc: 0.9246\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1769 - acc: 0.9249\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1744 - acc: 0.9262\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1722 - acc: 0.9272\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1710 - acc: 0.9277\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1712 - acc: 0.9278\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1697 - acc: 0.9279\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1670 - acc: 0.9293\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1655 - acc: 0.9302\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1644 - acc: 0.9306\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1630 - acc: 0.9313\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1614 - acc: 0.9319\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1600 - acc: 0.9327\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1584 - acc: 0.9332\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1573 - acc: 0.9339\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1569 - acc: 0.9340\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1562 - acc: 0.9344\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1544 - acc: 0.9350\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1533 - acc: 0.9355\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1519 - acc: 0.9364\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1514 - acc: 0.9363\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1498 - acc: 0.9372\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1494 - acc: 0.9374\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1486 - acc: 0.9377\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1477 - acc: 0.9382\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1462 - acc: 0.9388\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1456 - acc: 0.9389\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1444 - acc: 0.9393\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1441 - acc: 0.9397\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1436 - acc: 0.9400\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1424 - acc: 0.9406\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1419 - acc: 0.9405\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1404 - acc: 0.9415\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1393 - acc: 0.9420\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1387 - acc: 0.9420\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1384 - acc: 0.9421\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1370 - acc: 0.9431\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1365 - acc: 0.9429\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1363 - acc: 0.9431\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1352 - acc: 0.9436\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1339 - acc: 0.9442\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1337 - acc: 0.9443\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1335 - acc: 0.9445\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1314 - acc: 0.9453\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1319 - acc: 0.9451\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1313 - acc: 0.9453\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1305 - acc: 0.9456\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1301 - acc: 0.9458\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1295 - acc: 0.9459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72     43194\n",
      "           1       0.70      0.64      0.67     23145\n",
      "           2       0.77      0.78      0.77     39839\n",
      "\n",
      "    accuracy                           0.73    106178\n",
      "   macro avg       0.72      0.72      0.72    106178\n",
      "weighted avg       0.73      0.73      0.73    106178\n",
      "\n",
      "Acur√°cia\n",
      "0.7166630040526923\n",
      "Precisao\n",
      "0.7282935035548269\n",
      "Recall\n",
      "0.7288892237563337\n",
      "F1\n",
      "0.7282717145187605\n",
      "[[31435  4563  7196]\n",
      " [ 6100 14839  2206]\n",
      " [ 6812  1909 31118]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   4    8   11   12   17   20   30   43   45   53   54   67   70   75\n",
      "   76   77   81   82   91   93   95   97  101  112  119  122  125  134\n",
      "  141  142  148  154  164  166  167  170  173  177  180  181  191  194\n",
      "  199  201  203  225  227  228  230  237  238  241  244  248  255  264\n",
      "  265  272  276  278  282  284  289  290  292  301  306  309  313  330\n",
      "  337  345  347  350  352  355  358  361  363  369  370  373  375  390\n",
      "  392  394  403  406  408  416  423  424  425  429  430  435  436  439\n",
      "  440  445  450  452  469  475  479  487  508  509  514  527  534  535\n",
      "  546  547  548  556  557  559  567  568  583  590  599  600  604  606\n",
      "  612  613  627  630  634  638  641  644  645  649  663  667  690  691\n",
      "  692  696  712  721  725  727  737  744  750  766  767  768  769  770\n",
      "  786  794  799  804  814  817  818  826  828  842  845  860  865  886\n",
      "  887  888  891  893  895  900  903  906  918  920  927  935  936  948\n",
      "  954  956  959  970  971  973  978  986  996 1000 1002 1004 1007 1008\n",
      " 1010 1011 1014 1016 1018 1031 1035 1042 1044 1050 1051 1054 1058 1060\n",
      " 1064 1065 1068 1081 1083 1085 1087 1091 1093 1094 1095 1098 1099 1109\n",
      " 1111 1113 1114 1115 1117 1124 1125 1130 1132 1136 1144 1145 1149 1150\n",
      " 1151 1152 1153 1155 1157 1173 1175 1179 1180 1182 1183 1185 1188 1189\n",
      " 1190 1194 1206 1211 1215 1220 1222 1223 1232 1235 1245 1249 1252 1257\n",
      " 1261 1263 1265 1283 1285 1302 1305 1314 1317 1324 1329 1332 1335 1339\n",
      " 1367 1375 1379 1382 1388 1394 1403 1408 1409 1412 1417 1422 1426 1437\n",
      " 1448 1449 1466 1469 1472 1476 1477 1483 1484 1504 1512 1515 1522 1523\n",
      " 1525 1530 1532 1533 1534 1542 1547 1553 1557 1559 1566 1567 1576 1587\n",
      " 1589 1591 1594 1601 1612 1614 1615 1620 1626 1627 1631 1643 1646 1650\n",
      " 1651 1652 1654 1656 1664 1670 1689 1693 1715 1720 1727 1729 1737 1741\n",
      " 1746 1748 1752 1759 1762 1763 1764 1768 1772 1777 1779 1786 1788 1789\n",
      " 1792 1796 1798 1806 1812 1817 1820 1822 1829 1832 1833 1842 1868 1880\n",
      " 1882 1893 1901 1903 1908 1909 1914 1915 1939 1942 1944 1945 1949 1954\n",
      " 1959 1963 1972 1974 1978 1983 1986 1987]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.3398 - acc: 0.7640\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3126 - acc: 0.8583\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3068 - acc: 0.8618\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3045 - acc: 0.8628\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3028 - acc: 0.8627\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2998 - acc: 0.8642\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2974 - acc: 0.8660\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3001 - acc: 0.8639\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2971 - acc: 0.8654\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2918 - acc: 0.8678\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2906 - acc: 0.8685\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2883 - acc: 0.8695\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2855 - acc: 0.8710\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2835 - acc: 0.8721\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2841 - acc: 0.8724\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2805 - acc: 0.8741\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2779 - acc: 0.8757\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2785 - acc: 0.8756\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2759 - acc: 0.8768\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2757 - acc: 0.8765\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2688 - acc: 0.8801\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2641 - acc: 0.8827\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2614 - acc: 0.8848\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2548 - acc: 0.8883\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2485 - acc: 0.8917\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2462 - acc: 0.8931\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2415 - acc: 0.8957\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2379 - acc: 0.8972\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2360 - acc: 0.8982\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2359 - acc: 0.8985\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2328 - acc: 0.8995\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2274 - acc: 0.9022\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2224 - acc: 0.9047\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2202 - acc: 0.9054\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2173 - acc: 0.9068\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2156 - acc: 0.9077\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2125 - acc: 0.9089\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2093 - acc: 0.9107\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2073 - acc: 0.9116\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2038 - acc: 0.9129\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2025 - acc: 0.9134\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2001 - acc: 0.9145\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1970 - acc: 0.9161\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1936 - acc: 0.9176\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1920 - acc: 0.9183\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1894 - acc: 0.9194\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1868 - acc: 0.9209\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1871 - acc: 0.9206\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1838 - acc: 0.9221\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1827 - acc: 0.9225\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1793 - acc: 0.9240\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1786 - acc: 0.9242\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1768 - acc: 0.9253\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1758 - acc: 0.9255\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1736 - acc: 0.9266\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1720 - acc: 0.9273\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1696 - acc: 0.9285\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1679 - acc: 0.9291\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1667 - acc: 0.9295\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1645 - acc: 0.9308\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1637 - acc: 0.9310\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1623 - acc: 0.9315\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1611 - acc: 0.9321\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1620 - acc: 0.9316\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1590 - acc: 0.9330\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1571 - acc: 0.9339\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1562 - acc: 0.9343\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1548 - acc: 0.9351\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1530 - acc: 0.9357\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1528 - acc: 0.9359\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1521 - acc: 0.9362\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1507 - acc: 0.9367\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1490 - acc: 0.9378\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1482 - acc: 0.9378\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1487 - acc: 0.9377\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1461 - acc: 0.9386\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1453 - acc: 0.9391\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1453 - acc: 0.9390\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1433 - acc: 0.9400\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1423 - acc: 0.9407\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1430 - acc: 0.9400\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1407 - acc: 0.9411\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1411 - acc: 0.9410\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1390 - acc: 0.9419\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1385 - acc: 0.9422\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1386 - acc: 0.9422\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1372 - acc: 0.9426\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1370 - acc: 0.9427\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1358 - acc: 0.9433\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1354 - acc: 0.9436\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1351 - acc: 0.9436\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1337 - acc: 0.9442\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1328 - acc: 0.9450\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1333 - acc: 0.9442\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1323 - acc: 0.9448\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1318 - acc: 0.9453\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1294 - acc: 0.9464\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1307 - acc: 0.9457\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1290 - acc: 0.9462\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1287 - acc: 0.9464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72     42626\n",
      "           1       0.69      0.63      0.66     23953\n",
      "           2       0.76      0.78      0.77     36861\n",
      "\n",
      "    accuracy                           0.72    103440\n",
      "   macro avg       0.72      0.71      0.72    103440\n",
      "weighted avg       0.72      0.72      0.72    103440\n",
      "\n",
      "Acur√°cia\n",
      "0.7130667252949449\n",
      "Precisao\n",
      "0.7231503182531579\n",
      "Recall\n",
      "0.724100928074246\n",
      "F1\n",
      "0.7231589813578579\n",
      "[[30889  4899  6838]\n",
      " [ 6482 15086  2385]\n",
      " [ 6161  1774 28926]]\n",
      "TRAIN: [   0    1    2 ... 1996 1997 1999] TEST: [   6    9   14   16   18   31   34   37   42   46   47   49   51   55\n",
      "   60   62   65   71   88   94  105  107  108  109  111  116  127  131\n",
      "  139  143  144  145  151  155  159  161  163  165  183  186  189  190\n",
      "  196  200  202  207  210  216  217  218  267  269  273  281  295  298\n",
      "  299  300  302  303  305  321  322  325  331  334  341  346  359  362\n",
      "  365  374  377  381  384  398  400  412  413  414  415  417  418  420\n",
      "  426  434  444  457  459  462  465  470  471  473  480  500  516  518\n",
      "  521  522  523  530  533  536  543  544  545  552  574  575  581  584\n",
      "  589  592  594  601  607  610  611  614  617  620  621  622  636  642\n",
      "  660  661  662  664  669  675  680  681  682  683  687  688  689  711\n",
      "  722  729  736  738  745  752  758  760  764  765  772  777  787  797\n",
      "  802  813  815  821  831  832  833  839  850  853  856  861  864  877\n",
      "  882  884  889  896  905  907  910  911  912  915  917  919  923  925\n",
      "  929  932  939  940  942  947  952  953  957  958  962  964  975  982\n",
      "  987 1003 1005 1015 1024 1030 1034 1039 1040 1043 1045 1048 1057 1062\n",
      " 1063 1067 1071 1073 1074 1076 1096 1100 1102 1122 1127 1128 1139 1154\n",
      " 1161 1172 1174 1176 1177 1191 1197 1198 1200 1205 1210 1212 1221 1229\n",
      " 1230 1233 1250 1259 1262 1266 1271 1273 1274 1279 1282 1288 1289 1292\n",
      " 1295 1297 1304 1311 1320 1323 1325 1328 1330 1331 1334 1336 1337 1340\n",
      " 1343 1345 1346 1349 1351 1357 1361 1362 1364 1370 1371 1384 1385 1386\n",
      " 1389 1400 1402 1405 1411 1420 1421 1431 1438 1439 1440 1443 1445 1446\n",
      " 1451 1453 1454 1458 1471 1473 1475 1482 1487 1492 1495 1502 1503 1516\n",
      " 1517 1526 1529 1535 1539 1544 1548 1555 1558 1562 1568 1571 1573 1577\n",
      " 1593 1595 1602 1607 1608 1611 1618 1621 1642 1655 1657 1660 1666 1673\n",
      " 1676 1677 1694 1704 1705 1706 1708 1710 1712 1713 1717 1719 1733 1735\n",
      " 1745 1749 1751 1753 1758 1761 1765 1766 1780 1783 1785 1787 1791 1794\n",
      " 1795 1797 1824 1836 1840 1846 1847 1854 1874 1879 1881 1883 1886 1888\n",
      " 1892 1894 1896 1904 1905 1924 1927 1930 1932 1933 1937 1938 1940 1961\n",
      " 1962 1967 1971 1977 1984 1992 1995 1998]\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.3394 - acc: 0.8203\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3168 - acc: 0.8566\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3096 - acc: 0.8607\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3088 - acc: 0.8606\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3049 - acc: 0.8622\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3023 - acc: 0.8635\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2991 - acc: 0.8655\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2989 - acc: 0.8655\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2962 - acc: 0.8671\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2964 - acc: 0.8663\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2925 - acc: 0.8679\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2894 - acc: 0.8696\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2867 - acc: 0.8707\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2869 - acc: 0.8716\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2868 - acc: 0.8715\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2833 - acc: 0.8729\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2818 - acc: 0.8737\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2789 - acc: 0.8747\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2763 - acc: 0.8761\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2738 - acc: 0.8774\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2712 - acc: 0.8793\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2692 - acc: 0.8807\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2648 - acc: 0.8826\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2639 - acc: 0.8829\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2561 - acc: 0.8875\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2512 - acc: 0.8902\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2468 - acc: 0.8923\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2417 - acc: 0.8953\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2400 - acc: 0.8959\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2356 - acc: 0.8984\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2333 - acc: 0.8994\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2289 - acc: 0.9016\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2259 - acc: 0.9025\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2240 - acc: 0.9039\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2194 - acc: 0.9058\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2185 - acc: 0.9060\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2143 - acc: 0.9081\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2111 - acc: 0.9096\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2075 - acc: 0.9110\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2058 - acc: 0.9119\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2041 - acc: 0.9125\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2000 - acc: 0.9146\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1997 - acc: 0.9150\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1947 - acc: 0.9171\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1924 - acc: 0.9181\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1910 - acc: 0.9189\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1883 - acc: 0.9199\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1863 - acc: 0.9207\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1851 - acc: 0.9209\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1832 - acc: 0.9225\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1813 - acc: 0.9231\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1801 - acc: 0.9235\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1778 - acc: 0.9243\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1758 - acc: 0.9250\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1736 - acc: 0.9262\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1720 - acc: 0.9266\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1710 - acc: 0.9273\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1692 - acc: 0.9280\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1690 - acc: 0.9283\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1666 - acc: 0.9295\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1651 - acc: 0.9302\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1654 - acc: 0.9303\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1623 - acc: 0.9313\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1599 - acc: 0.9325\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1589 - acc: 0.9326\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1589 - acc: 0.9327\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1577 - acc: 0.9337\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1568 - acc: 0.9339\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1555 - acc: 0.9345\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1540 - acc: 0.9349\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1523 - acc: 0.9356\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1516 - acc: 0.9359\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1511 - acc: 0.9361\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1501 - acc: 0.9359\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1484 - acc: 0.9367\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1477 - acc: 0.9378\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1471 - acc: 0.9381\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1464 - acc: 0.9385\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1450 - acc: 0.9385\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1442 - acc: 0.9395\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1435 - acc: 0.9396\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1421 - acc: 0.9405\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1411 - acc: 0.9409\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1406 - acc: 0.9408\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1393 - acc: 0.9415\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1396 - acc: 0.9409\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1382 - acc: 0.9418\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1376 - acc: 0.9418\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1374 - acc: 0.9420\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1364 - acc: 0.9428\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1348 - acc: 0.9432\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1349 - acc: 0.9431\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1338 - acc: 0.9438\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1334 - acc: 0.9431\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1327 - acc: 0.9437\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1321 - acc: 0.9443\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1315 - acc: 0.9447\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1312 - acc: 0.9448\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1302 - acc: 0.9451\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1301 - acc: 0.9454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72     41355\n",
      "           1       0.68      0.63      0.65     22035\n",
      "           2       0.78      0.76      0.77     37501\n",
      "\n",
      "    accuracy                           0.72    100891\n",
      "   macro avg       0.72      0.71      0.71    100891\n",
      "weighted avg       0.72      0.72      0.72    100891\n",
      "\n",
      "Acur√°cia\n",
      "0.7098717759293507\n",
      "Precisao\n",
      "0.7238232185920744\n",
      "Recall\n",
      "0.7232260558424438\n",
      "F1\n",
      "0.7229791552622332\n",
      "[[30679  4488  6188]\n",
      " [ 6282 13898  1855]\n",
      " [ 7051  2060 28390]]\n",
      "TRAIN: [   0    1    3 ... 1996 1997 1998] TEST: [   2   21   24   26   27   28   29   33   35   36   39   40   41   59\n",
      "   61   63   64   72   73   79   87   92   96   98   99  124  129  132\n",
      "  133  138  140  147  152  156  158  172  175  176  178  185  192  193\n",
      "  195  198  209  213  219  221  223  224  229  231  232  234  235  246\n",
      "  247  251  252  254  261  266  270  274  277  283  293  304  310  316\n",
      "  319  324  326  335  342  349  356  364  378  379  380  385  387  389\n",
      "  391  393  395  405  411  422  437  446  447  458  460  463  476  478\n",
      "  482  483  489  502  503  507  513  517  519  532  539  540  541  542\n",
      "  549  553  554  560  561  563  566  570  571  573  578  582  586  587\n",
      "  591  593  595  598  605  615  619  624  626  628  637  639  646  655\n",
      "  656  658  659  666  668  674  677  684  685  694  697  704  708  713\n",
      "  718  720  728  740  741  749  753  759  761  763  771  774  776  782\n",
      "  785  790  793  795  800  803  805  811  827  829  835  836  838  840\n",
      "  841  843  847  848  852  855  862  867  872  876  880  883  890  892\n",
      "  894  899  902  904  909  913  924  928  943  945  950  960  961  965\n",
      "  969  974  980  984  991  992  993  999 1020 1027 1032 1037 1046 1049\n",
      " 1052 1061 1072 1084 1101 1106 1110 1112 1116 1119 1131 1146 1158 1162\n",
      " 1163 1164 1169 1170 1178 1193 1195 1208 1224 1226 1234 1239 1240 1244\n",
      " 1247 1256 1268 1269 1270 1275 1276 1277 1294 1306 1312 1313 1326 1327\n",
      " 1338 1341 1342 1347 1348 1352 1360 1366 1376 1378 1383 1387 1391 1392\n",
      " 1395 1414 1424 1441 1447 1452 1456 1461 1485 1486 1490 1505 1506 1507\n",
      " 1510 1511 1520 1521 1527 1531 1537 1543 1545 1549 1550 1561 1565 1570\n",
      " 1582 1583 1590 1596 1599 1600 1604 1605 1606 1610 1619 1622 1624 1625\n",
      " 1630 1633 1634 1635 1638 1639 1653 1661 1662 1663 1669 1672 1674 1681\n",
      " 1685 1688 1691 1692 1698 1700 1701 1703 1714 1721 1723 1725 1739 1744\n",
      " 1747 1750 1754 1757 1760 1769 1770 1781 1782 1790 1799 1802 1804 1810\n",
      " 1814 1821 1823 1825 1838 1843 1845 1848 1851 1852 1857 1861 1862 1864\n",
      " 1866 1869 1871 1876 1889 1902 1916 1917 1919 1922 1925 1934 1941 1943\n",
      " 1946 1948 1958 1975 1979 1981 1994 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.3399 - acc: 0.7590\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3135 - acc: 0.8585\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3069 - acc: 0.8618\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3045 - acc: 0.8628\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3026 - acc: 0.8633\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.3003 - acc: 0.8644\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2985 - acc: 0.8651\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2949 - acc: 0.8666\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2924 - acc: 0.8683\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2913 - acc: 0.8685\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2898 - acc: 0.8700\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2893 - acc: 0.8702\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2857 - acc: 0.8716\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2832 - acc: 0.8731\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2829 - acc: 0.8729\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2845 - acc: 0.8722\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2804 - acc: 0.8750\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2774 - acc: 0.8765\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2758 - acc: 0.8778\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2738 - acc: 0.8785\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2689 - acc: 0.8813\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2669 - acc: 0.8829\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2612 - acc: 0.8854\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2555 - acc: 0.8889\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2519 - acc: 0.8903\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2478 - acc: 0.8926\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2445 - acc: 0.8938\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2445 - acc: 0.8939\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2370 - acc: 0.8969\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2330 - acc: 0.8995\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2314 - acc: 0.8999\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2279 - acc: 0.9017\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2243 - acc: 0.9036\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2208 - acc: 0.9051\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2174 - acc: 0.9064\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2149 - acc: 0.9077\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2142 - acc: 0.9084\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2094 - acc: 0.9103\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2073 - acc: 0.9117\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2050 - acc: 0.9126\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.2019 - acc: 0.9139\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1986 - acc: 0.9155\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1967 - acc: 0.9159\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1946 - acc: 0.9170\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1945 - acc: 0.9171\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1902 - acc: 0.9192\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1887 - acc: 0.9202\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1860 - acc: 0.9211\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1838 - acc: 0.9220\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1814 - acc: 0.9233\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1798 - acc: 0.9237\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1786 - acc: 0.9244\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1762 - acc: 0.9253\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1747 - acc: 0.9260\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1730 - acc: 0.9268\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1729 - acc: 0.9268\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1690 - acc: 0.9287\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1684 - acc: 0.9287\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1669 - acc: 0.9292\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1650 - acc: 0.9305\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1634 - acc: 0.9308\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1621 - acc: 0.9314\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1610 - acc: 0.9317\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1596 - acc: 0.9326\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1582 - acc: 0.9335\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1571 - acc: 0.9340\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1563 - acc: 0.9341\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1543 - acc: 0.9349\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1539 - acc: 0.9353\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1522 - acc: 0.9360\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1511 - acc: 0.9364\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1493 - acc: 0.9371\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1491 - acc: 0.9373\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1477 - acc: 0.9376\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1464 - acc: 0.9378\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1479 - acc: 0.9377\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1447 - acc: 0.9391\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1438 - acc: 0.9395\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1441 - acc: 0.9390\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1428 - acc: 0.9396\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1422 - acc: 0.9397\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1411 - acc: 0.9404\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1402 - acc: 0.9406\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1400 - acc: 0.9412\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1383 - acc: 0.9415\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1372 - acc: 0.9424\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1366 - acc: 0.9424\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1364 - acc: 0.9426\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1363 - acc: 0.9429\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1359 - acc: 0.9433\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1339 - acc: 0.9440\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1331 - acc: 0.9443\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1319 - acc: 0.9446\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1322 - acc: 0.9444\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1312 - acc: 0.9452\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1304 - acc: 0.9452\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1295 - acc: 0.9457\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1303 - acc: 0.9452\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1291 - acc: 0.9460\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 17s 11ms/sample - loss: 0.1273 - acc: 0.9468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72     41852\n",
      "           1       0.69      0.64      0.66     23428\n",
      "           2       0.77      0.76      0.77     37923\n",
      "\n",
      "    accuracy                           0.72    103203\n",
      "   macro avg       0.72      0.71      0.72    103203\n",
      "weighted avg       0.72      0.72      0.72    103203\n",
      "\n",
      "Acur√°cia\n",
      "0.7114818811891342\n",
      "Precisao\n",
      "0.7234547005687534\n",
      "Recall\n",
      "0.723021617588636\n",
      "F1\n",
      "0.7227078725087287\n",
      "[[30919  4767  6166]\n",
      " [ 6246 14917  2265]\n",
      " [ 7235  1906 28782]]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_63 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_64 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_65 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_66 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_67 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_68 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_69 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 700, 3)            603       \n",
      "=================================================================\n",
      "Total params: 1,161,003\n",
      "Trainable params: 1,161,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acur√°cias total\n",
      "[0.7139502019340705, 0.7166630040526923, 0.7130667252949449, 0.7098717759293507, 0.7114818811891342]\n",
      "0.7130067176800385\n",
      "Precision total\n",
      "[0.7264754069853382, 0.7282935035548269, 0.7231503182531579, 0.7238232185920744, 0.7234547005687534]\n",
      "0.7250394295908302\n",
      "Recalls total\n",
      "[0.7265808650681711, 0.7288892237563337, 0.724100928074246, 0.7232260558424438, 0.723021617588636]\n",
      "0.7251637380659661\n",
      "F1 total\n",
      "[0.7262232244213146, 0.7282717145187605, 0.7231589813578579, 0.7229791552622332, 0.7227078725087287]\n",
      "0.724668189613779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(8)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ8[train_index],\n",
    "                           previsores[test_index], classesQ8[test_index], 8)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(3)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ3[train_index],\n",
    "                           previsores[test_index], classesQ3[test_index], 3)\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
