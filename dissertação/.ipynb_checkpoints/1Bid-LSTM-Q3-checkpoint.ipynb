{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 20:28].values\n",
    "classes = np.reshape(classes, (2000, 700, 8))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    #model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(8, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 100, verbose = 1)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 8))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 8))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   4    8   12   15   21   23   26   30   31   43   48   55   58   59\n",
      "   62   63   65   68   80   84   88   91   93   94   98  111  120  122\n",
      "  124  134  136  139  140  143  163  169  174  176  180  181  185  207\n",
      "  219  226  233  234  235  238  240  262  263  265  269  274  278  282\n",
      "  290  291  294  296  303  305  307  308  309  313  317  320  325  336\n",
      "  337  339  346  348  354  362  365  368  370  375  377  378  384  390\n",
      "  400  407  409  425  434  436  438  441  451  452  463  466  469  481\n",
      "  483  488  497  498  501  503  509  513  526  537  544  547  564  589\n",
      "  602  603  605  608  613  614  619  624  629  630  638  646  647  652\n",
      "  663  668  669  670  673  680  682  694  697  702  703  706  708  716\n",
      "  719  722  725  731  732  734  741  742  744  745  749  759  763  768\n",
      "  775  776  782  788  790  791  795  798  801  802  806  812  827  832\n",
      "  836  850  860  868  871  872  885  889  892  895  903  907  911  914\n",
      "  928  932  940  941  943  956  958  963  964  976  985  986  989  990\n",
      " 1013 1019 1020 1021 1028 1030 1044 1049 1052 1055 1056 1063 1065 1067\n",
      " 1080 1083 1096 1097 1106 1111 1119 1123 1129 1138 1144 1145 1159 1161\n",
      " 1163 1169 1178 1180 1183 1185 1192 1206 1220 1222 1223 1229 1231 1234\n",
      " 1240 1241 1250 1254 1260 1262 1263 1264 1267 1276 1278 1281 1285 1288\n",
      " 1292 1297 1298 1302 1304 1320 1326 1336 1339 1343 1348 1349 1353 1357\n",
      " 1360 1362 1363 1368 1370 1374 1377 1380 1386 1387 1391 1399 1401 1411\n",
      " 1421 1431 1437 1438 1446 1456 1466 1467 1471 1474 1481 1482 1490 1495\n",
      " 1504 1510 1520 1523 1527 1528 1533 1535 1537 1544 1550 1560 1566 1569\n",
      " 1574 1576 1591 1595 1596 1602 1604 1607 1609 1624 1631 1642 1646 1653\n",
      " 1657 1663 1674 1678 1679 1683 1684 1685 1690 1696 1706 1713 1717 1723\n",
      " 1725 1730 1733 1734 1737 1739 1741 1742 1744 1754 1765 1774 1776 1778\n",
      " 1781 1782 1784 1785 1789 1794 1795 1802 1804 1810 1812 1817 1827 1836\n",
      " 1841 1844 1847 1849 1851 1860 1866 1870 1874 1879 1881 1885 1886 1889\n",
      " 1893 1894 1904 1910 1918 1921 1922 1923 1926 1928 1932 1937 1943 1947\n",
      " 1949 1952 1975 1978 1985 1993 1994 1995]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.6451 - acc: 0.1290 1s - loss: 0.\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5962 - acc: 0.1411\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5629 - acc: 0.1603\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5433 - acc: 0.1676\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5311 - acc: 0.1732\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5253 - acc: 0.1756\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5209 - acc: 0.1779\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5167 - acc: 0.1798\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5127 - acc: 0.1816\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5099 - acc: 0.1829\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5074 - acc: 0.1840\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5081 - acc: 0.1841\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5050 - acc: 0.1852\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5020 - acc: 0.1863\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5011 - acc: 0.1864\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4972 - acc: 0.1883\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4973 - acc: 0.1881\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4962 - acc: 0.1885\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4932 - acc: 0.1900\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4926 - acc: 0.1903\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4897 - acc: 0.1915\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4901 - acc: 0.1912\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4888 - acc: 0.1918\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4868 - acc: 0.1927\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4863 - acc: 0.1929\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4860 - acc: 0.1930\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4832 - acc: 0.1940\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4814 - acc: 0.1949\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4830 - acc: 0.1942\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4818 - acc: 0.1949\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4783 - acc: 0.1963\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4804 - acc: 0.1954\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4762 - acc: 0.1975\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4755 - acc: 0.1974\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4731 - acc: 0.1987\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4730 - acc: 0.1983\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4727 - acc: 0.1985\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4697 - acc: 0.1999\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4681 - acc: 0.2005\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4691 - acc: 0.1998\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4690 - acc: 0.1999\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4647 - acc: 0.2013\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4626 - acc: 0.2023\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4656 - acc: 0.2013\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4611 - acc: 0.2029\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4590 - acc: 0.2034\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4552 - acc: 0.2053\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4541 - acc: 0.2058\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4536 - acc: 0.2056\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4511 - acc: 0.2067\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4504 - acc: 0.2067\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4488 - acc: 0.2077\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4480 - acc: 0.2081\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4476 - acc: 0.2078\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4436 - acc: 0.2096 0s - loss: 0.4449 - a\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4462 - acc: 0.2086\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4544 - acc: 0.2053\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4439 - acc: 0.2093\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4429 - acc: 0.2098\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4471 - acc: 0.2084\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4429 - acc: 0.2098\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4390 - acc: 0.2112\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4371 - acc: 0.2118\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4349 - acc: 0.2124\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4335 - acc: 0.2132\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4318 - acc: 0.2136\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4309 - acc: 0.2139\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4289 - acc: 0.2146\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4291 - acc: 0.2146\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4274 - acc: 0.2150\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4281 - acc: 0.2147\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4249 - acc: 0.2160\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4226 - acc: 0.2168\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4215 - acc: 0.2172\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4192 - acc: 0.2180\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4191 - acc: 0.2178\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4187 - acc: 0.2181\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4192 - acc: 0.2182 0s - loss: 0.4196 - acc:\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4171 - acc: 0.2187\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4144 - acc: 0.2198\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4133 - acc: 0.2201\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4125 - acc: 0.2202\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4117 - acc: 0.2204\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4115 - acc: 0.2206\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4091 - acc: 0.2215\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4067 - acc: 0.2219\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4062 - acc: 0.2225\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4071 - acc: 0.2220\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4088 - acc: 0.2212 0s - loss: 0.41\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4039 - acc: 0.2231\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4036 - acc: 0.2233 0s - loss: 0.4023 - acc\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4018 - acc: 0.2239 0s - loss: 0.404\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3998 - acc: 0.2244\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3995 - acc: 0.2246\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3983 - acc: 0.2252\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3967 - acc: 0.2254\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3961 - acc: 0.2257\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3949 - acc: 0.2261\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3959 - acc: 0.2255\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3950 - acc: 0.2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1280\n",
      "           1       0.56      0.66      0.61     22435\n",
      "           2       0.25      0.04      0.07      3757\n",
      "           3       0.68      0.76      0.72     33317\n",
      "           4       0.37      0.03      0.05       790\n",
      "           5       0.41      0.54      0.46     20622\n",
      "           6       0.33      0.03      0.06      9002\n",
      "           7       0.37      0.32      0.35     11470\n",
      "\n",
      "    accuracy                           0.54    102673\n",
      "   macro avg       0.37      0.30      0.29    102673\n",
      "weighted avg       0.51      0.54      0.51    102673\n",
      "\n",
      "Acur√°cia\n",
      "0.29833499781154815\n",
      "Precisao\n",
      "0.5062709990344164\n",
      "Recall\n",
      "0.540278359451852\n",
      "F1\n",
      "0.5052519954521884\n",
      "[[    0   366     3   213     1   577    15   105]\n",
      " [    0 14853    40  2979     3  3636    80   844]\n",
      " [    0   633   154  1169     0  1206    38   557]\n",
      " [    0  3210   154 25379    19  3148    39  1368]\n",
      " [    0    87     1   505    23   100     0    74]\n",
      " [    0  4246   102  3167     7 11056   253  1791]\n",
      " [    0  1505    57  1465     4  4161   306  1504]\n",
      " [    0  1460    97  2711     5  3290   206  3701]]\n",
      "TRAIN: [   0    1    2 ... 1996 1997 1998] TEST: [   5    7    9   14   18   20   22   32   34   36   37   40   41   47\n",
      "   52   56   57   85   90   95  100  102  106  118  123  125  128  133\n",
      "  146  147  156  157  161  164  171  178  187  191  197  198  201  205\n",
      "  206  212  214  216  220  224  228  230  241  242  248  249  250  255\n",
      "  259  264  268  270  275  279  281  289  293  302  304  311  314  316\n",
      "  323  333  334  338  349  350  359  360  367  371  380  383  385  386\n",
      "  387  392  394  398  399  401  402  413  422  428  430  433  444  446\n",
      "  456  457  470  474  475  476  480  493  518  521  524  535  538  539\n",
      "  546  548  561  573  581  588  591  606  620  622  633  636  648  649\n",
      "  655  658  664  665  674  678  679  681  686  688  690  710  711  718\n",
      "  728  735  737  738  752  756  762  764  766  772  774  778  789  804\n",
      "  809  811  814  816  823  840  853  859  864  866  867  874  876  888\n",
      "  891  893  894  896  901  905  909  912  913  916  919  921  924  925\n",
      "  937  939  945  948  950  951  960  975  978  979  983  988  991  995\n",
      "  998  999 1000 1002 1003 1008 1009 1011 1012 1024 1025 1038 1042 1046\n",
      " 1047 1048 1050 1051 1054 1057 1064 1068 1081 1088 1091 1098 1102 1108\n",
      " 1110 1122 1127 1130 1134 1139 1143 1148 1149 1160 1164 1172 1176 1189\n",
      " 1194 1195 1199 1201 1204 1209 1213 1225 1228 1233 1243 1247 1249 1287\n",
      " 1296 1308 1311 1313 1314 1317 1321 1324 1330 1331 1333 1334 1338 1342\n",
      " 1347 1350 1351 1352 1354 1355 1369 1372 1402 1403 1408 1412 1418 1419\n",
      " 1422 1427 1436 1439 1444 1447 1449 1453 1460 1464 1465 1468 1469 1472\n",
      " 1483 1500 1502 1515 1521 1522 1526 1529 1530 1534 1546 1556 1558 1559\n",
      " 1567 1570 1571 1572 1577 1578 1581 1590 1592 1594 1599 1601 1605 1608\n",
      " 1616 1620 1621 1626 1633 1649 1651 1655 1658 1665 1671 1672 1673 1677\n",
      " 1681 1682 1687 1688 1691 1709 1710 1712 1714 1719 1726 1729 1731 1736\n",
      " 1746 1750 1753 1755 1756 1757 1762 1766 1768 1771 1777 1786 1801 1807\n",
      " 1811 1828 1830 1843 1845 1846 1848 1850 1852 1854 1855 1857 1858 1859\n",
      " 1862 1869 1872 1895 1906 1914 1927 1933 1934 1941 1951 1953 1954 1956\n",
      " 1964 1968 1971 1972 1981 1984 1986 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.6429 - acc: 0.1297\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5907 - acc: 0.1455\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5619 - acc: 0.1599\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5425 - acc: 0.1679\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5316 - acc: 0.1727\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5257 - acc: 0.1755\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5186 - acc: 0.1792\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5157 - acc: 0.1805\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5138 - acc: 0.1814\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5107 - acc: 0.1824\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5087 - acc: 0.1832\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5045 - acc: 0.1850\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5047 - acc: 0.1850\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5020 - acc: 0.1864\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4997 - acc: 0.1876 1s \n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4982 - acc: 0.1881\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4977 - acc: 0.1883\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4966 - acc: 0.1885\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4931 - acc: 0.1899\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4928 - acc: 0.1906\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4903 - acc: 0.1913\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4924 - acc: 0.1903\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4893 - acc: 0.1914\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4891 - acc: 0.1916\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4873 - acc: 0.1926\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4868 - acc: 0.1929\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4857 - acc: 0.1931\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4842 - acc: 0.1934\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4835 - acc: 0.1941\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4808 - acc: 0.1953\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4794 - acc: 0.1956\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4785 - acc: 0.1962\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4812 - acc: 0.1949\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4799 - acc: 0.1952\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4753 - acc: 0.1974\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4744 - acc: 0.1976\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4731 - acc: 0.1981\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4701 - acc: 0.1998\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4689 - acc: 0.1999\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4702 - acc: 0.1995\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4655 - acc: 0.2016\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4664 - acc: 0.2011\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4622 - acc: 0.2024\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4602 - acc: 0.2034\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4630 - acc: 0.2024\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4659 - acc: 0.2007\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4612 - acc: 0.2028\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4582 - acc: 0.2042\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4547 - acc: 0.2054\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4574 - acc: 0.2044\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4530 - acc: 0.2064 1s - \n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4508 - acc: 0.2073\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4512 - acc: 0.2069\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4485 - acc: 0.2080\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4477 - acc: 0.2081\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4444 - acc: 0.2093\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4436 - acc: 0.2097\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4419 - acc: 0.2104\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4424 - acc: 0.2102\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4409 - acc: 0.2106\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4394 - acc: 0.2115\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4382 - acc: 0.2116\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4352 - acc: 0.2125\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4334 - acc: 0.2133\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4322 - acc: 0.2139\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4308 - acc: 0.2143\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4316 - acc: 0.2140\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4288 - acc: 0.2149\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4285 - acc: 0.2151 1s - l\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4274 - acc: 0.2153\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4263 - acc: 0.2160\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4268 - acc: 0.2158 1s - loss\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4283 - acc: 0.2149\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4226 - acc: 0.2171\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4260 - acc: 0.2160\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4200 - acc: 0.2180\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4182 - acc: 0.2187\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4162 - acc: 0.2194\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4153 - acc: 0.2198\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4147 - acc: 0.2198\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4131 - acc: 0.2205 0s - loss: 0.4120 - acc: 0.21\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4116 - acc: 0.2209\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4103 - acc: 0.2213\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4091 - acc: 0.2218\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4089 - acc: 0.2216\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4068 - acc: 0.2226\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4057 - acc: 0.2231\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4034 - acc: 0.2237\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4040 - acc: 0.2233\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4049 - acc: 0.2230 0s - loss: 0.4061 - acc: 0\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4020 - acc: 0.2239\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3993 - acc: 0.2249\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3998 - acc: 0.2246\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4027 - acc: 0.2237\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4191 - acc: 0.2180\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4033 - acc: 0.2235 0s - loss: 0.4060 - acc\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4012 - acc: 0.2242\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4122 - acc: 0.2203\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4036 - acc: 0.2234\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3982 - acc: 0.2252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1228\n",
      "           1       0.57      0.63      0.60     20733\n",
      "           2       0.31      0.04      0.06      4110\n",
      "           3       0.66      0.83      0.74     34416\n",
      "           4       0.67      0.06      0.11       813\n",
      "           5       0.43      0.52      0.47     20743\n",
      "           6       0.35      0.04      0.07      9182\n",
      "           7       0.37      0.32      0.34     11682\n",
      "\n",
      "    accuracy                           0.55    102907\n",
      "   macro avg       0.42      0.30      0.30    102907\n",
      "weighted avg       0.51      0.55      0.51    102907\n",
      "\n",
      "Acur√°cia\n",
      "0.3046218020882473\n",
      "Precisao\n",
      "0.5129995451005724\n",
      "Recall\n",
      "0.5515076719756673\n",
      "F1\n",
      "0.5104227556798107\n",
      "[[    0   323     6   229     0   542    17   111]\n",
      " [    0 13138    27  3427     0  3237    79   825]\n",
      " [    0   630   145  1425     0  1170    46   694]\n",
      " [    0  2245    66 28571    18  2322    54  1140]\n",
      " [    0    78     5   571    50    63     1    45]\n",
      " [    0  3845    71  3876     1 10786   276  1888]\n",
      " [    0  1433    54  1871     1  3958   364  1501]\n",
      " [    0  1350    98  3356     5  2955   218  3700]]\n",
      "TRAIN: [   0    1    4 ... 1995 1996 1999] TEST: [   2    3   13   25   28   42   45   50   60   71   72   74   77   82\n",
      "   86   89  103  108  117  119  127  129  144  148  153  162  165  167\n",
      "  177  184  188  190  195  199  204  208  209  217  218  223  229  232\n",
      "  246  247  251  266  267  272  280  283  285  292  298  312  319  328\n",
      "  329  355  358  364  374  379  389  395  396  403  405  408  412  414\n",
      "  416  418  427  429  431  437  439  440  442  443  450  453  455  465\n",
      "  468  471  477  479  489  490  495  496  504  507  508  512  515  516\n",
      "  519  525  530  531  540  558  562  563  567  572  575  577  578  582\n",
      "  584  586  590  593  594  599  604  607  611  612  615  616  617  618\n",
      "  621  623  627  628  632  645  651  654  660  661  667  676  677  684\n",
      "  689  693  696  698  709  713  720  721  723  726  727  736  743  746\n",
      "  747  748  755  765  767  779  781  783  784  793  794  796  807  818\n",
      "  825  828  829  833  834  835  839  841  851  857  875  878  882  890\n",
      "  898  900  902  930  931  933  935  942  944  946  954  955  959  967\n",
      "  968  972  973  987 1007 1017 1023 1031 1035 1036 1037 1040 1043 1045\n",
      " 1053 1059 1060 1061 1062 1069 1070 1071 1075 1079 1082 1090 1092 1093\n",
      " 1099 1100 1104 1107 1109 1112 1114 1116 1117 1120 1135 1137 1150 1153\n",
      " 1154 1157 1158 1165 1167 1171 1173 1181 1184 1188 1190 1191 1197 1198\n",
      " 1203 1211 1216 1227 1230 1236 1237 1244 1246 1252 1265 1268 1269 1273\n",
      " 1274 1275 1277 1289 1294 1299 1305 1315 1337 1344 1358 1364 1365 1366\n",
      " 1375 1381 1383 1384 1385 1390 1392 1393 1404 1410 1415 1416 1417 1429\n",
      " 1432 1433 1440 1441 1443 1452 1457 1461 1462 1470 1479 1480 1496 1508\n",
      " 1512 1514 1518 1524 1525 1536 1540 1541 1552 1554 1555 1575 1579 1586\n",
      " 1588 1598 1600 1603 1606 1611 1614 1622 1625 1639 1645 1647 1648 1656\n",
      " 1659 1662 1667 1668 1686 1692 1693 1694 1695 1698 1699 1701 1715 1722\n",
      " 1724 1735 1740 1747 1748 1752 1758 1761 1769 1773 1780 1790 1792 1796\n",
      " 1819 1825 1829 1832 1837 1856 1863 1867 1873 1877 1883 1901 1905 1907\n",
      " 1913 1915 1925 1931 1935 1936 1939 1940 1942 1948 1955 1957 1958 1961\n",
      " 1963 1966 1973 1982 1987 1988 1997 1998]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 4s 2ms/sample - loss: 0.6384 - acc: 0.1329\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5931 - acc: 0.1429\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5552 - acc: 0.1631\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5387 - acc: 0.1691\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5279 - acc: 0.1741 0s - loss: 0.5306 - acc: 0\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5247 - acc: 0.1752\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5176 - acc: 0.1787 2s - loss: 0.5504 -  - ETA:\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5132 - acc: 0.1808\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5109 - acc: 0.1819\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5090 - acc: 0.1824\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5048 - acc: 0.1845\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5046 - acc: 0.1846\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5033 - acc: 0.1848\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5000 - acc: 0.1869\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4979 - acc: 0.1876\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4952 - acc: 0.1889 1s - los\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4980 - acc: 0.1874\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4937 - acc: 0.1894 0s - loss: 0.4901 - acc:\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4964 - acc: 0.1879\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4928 - acc: 0.1896 1s\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4926 - acc: 0.1896\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4886 - acc: 0.1911 1s - loss: 0.4856 - acc: 0.193 - ETA: 1s - loss: 0.\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4892 - acc: 0.1911\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4850 - acc: 0.1930 \n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4857 - acc: 0.1925\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4830 - acc: 0.1938\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4819 - acc: 0.1941 0s - loss: 0.4833 - \n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4797 - acc: 0.1954\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4787 - acc: 0.1955\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4765 - acc: 0.1964\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4762 - acc: 0.1963\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4732 - acc: 0.1977 0s - loss: 0.4727 - acc: \n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4746 - acc: 0.1971\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4707 - acc: 0.1987\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4693 - acc: 0.1992\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4694 - acc: 0.1991\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4652 - acc: 0.2009 1s - loss: 0.\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4644 - acc: 0.2012\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4640 - acc: 0.2011\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4621 - acc: 0.2022\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4618 - acc: 0.2023\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4589 - acc: 0.2032\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4573 - acc: 0.2043\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4573 - acc: 0.2042 1s \n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4567 - acc: 0.2042\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4561 - acc: 0.2047\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4539 - acc: 0.2055\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4530 - acc: 0.2056\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4498 - acc: 0.2069\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4484 - acc: 0.2074\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4493 - acc: 0.2070\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4464 - acc: 0.2082\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4447 - acc: 0.2087\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4441 - acc: 0.2089\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4429 - acc: 0.2096\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4433 - acc: 0.2097\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4417 - acc: 0.2098\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4404 - acc: 0.2103\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4391 - acc: 0.2108\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4367 - acc: 0.2120\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4345 - acc: 0.2124\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4333 - acc: 0.2130 1s - l\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4332 - acc: 0.2127\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4323 - acc: 0.2130\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4294 - acc: 0.2144\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4347 - acc: 0.2121\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4293 - acc: 0.2143\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4263 - acc: 0.2152\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4250 - acc: 0.2158\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4242 - acc: 0.2158 1s - \n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4259 - acc: 0.2153 2s - los - ETA: 1s - los\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4228 - acc: 0.2163\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4203 - acc: 0.2172\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4191 - acc: 0.2175\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4171 - acc: 0.2185\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4166 - acc: 0.2184\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4158 - acc: 0.2188\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4238 - acc: 0.2161\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4152 - acc: 0.2192\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4148 - acc: 0.2190\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4145 - acc: 0.2193 0s - loss: 0.4150 - acc: 0.21\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4106 - acc: 0.2205\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4088 - acc: 0.2214\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4099 - acc: 0.2208\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4073 - acc: 0.2217\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4065 - acc: 0.2220 0s - loss: 0.4013 - ac\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4072 - acc: 0.2217\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4028 - acc: 0.2233\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4025 - acc: 0.2233\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4038 - acc: 0.2229\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4022 - acc: 0.2235 0s - loss: 0.4024 - a\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4005 - acc: 0.2237\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3995 - acc: 0.2241 1s - loss:\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3987 - acc: 0.2244\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3970 - acc: 0.2250\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3976 - acc: 0.2246\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3949 - acc: 0.2257\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3934 - acc: 0.2263\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3916 - acc: 0.2267\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3926 - acc: 0.2263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1300\n",
      "           1       0.56      0.66      0.61     21610\n",
      "           2       0.28      0.04      0.08      4024\n",
      "           3       0.66      0.80      0.72     33912\n",
      "           4       0.56      0.11      0.18       657\n",
      "           5       0.43      0.51      0.46     21097\n",
      "           6       0.35      0.04      0.07      9233\n",
      "           7       0.38      0.34      0.36     11815\n",
      "\n",
      "    accuracy                           0.55    103648\n",
      "   macro avg       0.40      0.31      0.31    103648\n",
      "weighted avg       0.51      0.55      0.51    103648\n",
      "\n",
      "Acur√°cia\n",
      "0.3123431593426311\n",
      "Precisao\n",
      "0.5098420189472355\n",
      "Recall\n",
      "0.5466193269527632\n",
      "F1\n",
      "0.5092868184668783\n",
      "[[    0   371     6   243     1   528    23   128]\n",
      " [    0 14328    30  3168     1  3215    83   785]\n",
      " [    0   634   174  1336     2  1213    40   625]\n",
      " [    0  2848   112 26990    40  2539    61  1322]\n",
      " [    0    81     1   429    72    45     1    28]\n",
      " [    0  4173   108  3764     6 10721   286  2039]\n",
      " [    0  1559    60  1722     2  3898   375  1617]\n",
      " [    0  1514   120  3085     5  2887   208  3996]]\n",
      "TRAIN: [   0    2    3 ... 1997 1998 1999] TEST: [   1   10   11   16   19   27   35   39   44   49   51   64   66   67\n",
      "   69   70   73   76   79   81   96   97  101  104  105  107  121  126\n",
      "  137  145  154  158  159  166  172  173  175  179  182  186  194  210\n",
      "  211  225  236  239  254  256  257  260  271  273  276  284  288  295\n",
      "  299  300  306  310  318  324  326  327  330  331  332  335  340  341\n",
      "  342  343  353  356  363  366  369  372  373  376  382  391  393  410\n",
      "  415  421  423  424  448  460  462  467  472  478  482  487  492  494\n",
      "  499  500  502  505  511  514  520  523  528  529  532  541  542  550\n",
      "  553  554  557  568  570  576  580  585  587  592  595  600  601  631\n",
      "  635  637  639  641  642  650  656  662  671  683  685  687  692  699\n",
      "  701  705  707  712  714  717  729  751  757  758  760  761  770  773\n",
      "  777  785  786  797  799  815  819  820  821  822  826  831  837  838\n",
      "  844  847  848  852  854  855  856  858  861  869  873  879  880  881\n",
      "  897  906  917  918  920  923  927  929  934  936  938  947  952  953\n",
      "  957  961  962  969  970  974  980  982  993 1001 1005 1006 1014 1015\n",
      " 1016 1018 1022 1026 1027 1032 1034 1039 1041 1066 1073 1085 1086 1094\n",
      " 1095 1103 1105 1115 1118 1124 1128 1136 1140 1142 1151 1152 1156 1168\n",
      " 1174 1177 1193 1207 1210 1212 1214 1218 1219 1224 1232 1238 1239 1242\n",
      " 1248 1251 1253 1255 1256 1280 1282 1283 1291 1295 1300 1306 1309 1312\n",
      " 1316 1318 1319 1325 1329 1332 1335 1341 1361 1367 1371 1378 1382 1388\n",
      " 1389 1394 1397 1400 1407 1423 1425 1428 1458 1459 1463 1473 1478 1484\n",
      " 1485 1486 1487 1492 1497 1498 1501 1503 1505 1506 1509 1511 1516 1517\n",
      " 1531 1532 1538 1539 1542 1543 1545 1548 1553 1562 1580 1584 1585 1587\n",
      " 1597 1610 1612 1619 1623 1628 1629 1630 1632 1638 1640 1644 1650 1660\n",
      " 1666 1676 1700 1702 1703 1704 1705 1707 1720 1721 1727 1728 1745 1749\n",
      " 1751 1760 1764 1772 1779 1788 1791 1793 1799 1805 1806 1808 1814 1815\n",
      " 1816 1818 1820 1822 1823 1824 1826 1831 1833 1839 1853 1868 1875 1878\n",
      " 1880 1882 1884 1887 1890 1892 1897 1898 1899 1902 1911 1912 1917 1920\n",
      " 1929 1945 1967 1977 1979 1983 1991 1996]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.6425 - acc: 0.1336\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5933 - acc: 0.1458\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5643 - acc: 0.1611\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5438 - acc: 0.1696\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5343 - acc: 0.1733\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5253 - acc: 0.1774\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5212 - acc: 0.1793\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5173 - acc: 0.1810\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5163 - acc: 0.1813\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5119 - acc: 0.1835 1s - loss: \n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5087 - acc: 0.1851\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5061 - acc: 0.1860\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5049 - acc: 0.1866\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5035 - acc: 0.1870\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5008 - acc: 0.1883\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4985 - acc: 0.1894\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4994 - acc: 0.1886\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4948 - acc: 0.1910\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4959 - acc: 0.1902\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4928 - acc: 0.1918\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4940 - acc: 0.1912 1s - l\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4914 - acc: 0.1923 1s - loss\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4897 - acc: 0.1931\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4892 - acc: 0.1932 0s - loss: 0.4910 - acc: \n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4878 - acc: 0.1938\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4857 - acc: 0.1946\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4864 - acc: 0.1944 1s - loss\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4860 - acc: 0.1944\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4832 - acc: 0.1957\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4825 - acc: 0.1957\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4804 - acc: 0.1967\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4823 - acc: 0.1961 2s - loss: 0.5010 - ac -\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4798 - acc: 0.1968\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4782 - acc: 0.1976\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4779 - acc: 0.1977\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4761 - acc: 0.1984\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4734 - acc: 0.1995\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4713 - acc: 0.2002\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4691 - acc: 0.2012\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4684 - acc: 0.2018\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4677 - acc: 0.2021\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4652 - acc: 0.2025\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4647 - acc: 0.2029\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4647 - acc: 0.2028\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4599 - acc: 0.2047\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4585 - acc: 0.2053\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4581 - acc: 0.2053\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4582 - acc: 0.2056\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4562 - acc: 0.2063\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4534 - acc: 0.2072 0s - loss: 0.4543 - acc: 0.207\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4518 - acc: 0.2081\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4512 - acc: 0.2082\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4487 - acc: 0.2091 1s - loss: 0.4\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4468 - acc: 0.2097 1s\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4447 - acc: 0.2105\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4451 - acc: 0.2100\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4432 - acc: 0.2108\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4418 - acc: 0.2115 0s - loss: 0.4429 - ac\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4488 - acc: 0.2086\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4413 - acc: 0.2115\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4388 - acc: 0.2127\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4361 - acc: 0.2135\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4355 - acc: 0.2139\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4347 - acc: 0.2141\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4329 - acc: 0.2146\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4319 - acc: 0.2149\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4309 - acc: 0.2152\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4328 - acc: 0.2148 1s - loss:\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4287 - acc: 0.2160\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4250 - acc: 0.2176\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4248 - acc: 0.2172\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4226 - acc: 0.2182\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4212 - acc: 0.2187\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4219 - acc: 0.2184\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4222 - acc: 0.2181\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4185 - acc: 0.2196\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4167 - acc: 0.2202 2s - loss: 0.4109 - - ETA: 1s \n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4187 - acc: 0.2194\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4174 - acc: 0.2199 1s - \n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4139 - acc: 0.2209\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4121 - acc: 0.2217 1s - loss: 0.4151 - acc: 0 - ETA: 0s - loss: 0.4144 -\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4111 - acc: 0.2219 1s - loss:\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4118 - acc: 0.2219\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4091 - acc: 0.2227\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4084 - acc: 0.2228\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4092 - acc: 0.2228\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4076 - acc: 0.2230\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4059 - acc: 0.2237\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4084 - acc: 0.2229 0s - loss: 0.4084 - acc\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4034 - acc: 0.2245\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4006 - acc: 0.2255\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3993 - acc: 0.2259\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3995 - acc: 0.2257\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3974 - acc: 0.2263\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4011 - acc: 0.2252\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4020 - acc: 0.2248\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3979 - acc: 0.2262 1s - loss: 0.\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3942 - acc: 0.2277 1s - loss: 0\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3946 - acc: 0.2275\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3941 - acc: 0.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1200\n",
      "           1       0.56      0.67      0.61     22127\n",
      "           2       0.27      0.05      0.08      4054\n",
      "           3       0.67      0.78      0.72     32434\n",
      "           4       0.49      0.07      0.12       606\n",
      "           5       0.41      0.51      0.45     20559\n",
      "           6       0.33      0.02      0.04      8937\n",
      "           7       0.37      0.33      0.35     11623\n",
      "\n",
      "    accuracy                           0.54    101540\n",
      "   macro avg       0.39      0.30      0.30    101540\n",
      "weighted avg       0.51      0.54      0.50    101540\n",
      "\n",
      "Acur√°cia\n",
      "0.3045964889150821\n",
      "Precisao\n",
      "0.5054265457860351\n",
      "Recall\n",
      "0.5420425448099271\n",
      "F1\n",
      "0.5045645376336734\n",
      "[[    0   374    18   189     0   519     8    92]\n",
      " [    0 14934    53  2848     6  3345    56   885]\n",
      " [    0   676   202  1241     2  1204    29   700]\n",
      " [    0  2725   146 25404    22  2684    48  1405]\n",
      " [    0    78     5   356    42    84     2    39]\n",
      " [    0  4440   111  3459     6 10420   159  1964]\n",
      " [    0  1585    70  1522     5  3992   205  1558]\n",
      " [    0  1751   135  2672     3  3109   121  3832]]\n",
      "TRAIN: [   1    2    3 ... 1997 1998 1999] TEST: [   0    6   17   24   29   33   38   46   53   54   61   75   78   83\n",
      "   87   92   99  109  110  112  113  114  115  116  130  131  132  135\n",
      "  138  141  142  149  150  151  152  155  160  168  170  183  189  192\n",
      "  193  196  200  202  203  213  215  221  222  227  231  237  243  244\n",
      "  245  252  253  258  261  277  286  287  297  301  315  321  322  344\n",
      "  345  347  351  352  357  361  381  388  397  404  406  411  417  419\n",
      "  420  426  432  435  445  447  449  454  458  459  461  464  473  484\n",
      "  485  486  491  506  510  517  522  527  533  534  536  543  545  549\n",
      "  551  552  555  556  559  560  565  566  569  571  574  579  583  596\n",
      "  597  598  609  610  625  626  634  640  643  644  653  657  659  666\n",
      "  672  675  691  695  700  704  715  724  730  733  739  740  750  753\n",
      "  754  769  771  780  787  792  800  803  805  808  810  813  817  824\n",
      "  830  842  843  845  846  849  862  863  865  870  877  883  884  886\n",
      "  887  899  904  908  910  915  922  926  949  965  966  971  977  981\n",
      "  984  992  994  996  997 1004 1010 1029 1033 1058 1072 1074 1076 1077\n",
      " 1078 1084 1087 1089 1101 1113 1121 1125 1126 1131 1132 1133 1141 1146\n",
      " 1147 1155 1162 1166 1170 1175 1179 1182 1186 1187 1196 1200 1202 1205\n",
      " 1208 1215 1217 1221 1226 1235 1245 1257 1258 1259 1261 1266 1270 1271\n",
      " 1272 1279 1284 1286 1290 1293 1301 1303 1307 1310 1322 1323 1327 1328\n",
      " 1340 1345 1346 1356 1359 1373 1376 1379 1395 1396 1398 1405 1406 1409\n",
      " 1413 1414 1420 1424 1426 1430 1434 1435 1442 1445 1448 1450 1451 1454\n",
      " 1455 1475 1476 1477 1488 1489 1491 1493 1494 1499 1507 1513 1519 1547\n",
      " 1549 1551 1557 1561 1563 1564 1565 1568 1573 1582 1583 1589 1593 1613\n",
      " 1615 1617 1618 1627 1634 1635 1636 1637 1641 1643 1652 1654 1661 1664\n",
      " 1669 1670 1675 1680 1689 1697 1708 1711 1716 1718 1732 1738 1743 1759\n",
      " 1763 1767 1770 1775 1783 1787 1797 1798 1800 1803 1809 1813 1821 1834\n",
      " 1835 1838 1840 1842 1861 1864 1865 1871 1876 1888 1891 1896 1900 1903\n",
      " 1908 1909 1916 1919 1924 1930 1938 1944 1946 1950 1959 1960 1962 1965\n",
      " 1969 1970 1974 1976 1980 1989 1990 1992]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.6351 - acc: 0.1320\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5892 - acc: 0.1446\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5594 - acc: 0.1598\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5382 - acc: 0.1685 2s  - ETA: 0s - loss: 0.5480 - acc\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5279 - acc: 0.1726\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5238 - acc: 0.1744\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5174 - acc: 0.1779\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5144 - acc: 0.1788\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.5099 - acc: 0.179 - 3s 2ms/sample - loss: 0.5113 - acc: 0.1801\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5069 - acc: 0.1825\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5053 - acc: 0.1829\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5069 - acc: 0.1822\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5039 - acc: 0.1833 1s - loss: 0\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5000 - acc: 0.1851\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.5003 - acc: 0.1847\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4971 - acc: 0.1867\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4959 - acc: 0.1869 0s - loss: 0.49\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4956 - acc: 0.1869\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4941 - acc: 0.1877 0s - loss: 0.4885 -  - ETA: 0s - loss: 0.4921 - acc: 0.\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4909 - acc: 0.1889\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4907 - acc: 0.1889\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4892 - acc: 0.1898\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4904 - acc: 0.1892\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4872 - acc: 0.1906\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4882 - acc: 0.1901\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4893 - acc: 0.1895\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4864 - acc: 0.1907\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4843 - acc: 0.1916 0s - loss: 0.4869 - acc: 0.\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4817 - acc: 0.1928\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4815 - acc: 0.1927\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4794 - acc: 0.1939\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4785 - acc: 0.1940\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4796 - acc: 0.1935\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4758 - acc: 0.1952\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4742 - acc: 0.1957 0s - loss: 0.4738 - a\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4732 - acc: 0.1962\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4729 - acc: 0.1962 2s - loss: 0.4697 - ac - ETA: 1\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4706 - acc: 0.1975\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4700 - acc: 0.1976\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4680 - acc: 0.1986\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4667 - acc: 0.1989\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4648 - acc: 0.1997 1s - loss: 0.\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4655 - acc: 0.1992\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4615 - acc: 0.2011\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4593 - acc: 0.2018\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4576 - acc: 0.2025\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4569 - acc: 0.2027\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4547 - acc: 0.2036\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4522 - acc: 0.2046\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4525 - acc: 0.2046\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4491 - acc: 0.2058\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4477 - acc: 0.2061\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4477 - acc: 0.2062\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4482 - acc: 0.2059\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4453 - acc: 0.2070\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4446 - acc: 0.2073\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4423 - acc: 0.2085\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4400 - acc: 0.2091\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4382 - acc: 0.2098 1s - - ETA: 0s - loss: 0.4382 - acc: 0.\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4365 - acc: 0.2101\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4357 - acc: 0.2103\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4346 - acc: 0.2109\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4364 - acc: 0.2102\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4384 - acc: 0.2091\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4342 - acc: 0.2108 0s - loss: 0.432\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4317 - acc: 0.2119 0s - loss: 0.4282 - acc: 0.2\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4309 - acc: 0.2121\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4280 - acc: 0.2130\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4294 - acc: 0.2127\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4255 - acc: 0.2139\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4232 - acc: 0.2148\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4222 - acc: 0.2152 2s - loss: - ETA: 0s - loss: 0.423\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4223 - acc: 0.2152\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4207 - acc: 0.2156\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4207 - acc: 0.2156\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4222 - acc: 0.2151\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4180 - acc: 0.2165\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4152 - acc: 0.2174\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4141 - acc: 0.2177\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4128 - acc: 0.2182\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4238 - acc: 0.2145 1s - loss: 0\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4143 - acc: 0.2179\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4105 - acc: 0.2190 2s - loss: 0.4189 - acc:\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4076 - acc: 0.2201\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4070 - acc: 0.2202 2s - loss: 0.4026  - ETA: 1s - loss:\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4093 - acc: 0.2192\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4072 - acc: 0.2203 1s - \n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4062 - acc: 0.2201\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.4037 - acc: 0.220 - 3s 2ms/sample - loss: 0.4047 - acc: 0.2211\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4024 - acc: 0.2218\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4010 - acc: 0.2220\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4008 - acc: 0.2222\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4028 - acc: 0.2214\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.4019 - acc: 0.2218 1s - loss: 0.\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3985 - acc: 0.2228 0s - loss: 0.3981 - a\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.3944 - acc: 0.223 - 3s 2ms/sample - loss: 0.3952 - acc: 0.2239\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3964 - acc: 0.2235\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3961 - acc: 0.2238\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3964 - acc: 0.2238 0s - loss: 0.3981 - acc: 0.\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 3s 2ms/sample - loss: 0.3927 - acc: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1256\n",
      "           1       0.56      0.68      0.61     22027\n",
      "           2       0.28      0.04      0.07      3926\n",
      "           3       0.68      0.78      0.73     35064\n",
      "           4       0.51      0.09      0.16       651\n",
      "           5       0.42      0.51      0.46     21064\n",
      "           6       0.33      0.02      0.04      9234\n",
      "           7       0.37      0.34      0.35     11818\n",
      "\n",
      "    accuracy                           0.55    105040\n",
      "   macro avg       0.39      0.31      0.30    105040\n",
      "weighted avg       0.51      0.55      0.51    105040\n",
      "\n",
      "Acur√°cia\n",
      "0.30872036176473294\n",
      "Precisao\n",
      "0.5124476869663988\n",
      "Recall\n",
      "0.5479150799695354\n",
      "F1\n",
      "0.5108695935634794\n",
      "[[    0   359     7   237     0   522    12   119]\n",
      " [    0 14916    46  3059     1  3105    57   843]\n",
      " [    0   638   167  1250     0  1159    25   687]\n",
      " [    0  2983   126 27360    48  3074    39  1434]\n",
      " [    0   102     2   415    61    39     1    31]\n",
      " [    0  4463    90  3461     4 10839   170  2037]\n",
      " [    0  1606    60  1572     1  4051   222  1722]\n",
      " [    0  1515   105  2941     5  3127   137  3988]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede()\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classes[train_index],\n",
    "                           previsores[test_index], classes[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_13 (Bidirectio (None, 700, 200)          97600     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 99,208\n",
      "Trainable params: 99,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cias total\n",
      "[0.29833499781154815, 0.3046218020882473, 0.3123431593426311, 0.3045964889150821, 0.30872036176473294]\n",
      "0.3057233619844483\n",
      "Precision total\n",
      "[0.5062709990344164, 0.5129995451005724, 0.5098420189472355, 0.5054265457860351, 0.5124476869663988]\n",
      "0.5093973591669316\n",
      "Recalls total\n",
      "[0.540278359451852, 0.5515076719756673, 0.5466193269527632, 0.5420425448099271, 0.5479150799695354]\n",
      "0.5456725966319491\n",
      "F1 total\n",
      "[0.5052519954521884, 0.5104227556798107, 0.5092868184668783, 0.5045645376336734, 0.5108695935634794]\n",
      "0.508079140159206\n"
     ]
    }
   ],
   "source": [
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
