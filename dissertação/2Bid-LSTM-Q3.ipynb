{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 28:31].values\n",
    "classes = np.reshape(classes, (2000, 700, 3))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    #model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 100, verbose = 1, batch_size = 32)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 3))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 3))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 20:18:33.910733 15276 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0819 20:18:33.915692 15276 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0819 20:18:33.917707 15276 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0819 20:18:33.917707 15276 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 1996 1998 1999] TEST: [   3    6   10   11   12   18   19   20   25   28   29   37   46   57\n",
      "   58   59   63   69   74   77   85   97  100  101  102  103  108  117\n",
      "  128  133  136  139  140  144  157  166  175  179  182  187  190  191\n",
      "  192  198  202  210  231  233  234  237  238  248  249  259  263  269\n",
      "  272  274  275  280  296  307  309  318  322  327  329  330  341  351\n",
      "  354  355  362  363  370  372  373  380  382  386  387  395  403  415\n",
      "  419  425  426  428  430  431  437  440  447  461  462  463  464  469\n",
      "  470  482  483  491  494  495  504  513  514  530  531  533  560  565\n",
      "  576  585  596  600  605  606  610  614  619  622  623  629  632  634\n",
      "  641  643  651  652  654  655  659  665  671  685  689  701  706  709\n",
      "  711  713  717  725  728  733  736  740  748  750  760  764  770  774\n",
      "  775  787  791  796  798  800  811  813  815  818  819  822  826  831\n",
      "  835  838  853  871  876  882  891  899  901  910  915  933  944  951\n",
      "  953  955  967  987 1010 1011 1014 1016 1021 1024 1027 1035 1038 1039\n",
      " 1042 1049 1050 1057 1068 1071 1074 1078 1082 1083 1093 1097 1098 1100\n",
      " 1105 1107 1117 1121 1123 1137 1141 1142 1143 1146 1156 1157 1158 1159\n",
      " 1164 1165 1167 1172 1174 1175 1178 1185 1186 1187 1188 1205 1207 1208\n",
      " 1210 1214 1219 1228 1232 1235 1237 1256 1270 1271 1273 1289 1290 1296\n",
      " 1304 1307 1312 1320 1322 1325 1328 1329 1331 1338 1343 1345 1350 1351\n",
      " 1370 1374 1375 1384 1387 1388 1389 1392 1393 1396 1398 1400 1402 1408\n",
      " 1411 1412 1415 1416 1435 1437 1442 1454 1455 1460 1464 1465 1479 1485\n",
      " 1492 1501 1502 1503 1505 1506 1529 1531 1540 1541 1555 1559 1577 1579\n",
      " 1581 1583 1585 1587 1591 1597 1601 1605 1610 1612 1613 1617 1622 1630\n",
      " 1657 1660 1662 1663 1667 1668 1670 1672 1687 1691 1692 1697 1702 1712\n",
      " 1715 1716 1720 1727 1730 1734 1745 1748 1754 1761 1763 1764 1769 1773\n",
      " 1776 1780 1782 1784 1785 1786 1790 1794 1800 1801 1803 1809 1816 1819\n",
      " 1821 1827 1838 1848 1849 1851 1854 1866 1868 1876 1879 1881 1884 1899\n",
      " 1900 1901 1921 1923 1927 1928 1935 1939 1947 1948 1951 1956 1958 1961\n",
      " 1965 1969 1973 1975 1985 1990 1992 1997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 20:18:34.670674 15276 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 8s 5ms/sample - loss: 0.3566 - acc: 0.7292\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3171 - acc: 0.8499\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3063 - acc: 0.8613\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3023 - acc: 0.8638\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2953 - acc: 0.8674\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2923 - acc: 0.8692\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2893 - acc: 0.8708\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2895 - acc: 0.8706\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2853 - acc: 0.8725\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2844 - acc: 0.8728\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2845 - acc: 0.8731\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2825 - acc: 0.8746\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2785 - acc: 0.8762\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2763 - acc: 0.8777\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2769 - acc: 0.8774\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2725 - acc: 0.8797\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2717 - acc: 0.8800\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2690 - acc: 0.8815\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2670 - acc: 0.8824\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2665 - acc: 0.8832\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2654 - acc: 0.8836\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2657 - acc: 0.8837\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2641 - acc: 0.8841\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2604 - acc: 0.8858\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2575 - acc: 0.8875\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2539 - acc: 0.8898\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2509 - acc: 0.8908\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2519 - acc: 0.8901\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2503 - acc: 0.8908\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2462 - acc: 0.8929\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2430 - acc: 0.8947\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2402 - acc: 0.8961\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2366 - acc: 0.8978\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2358 - acc: 0.8977\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2336 - acc: 0.8991\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2304 - acc: 0.9008\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2275 - acc: 0.9020\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2271 - acc: 0.9025\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2247 - acc: 0.9037\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2211 - acc: 0.9054\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2180 - acc: 0.9065\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2185 - acc: 0.9061\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2170 - acc: 0.9070\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2141 - acc: 0.9079\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2111 - acc: 0.9092\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2084 - acc: 0.9104\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2052 - acc: 0.9121\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2034 - acc: 0.9120\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2018 - acc: 0.9136\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2011 - acc: 0.9137\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2020 - acc: 0.9125\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1994 - acc: 0.9143\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1944 - acc: 0.9163\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1914 - acc: 0.9168\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1909 - acc: 0.9173\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1890 - acc: 0.9178\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1885 - acc: 0.9173\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1860 - acc: 0.9195\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1844 - acc: 0.9197\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1843 - acc: 0.9198\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1825 - acc: 0.9207\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1789 - acc: 0.9231\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1795 - acc: 0.9227\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1779 - acc: 0.9233\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1785 - acc: 0.9230\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1766 - acc: 0.9230\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1718 - acc: 0.9258\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1707 - acc: 0.9253\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1704 - acc: 0.9255\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1689 - acc: 0.9272\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1676 - acc: 0.9269\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1719 - acc: 0.9250\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1664 - acc: 0.9271\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1643 - acc: 0.9278\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1641 - acc: 0.9283\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1647 - acc: 0.9281\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1626 - acc: 0.9294\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1589 - acc: 0.9305\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1576 - acc: 0.9314\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1568 - acc: 0.9321\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1567 - acc: 0.9321\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1557 - acc: 0.9315\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1548 - acc: 0.9328\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1531 - acc: 0.9335\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1516 - acc: 0.9335\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1519 - acc: 0.9332\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1540 - acc: 0.9325\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1513 - acc: 0.9333\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1510 - acc: 0.9348\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1480 - acc: 0.9356\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1479 - acc: 0.9350\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1475 - acc: 0.9350\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1454 - acc: 0.9362\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1445 - acc: 0.9362\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1455 - acc: 0.9356\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1438 - acc: 0.9362\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1421 - acc: 0.9370\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1413 - acc: 0.9379\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1408 - acc: 0.9376\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1390 - acc: 0.9383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69     43008\n",
      "           1       0.64      0.56      0.59     21768\n",
      "           2       0.72      0.72      0.72     40490\n",
      "\n",
      "    accuracy                           0.68    105266\n",
      "   macro avg       0.67      0.66      0.67    105266\n",
      "weighted avg       0.68      0.68      0.68    105266\n",
      "\n",
      "Acur√°cia\n",
      "0.6605568753265784\n",
      "Precisao\n",
      "0.6798332561868559\n",
      "Recall\n",
      "0.6805046263750879\n",
      "F1\n",
      "0.6792289140529946\n",
      "[[30590  4225  8193]\n",
      " [ 6381 12086  3301]\n",
      " [ 8980  2552 28958]]\n",
      "TRAIN: [   1    2    3 ... 1997 1998 1999] TEST: [   0   15   21   23   26   27   34   44   45   47   48   50   53   68\n",
      "   78   79   81   82   86  106  107  109  110  111  118  120  129  137\n",
      "  143  148  151  154  158  160  162  165  168  170  171  181  188  189\n",
      "  200  212  213  222  223  224  226  227  228  236  241  242  243  246\n",
      "  253  262  264  266  267  270  279  308  313  319  324  325  331  336\n",
      "  337  340  342  344  348  360  361  367  368  375  378  379  383  391\n",
      "  392  393  394  396  398  399  406  408  411  414  421  429  435  445\n",
      "  449  451  454  456  459  460  467  477  479  486  489  492  502  509\n",
      "  510  512  520  524  527  529  537  541  543  546  554  559  562  571\n",
      "  573  575  578  582  584  592  595  597  611  616  618  633  635  646\n",
      "  658  661  668  670  674  676  695  697  700  702  705  707  710  712\n",
      "  714  715  730  741  746  752  753  755  766  773  777  780  788  793\n",
      "  797  799  803  810  820  823  825  837  839  850  851  856  862  867\n",
      "  868  880  884  886  889  897  898  900  902  903  904  909  914  916\n",
      "  920  923  935  939  940  941  943  956  957  958  975  981  988  992\n",
      "  993 1001 1005 1006 1007 1018 1023 1026 1036 1044 1045 1046 1048 1056\n",
      " 1059 1061 1070 1075 1077 1085 1087 1088 1089 1090 1092 1095 1099 1104\n",
      " 1114 1115 1120 1129 1134 1136 1144 1148 1160 1168 1173 1177 1179 1180\n",
      " 1184 1204 1211 1212 1218 1223 1226 1229 1233 1239 1244 1249 1258 1269\n",
      " 1276 1277 1279 1280 1281 1293 1297 1299 1300 1301 1303 1306 1311 1314\n",
      " 1318 1319 1330 1333 1335 1341 1349 1361 1368 1373 1378 1382 1383 1397\n",
      " 1399 1409 1413 1422 1431 1446 1447 1458 1463 1470 1483 1486 1499 1504\n",
      " 1507 1514 1517 1518 1520 1526 1528 1530 1542 1548 1566 1569 1572 1574\n",
      " 1588 1589 1598 1611 1614 1619 1621 1629 1633 1642 1646 1647 1649 1652\n",
      " 1654 1656 1659 1674 1676 1677 1679 1680 1681 1684 1690 1693 1700 1701\n",
      " 1705 1707 1722 1723 1724 1737 1741 1744 1749 1750 1757 1762 1766 1771\n",
      " 1775 1808 1822 1826 1830 1833 1839 1852 1855 1858 1863 1869 1870 1878\n",
      " 1885 1887 1890 1891 1892 1895 1904 1906 1913 1914 1915 1920 1938 1940\n",
      " 1941 1944 1946 1949 1960 1984 1991 1993]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3590 - acc: 0.7949\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3199 - acc: 0.8524\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3100 - acc: 0.8602\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3032 - acc: 0.8642\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2991 - acc: 0.8668\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2980 - acc: 0.8668\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2925 - acc: 0.8701\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2907 - acc: 0.8712\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2879 - acc: 0.8723\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2861 - acc: 0.8724\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2862 - acc: 0.8732\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2833 - acc: 0.8746\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2817 - acc: 0.8753\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2799 - acc: 0.8756\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2781 - acc: 0.8771\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2766 - acc: 0.8774\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2755 - acc: 0.8774\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2759 - acc: 0.8780\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2720 - acc: 0.8796\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2715 - acc: 0.8799\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2693 - acc: 0.8810\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2666 - acc: 0.8824\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2680 - acc: 0.8813\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2657 - acc: 0.8823\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2664 - acc: 0.8825\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2726 - acc: 0.8801\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2649 - acc: 0.8841\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2591 - acc: 0.8872\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2571 - acc: 0.8878\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2544 - acc: 0.8895\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2519 - acc: 0.8899\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2505 - acc: 0.8906\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2517 - acc: 0.8903\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2476 - acc: 0.8927\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2438 - acc: 0.8944\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2408 - acc: 0.8959\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2384 - acc: 0.8967\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2357 - acc: 0.8979\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2337 - acc: 0.8990\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2330 - acc: 0.8990\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2359 - acc: 0.8976\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2295 - acc: 0.9003\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2274 - acc: 0.9017\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2244 - acc: 0.9032\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2225 - acc: 0.9038\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2192 - acc: 0.9052\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2171 - acc: 0.9064\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2156 - acc: 0.9069\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2149 - acc: 0.9071\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2156 - acc: 0.9071\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2102 - acc: 0.9091\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2072 - acc: 0.9110\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2050 - acc: 0.9117\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2023 - acc: 0.9122\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2011 - acc: 0.9123\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2268 - acc: 0.9014\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2153 - acc: 0.9063\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2089 - acc: 0.9091\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1998 - acc: 0.9124\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1959 - acc: 0.9146\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1938 - acc: 0.9151\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1916 - acc: 0.9163\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1912 - acc: 0.9160\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1883 - acc: 0.9176\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1868 - acc: 0.9174\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1850 - acc: 0.9185\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1841 - acc: 0.9191\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1839 - acc: 0.9184\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1817 - acc: 0.9195\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1797 - acc: 0.9208\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1787 - acc: 0.9206\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1783 - acc: 0.9210\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1769 - acc: 0.9213\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1766 - acc: 0.9217\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1743 - acc: 0.9223\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1723 - acc: 0.9237\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1784 - acc: 0.9210\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1781 - acc: 0.9211\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1715 - acc: 0.9229\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1683 - acc: 0.9249\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1664 - acc: 0.9255\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1649 - acc: 0.9265\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1712 - acc: 0.9241\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1690 - acc: 0.9259\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1634 - acc: 0.9271\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1607 - acc: 0.9275\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1602 - acc: 0.9289\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1593 - acc: 0.9288\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1771 - acc: 0.9216\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1612 - acc: 0.9280\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1562 - acc: 0.9301\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1545 - acc: 0.9309\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1544 - acc: 0.9306\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.1531 - acc: 0.9329\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1517 - acc: 0.9324\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1519 - acc: 0.9319\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1516 - acc: 0.9316\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1513 - acc: 0.9319\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1546 - acc: 0.9316\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1497 - acc: 0.9328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70     42600\n",
      "           1       0.68      0.57      0.62     24423\n",
      "           2       0.72      0.70      0.71     36214\n",
      "\n",
      "    accuracy                           0.69    103237\n",
      "   macro avg       0.69      0.67      0.68    103237\n",
      "weighted avg       0.69      0.69      0.68    103237\n",
      "\n",
      "Acur√°cia\n",
      "0.6692014567351116\n",
      "Precisao\n",
      "0.6866890465517655\n",
      "Recall\n",
      "0.6854131755087808\n",
      "F1\n",
      "0.6838828951316156\n",
      "[[31541  4313  6746]\n",
      " [ 7602 13819  3002]\n",
      " [ 8555  2259 25400]]\n",
      "TRAIN: [   0    3    4 ... 1997 1998 1999] TEST: [   1    2   16   31   32   38   39   42   43   51   60   65   75   87\n",
      "   92   93   99  114  119  121  124  126  132  134  142  145  153  161\n",
      "  163  164  172  173  174  178  184  186  194  197  205  207  216  218\n",
      "  220  221  225  232  235  245  250  251  252  255  257  258  260  276\n",
      "  281  282  286  288  292  294  295  297  299  304  305  310  312  323\n",
      "  326  338  343  349  350  366  374  381  390  410  413  417  418  423\n",
      "  424  427  441  442  444  448  450  452  466  472  476  487  497  498\n",
      "  499  511  516  518  521  532  536  539  542  544  547  550  561  563\n",
      "  580  587  590  591  594  599  601  603  607  615  621  627  630  642\n",
      "  644  647  649  650  657  662  663  667  672  675  677  678  680  682\n",
      "  683  684  686  687  688  696  698  699  704  716  727  729  731  739\n",
      "  745  754  758  759  761  767  772  776  778  790  792  804  805  814\n",
      "  821  824  832  840  841  842  845  857  860  863  864  865  869  870\n",
      "  874  885  887  907  912  921  924  929  931  932  942  945  946  950\n",
      "  952  969  971  973  977  979  980  983  989 1015 1032 1033 1040 1054\n",
      " 1055 1064 1065 1072 1073 1091 1096 1101 1110 1124 1126 1127 1131 1132\n",
      " 1138 1139 1147 1149 1153 1171 1176 1181 1182 1190 1198 1201 1216 1222\n",
      " 1225 1230 1231 1240 1242 1250 1253 1257 1260 1268 1283 1285 1286 1292\n",
      " 1294 1309 1310 1323 1336 1353 1355 1357 1369 1376 1379 1386 1394 1401\n",
      " 1407 1419 1421 1423 1424 1428 1429 1432 1434 1438 1441 1444 1451 1452\n",
      " 1456 1466 1467 1472 1473 1474 1475 1477 1482 1489 1494 1495 1496 1500\n",
      " 1509 1513 1521 1524 1525 1534 1537 1538 1543 1549 1553 1557 1560 1561\n",
      " 1565 1567 1570 1573 1586 1590 1593 1607 1609 1615 1620 1625 1626 1634\n",
      " 1639 1641 1644 1645 1651 1655 1673 1675 1682 1685 1686 1695 1696 1708\n",
      " 1711 1714 1717 1726 1735 1739 1740 1742 1743 1756 1759 1760 1770 1772\n",
      " 1777 1791 1792 1795 1799 1802 1805 1811 1813 1814 1825 1828 1832 1842\n",
      " 1843 1844 1845 1846 1856 1857 1861 1864 1871 1874 1875 1889 1902 1909\n",
      " 1918 1922 1926 1929 1930 1933 1937 1943 1950 1952 1957 1962 1963 1967\n",
      " 1968 1970 1971 1977 1978 1982 1994 1996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3613 - acc: 0.8094\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3224 - acc: 0.8521\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3076 - acc: 0.8609\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3044 - acc: 0.8635\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2997 - acc: 0.8665\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2950 - acc: 0.8690\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2915 - acc: 0.8708\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2911 - acc: 0.8712\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2886 - acc: 0.8720\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2857 - acc: 0.8738\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2831 - acc: 0.8747\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2822 - acc: 0.8748\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2823 - acc: 0.8747\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2800 - acc: 0.8754\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2780 - acc: 0.8766\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2790 - acc: 0.8767\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2763 - acc: 0.8788\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2738 - acc: 0.8790\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2809 - acc: 0.8761\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2773 - acc: 0.8771\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2706 - acc: 0.8807\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2680 - acc: 0.8809\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2703 - acc: 0.8817\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2644 - acc: 0.8838\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2604 - acc: 0.8859\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2587 - acc: 0.8871\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2580 - acc: 0.8875\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2576 - acc: 0.8879\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2534 - acc: 0.8892\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2513 - acc: 0.8905\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2515 - acc: 0.8898\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2480 - acc: 0.8917\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2455 - acc: 0.8924\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2428 - acc: 0.8942\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2417 - acc: 0.8944\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2397 - acc: 0.8958\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2356 - acc: 0.8976\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2355 - acc: 0.8973\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2345 - acc: 0.8978\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2301 - acc: 0.8999\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2272 - acc: 0.9002\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2240 - acc: 0.9026\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2224 - acc: 0.9022\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2207 - acc: 0.9032\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2277 - acc: 0.8999\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2258 - acc: 0.8998\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2158 - acc: 0.9042\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2115 - acc: 0.9070\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2112 - acc: 0.9060\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2097 - acc: 0.9093\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2114 - acc: 0.9070\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2085 - acc: 0.9078\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2074 - acc: 0.9107\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2073 - acc: 0.9087\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2011 - acc: 0.9130\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1997 - acc: 0.9140\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1956 - acc: 0.9155\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1948 - acc: 0.9163\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1942 - acc: 0.9166\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1914 - acc: 0.9182\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1903 - acc: 0.9180\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1899 - acc: 0.9172\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1872 - acc: 0.9199\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1856 - acc: 0.9206\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1837 - acc: 0.9213\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1812 - acc: 0.9223\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1810 - acc: 0.9227\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1781 - acc: 0.9240\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1792 - acc: 0.9233\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1779 - acc: 0.9235\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1771 - acc: 0.9244\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1774 - acc: 0.9236\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1801 - acc: 0.9231\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1752 - acc: 0.9254\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1705 - acc: 0.9274\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1679 - acc: 0.9283\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1683 - acc: 0.9283\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1681 - acc: 0.9284\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1652 - acc: 0.9298\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1637 - acc: 0.9304\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1630 - acc: 0.9307\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1622 - acc: 0.9309\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1613 - acc: 0.9312\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1618 - acc: 0.9312\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1618 - acc: 0.9309\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1692 - acc: 0.9278\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1616 - acc: 0.9312\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1600 - acc: 0.9320\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1562 - acc: 0.9336\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1549 - acc: 0.9344\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1537 - acc: 0.9351\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1521 - acc: 0.9357\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1526 - acc: 0.9350\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1506 - acc: 0.9361\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1486 - acc: 0.9368\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1497 - acc: 0.9365\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1482 - acc: 0.9373\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1465 - acc: 0.9380\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1463 - acc: 0.9379\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1461 - acc: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68     41722\n",
      "           1       0.66      0.54      0.59     22777\n",
      "           2       0.70      0.72      0.71     37385\n",
      "\n",
      "    accuracy                           0.67    101884\n",
      "   macro avg       0.67      0.66      0.66    101884\n",
      "weighted avg       0.67      0.67      0.67    101884\n",
      "\n",
      "Acur√°cia\n",
      "0.6556765832170971\n",
      "Precisao\n",
      "0.6742711569895773\n",
      "Recall\n",
      "0.6746496015075969\n",
      "F1\n",
      "0.6726982394613646\n",
      "[[29563  4132  8027]\n",
      " [ 7077 12278  3422]\n",
      " [ 8268  2222 26895]]\n",
      "TRAIN: [   0    1    2 ... 1996 1997 1999] TEST: [   8    9   13   14   36   40   41   49   52   62   64   66   70   80\n",
      "   84   88   89   90   95   98  104  105  115  116  138  146  147  149\n",
      "  155  169  176  177  183  193  201  203  208  209  211  217  219  230\n",
      "  239  240  247  256  265  268  278  285  289  290  293  298  300  301\n",
      "  302  303  306  316  320  328  332  335  352  356  358  364  365  385\n",
      "  388  402  405  407  409  412  416  420  422  432  433  434  436  439\n",
      "  453  458  468  480  484  485  488  490  493  505  508  517  519  522\n",
      "  523  525  526  534  538  545  548  551  552  557  566  568  569  570\n",
      "  572  574  577  579  581  583  589  593  613  617  624  625  626  631\n",
      "  636  637  639  640  648  664  666  669  673  679  690  691  692  693\n",
      "  703  720  721  723  724  732  734  737  738  747  749  751  762  763\n",
      "  769  781  785  801  807  808  812  827  828  836  843  844  848  849\n",
      "  852  855  858  866  872  875  877  881  883  888  892  895  906  908\n",
      "  917  918  922  925  926  936  937  938  947  948  949  954  959  961\n",
      "  963  964  966  968  984  985  990  997  998  999 1000 1004 1008 1012\n",
      " 1013 1020 1022 1025 1053 1060 1062 1066 1067 1076 1079 1080 1081 1084\n",
      " 1086 1106 1112 1113 1119 1125 1130 1135 1145 1152 1161 1163 1170 1195\n",
      " 1199 1203 1213 1220 1224 1227 1236 1243 1246 1247 1248 1252 1254 1262\n",
      " 1265 1275 1278 1282 1287 1291 1308 1313 1316 1317 1326 1327 1334 1354\n",
      " 1358 1359 1360 1364 1365 1371 1381 1390 1391 1395 1404 1405 1406 1417\n",
      " 1418 1425 1427 1439 1443 1448 1449 1450 1453 1457 1459 1462 1476 1487\n",
      " 1488 1490 1491 1497 1508 1512 1515 1516 1522 1523 1527 1535 1536 1545\n",
      " 1546 1547 1550 1551 1552 1556 1558 1562 1564 1575 1576 1580 1584 1594\n",
      " 1595 1596 1603 1616 1618 1623 1624 1627 1628 1632 1635 1636 1637 1638\n",
      " 1643 1650 1658 1661 1665 1671 1683 1689 1703 1706 1709 1718 1719 1721\n",
      " 1728 1731 1738 1746 1774 1778 1783 1787 1788 1798 1804 1807 1810 1812\n",
      " 1817 1818 1820 1823 1829 1831 1837 1847 1850 1853 1860 1862 1865 1867\n",
      " 1872 1873 1877 1896 1903 1911 1916 1917 1936 1942 1945 1953 1955 1966\n",
      " 1972 1974 1979 1980 1981 1986 1995 1998]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3579 - acc: 0.8114\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3197 - acc: 0.8537\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3070 - acc: 0.8621\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3026 - acc: 0.8647\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2976 - acc: 0.8679\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2943 - acc: 0.8694\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2920 - acc: 0.8705\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2900 - acc: 0.8717\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2876 - acc: 0.8728\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2852 - acc: 0.8742\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2853 - acc: 0.8733\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2821 - acc: 0.8745\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2808 - acc: 0.8756\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2787 - acc: 0.8762\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2777 - acc: 0.8771\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2787 - acc: 0.8759\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2784 - acc: 0.8764\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2829 - acc: 0.8739\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2759 - acc: 0.8779\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2732 - acc: 0.8794\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2705 - acc: 0.8811\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2699 - acc: 0.8818\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2684 - acc: 0.8822\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2646 - acc: 0.8839\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2620 - acc: 0.8856\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2616 - acc: 0.8857\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2592 - acc: 0.8871\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2600 - acc: 0.8862\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2729 - acc: 0.8779\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2612 - acc: 0.8835\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2577 - acc: 0.8866\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2555 - acc: 0.8885\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2528 - acc: 0.8885\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2489 - acc: 0.8909\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2480 - acc: 0.8919\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2450 - acc: 0.8926\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2429 - acc: 0.8939\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2409 - acc: 0.8949\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2410 - acc: 0.8946\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2408 - acc: 0.8948\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2356 - acc: 0.8972\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2321 - acc: 0.8997\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2296 - acc: 0.9004\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2276 - acc: 0.9009\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2258 - acc: 0.9024\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2236 - acc: 0.9031\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2210 - acc: 0.9044\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2199 - acc: 0.9052\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2176 - acc: 0.9060\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2236 - acc: 0.9039\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2148 - acc: 0.9073\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2127 - acc: 0.9084\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2088 - acc: 0.9107\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2071 - acc: 0.9115\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2083 - acc: 0.9103\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2073 - acc: 0.9112\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2044 - acc: 0.9121\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2026 - acc: 0.9129\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1990 - acc: 0.9144\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1959 - acc: 0.9167\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1950 - acc: 0.9164\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1940 - acc: 0.9167\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1902 - acc: 0.9177\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1924 - acc: 0.9168\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1902 - acc: 0.9183\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1883 - acc: 0.9198\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1853 - acc: 0.9210\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1859 - acc: 0.9204\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1826 - acc: 0.9219\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1807 - acc: 0.9232\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1801 - acc: 0.9229\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1782 - acc: 0.9233\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1768 - acc: 0.9235\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.1737 - acc: 0.9249\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1735 - acc: 0.9247\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1729 - acc: 0.9247\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1717 - acc: 0.9268\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1694 - acc: 0.9279\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1681 - acc: 0.9283\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1662 - acc: 0.9290\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1654 - acc: 0.9287\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1655 - acc: 0.9295\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1640 - acc: 0.9299\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1657 - acc: 0.9286\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1655 - acc: 0.9286\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1631 - acc: 0.9298\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1612 - acc: 0.9315\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1575 - acc: 0.9324\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1569 - acc: 0.9321\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1563 - acc: 0.9314\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1545 - acc: 0.9335\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1536 - acc: 0.9345\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1533 - acc: 0.9353\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1522 - acc: 0.9353\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1511 - acc: 0.9351\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1513 - acc: 0.9354\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1499 - acc: 0.9363\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1487 - acc: 0.9357\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1473 - acc: 0.9364\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1469 - acc: 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69     42897\n",
      "           1       0.67      0.56      0.61     24156\n",
      "           2       0.70      0.73      0.72     37734\n",
      "\n",
      "    accuracy                           0.68    104787\n",
      "   macro avg       0.68      0.67      0.67    104787\n",
      "weighted avg       0.68      0.68      0.68    104787\n",
      "\n",
      "Acur√°cia\n",
      "0.6673096735662384\n",
      "Precisao\n",
      "0.6828845695061632\n",
      "Recall\n",
      "0.6833576684130666\n",
      "F1\n",
      "0.6815736352934462\n",
      "[[30373  4418  8106]\n",
      " [ 6955 13502  3699]\n",
      " [ 7858  2144 27732]]\n",
      "TRAIN: [   0    1    2 ... 1996 1997 1998] TEST: [   4    5    7   17   22   24   30   33   35   54   55   56   61   67\n",
      "   71   72   73   76   83   91   94   96  112  113  122  123  125  127\n",
      "  130  131  135  141  150  152  156  159  167  180  185  195  196  199\n",
      "  204  206  214  215  229  244  254  261  271  273  277  283  284  287\n",
      "  291  311  314  315  317  321  333  334  339  345  346  347  353  357\n",
      "  359  369  371  376  377  384  389  397  400  401  404  438  443  446\n",
      "  455  457  465  471  473  474  475  478  481  496  500  501  503  506\n",
      "  507  515  528  535  540  549  553  555  556  558  564  567  586  588\n",
      "  598  602  604  608  609  612  620  628  638  645  653  656  660  681\n",
      "  694  708  718  719  722  726  735  742  743  744  756  757  765  768\n",
      "  771  779  782  783  784  786  789  794  795  802  806  809  816  817\n",
      "  829  830  833  834  846  847  854  859  861  873  878  879  890  893\n",
      "  894  896  905  911  913  919  927  928  930  934  960  962  965  970\n",
      "  972  974  976  978  982  986  991  994  995  996 1002 1003 1009 1017\n",
      " 1019 1028 1029 1030 1031 1034 1037 1041 1043 1047 1051 1052 1058 1063\n",
      " 1069 1094 1102 1103 1108 1109 1111 1116 1118 1122 1128 1133 1140 1150\n",
      " 1151 1154 1155 1162 1166 1169 1183 1189 1191 1192 1193 1194 1196 1197\n",
      " 1200 1202 1206 1209 1215 1217 1221 1234 1238 1241 1245 1251 1255 1259\n",
      " 1261 1263 1264 1266 1267 1272 1274 1284 1288 1295 1298 1302 1305 1315\n",
      " 1321 1324 1332 1337 1339 1340 1342 1344 1346 1347 1348 1352 1356 1362\n",
      " 1363 1366 1367 1372 1377 1380 1385 1403 1410 1414 1420 1426 1430 1433\n",
      " 1436 1440 1445 1461 1468 1469 1471 1478 1480 1481 1484 1493 1498 1510\n",
      " 1511 1519 1532 1533 1539 1544 1554 1563 1568 1571 1578 1582 1592 1599\n",
      " 1600 1602 1604 1606 1608 1631 1640 1648 1653 1664 1666 1669 1678 1688\n",
      " 1694 1698 1699 1704 1710 1713 1725 1729 1732 1733 1736 1747 1751 1752\n",
      " 1753 1755 1758 1765 1767 1768 1779 1781 1789 1793 1796 1797 1806 1815\n",
      " 1824 1834 1835 1836 1840 1841 1859 1880 1882 1883 1886 1888 1893 1894\n",
      " 1897 1898 1905 1907 1908 1910 1912 1919 1924 1925 1931 1932 1934 1954\n",
      " 1959 1964 1976 1983 1987 1988 1989 1999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3605 - acc: 0.8197\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3225 - acc: 0.8515\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3109 - acc: 0.8599\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3052 - acc: 0.8635\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3020 - acc: 0.8655\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2977 - acc: 0.8677\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2934 - acc: 0.8697\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2920 - acc: 0.8704\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2904 - acc: 0.8713\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2921 - acc: 0.8698\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2889 - acc: 0.8717\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2858 - acc: 0.8733\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2847 - acc: 0.8736\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2821 - acc: 0.8751\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2795 - acc: 0.8760\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2788 - acc: 0.8769\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2782 - acc: 0.8777\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2757 - acc: 0.8787\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2753 - acc: 0.8786\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2711 - acc: 0.8805\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2708 - acc: 0.8808\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2692 - acc: 0.8818\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2672 - acc: 0.8829\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2687 - acc: 0.8821\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2640 - acc: 0.8843\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2631 - acc: 0.8853\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2597 - acc: 0.8864\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2579 - acc: 0.8873\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2534 - acc: 0.8896\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2533 - acc: 0.8894\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2473 - acc: 0.8925\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2458 - acc: 0.8936\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2441 - acc: 0.8944\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2424 - acc: 0.8948\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2411 - acc: 0.8957\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2378 - acc: 0.8972\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2345 - acc: 0.8987\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2311 - acc: 0.9007\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2294 - acc: 0.9011\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2280 - acc: 0.9018\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2262 - acc: 0.9026\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2232 - acc: 0.9039\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2224 - acc: 0.9042\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2182 - acc: 0.9058\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2160 - acc: 0.9072\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2140 - acc: 0.9081\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2135 - acc: 0.9083\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2128 - acc: 0.9089\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2142 - acc: 0.9078\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2087 - acc: 0.9103\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2076 - acc: 0.9111\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2044 - acc: 0.9123\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2023 - acc: 0.9134\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2019 - acc: 0.9137\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2002 - acc: 0.9143\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1974 - acc: 0.9155\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1963 - acc: 0.9158\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1964 - acc: 0.9160\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1953 - acc: 0.9164\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1917 - acc: 0.9182\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1886 - acc: 0.9195\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1890 - acc: 0.9195\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1871 - acc: 0.9204\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1854 - acc: 0.9211\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1820 - acc: 0.9224\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1800 - acc: 0.9233\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1798 - acc: 0.9235\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1786 - acc: 0.9241\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1794 - acc: 0.9237\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1774 - acc: 0.9247\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1875 - acc: 0.9201\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1818 - acc: 0.9226\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1750 - acc: 0.9256\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1726 - acc: 0.9266\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1709 - acc: 0.9276\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1695 - acc: 0.9277\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1668 - acc: 0.9291\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1664 - acc: 0.9294\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1660 - acc: 0.9296\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1653 - acc: 0.9301\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1641 - acc: 0.9306\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1633 - acc: 0.9307\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1636 - acc: 0.9307\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1632 - acc: 0.9309\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1634 - acc: 0.9308\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1600 - acc: 0.9324\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1573 - acc: 0.9335\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1558 - acc: 0.9340\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1552 - acc: 0.9344\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1541 - acc: 0.9350\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1531 - acc: 0.9353\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1530 - acc: 0.9352\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1526 - acc: 0.9356\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1512 - acc: 0.9362\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1508 - acc: 0.9364\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1496 - acc: 0.9368\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1496 - acc: 0.9369\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.1488 - acc: 0.9371\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.1464 - acc: 0.9382\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.1460 - acc: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69     41371\n",
      "           1       0.63      0.57      0.60     22072\n",
      "           2       0.73      0.68      0.70     37191\n",
      "\n",
      "    accuracy                           0.68    100634\n",
      "   macro avg       0.67      0.66      0.66    100634\n",
      "weighted avg       0.68      0.68      0.67    100634\n",
      "\n",
      "Acur√°cia\n",
      "0.6592568789945416\n",
      "Precisao\n",
      "0.6769864327075001\n",
      "Recall\n",
      "0.6755669058171194\n",
      "F1\n",
      "0.6748151429419853\n",
      "[[30088  4639  6644]\n",
      " [ 6799 12570  2703]\n",
      " [ 9132  2732 25327]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede()\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classes[train_index],\n",
    "                           previsores[test_index], classes[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_8 (Bidirection (None, 700, 200)          97600     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 700, 200)          241600    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 700, 3)            603       \n",
      "=================================================================\n",
      "Total params: 339,803\n",
      "Trainable params: 339,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cias total\n",
      "[0.6605568753265784, 0.6692014567351116, 0.6556765832170971, 0.6673096735662384, 0.6592568789945416]\n",
      "0.6624002935679134\n",
      "Precision total\n",
      "[0.6798332561868559, 0.6866890465517655, 0.6742711569895773, 0.6828845695061632, 0.6769864327075001]\n",
      "0.6801328923883725\n",
      "Recalls total\n",
      "[0.6805046263750879, 0.6854131755087808, 0.6746496015075969, 0.6833576684130666, 0.6755669058171194]\n",
      "0.6798983955243303\n",
      "F1 total\n",
      "[0.6792289140529946, 0.6838828951316156, 0.6726982394613646, 0.6815736352934462, 0.6748151429419853]\n",
      "0.6784397653762813\n"
     ]
    }
   ],
   "source": [
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
