{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classes = base.iloc[:1400000, 28:31].values\n",
    "classes = np.reshape(classes, (2000, 700, 3))\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM, Bidirectional, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede():\n",
    "    model = Sequential()\n",
    "  \n",
    "    #model.add(Masking(mask_value = 0, input_shape = (700, 20)))\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNLSTM(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train, epochs = 100, verbose = 1, batch_size = 32)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "  \n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], 3))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], 3))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 22:51:08.051712 13068 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0819 22:51:08.057696 13068 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0819 22:51:08.058693 13068 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0819 22:51:08.059689 13068 deprecation.py:506] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 1996 1998 1999] TEST: [  10   12   23   26   29   30   36   37   38   39   41   46   61   68\n",
      "   78   79   82   83   85   90   95   97  104  107  117  119  124  125\n",
      "  131  143  144  155  160  172  174  186  193  201  206  207  220  238\n",
      "  246  254  255  264  268  269  275  283  285  289  297  299  309  316\n",
      "  317  320  331  332  347  349  350  353  354  357  359  360  366  372\n",
      "  376  379  383  389  391  399  401  403  407  413  414  429  430  432\n",
      "  433  442  443  445  446  450  454  457  458  470  475  483  486  495\n",
      "  507  510  512  523  525  528  532  533  537  538  542  545  549  551\n",
      "  561  563  566  568  571  574  578  579  583  585  587  594  601  604\n",
      "  605  608  610  613  615  620  624  625  628  630  632  639  643  657\n",
      "  661  664  665  666  680  681  687  691  699  700  711  713  714  725\n",
      "  726  730  743  751  755  757  760  764  768  773  775  777  781  790\n",
      "  793  796  798  802  807  815  827  832  834  839  844  849  851  852\n",
      "  853  864  867  870  871  873  877  881  885  888  905  916  917  924\n",
      "  928  936  940  945  951  954  958  959  965  973  975 1003 1005 1007\n",
      " 1008 1009 1011 1020 1022 1025 1028 1030 1031 1032 1038 1041 1043 1044\n",
      " 1045 1047 1052 1055 1058 1065 1066 1071 1077 1079 1084 1085 1089 1101\n",
      " 1110 1116 1118 1120 1122 1123 1128 1129 1131 1133 1136 1141 1158 1162\n",
      " 1165 1168 1172 1176 1187 1190 1192 1194 1201 1204 1215 1218 1220 1226\n",
      " 1230 1232 1233 1249 1266 1269 1276 1277 1287 1291 1293 1311 1313 1320\n",
      " 1326 1333 1334 1336 1343 1359 1361 1362 1363 1367 1369 1380 1382 1387\n",
      " 1402 1408 1421 1430 1440 1441 1445 1447 1449 1458 1462 1483 1494 1498\n",
      " 1502 1514 1515 1524 1527 1528 1534 1536 1550 1557 1560 1562 1563 1566\n",
      " 1571 1573 1583 1586 1589 1591 1603 1604 1605 1620 1631 1640 1668 1672\n",
      " 1679 1684 1685 1688 1691 1703 1706 1709 1714 1715 1716 1719 1724 1727\n",
      " 1728 1734 1737 1738 1740 1741 1751 1756 1758 1767 1769 1775 1777 1794\n",
      " 1802 1803 1806 1810 1822 1828 1836 1841 1850 1853 1857 1862 1867 1878\n",
      " 1883 1889 1895 1898 1909 1915 1919 1925 1929 1931 1933 1934 1936 1937\n",
      " 1942 1948 1949 1953 1971 1984 1991 1997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 22:51:09.385150 13068 deprecation.py:323] From c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 13s 8ms/sample - loss: 0.3591 - acc: 0.7556\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3205 - acc: 0.8511\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3067 - acc: 0.8600\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2997 - acc: 0.8639\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2970 - acc: 0.8649\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2930 - acc: 0.8672\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2908 - acc: 0.8676\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2880 - acc: 0.8691\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2864 - acc: 0.8703\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2834 - acc: 0.8708\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2836 - acc: 0.8713\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2790 - acc: 0.8737\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2775 - acc: 0.8745\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2762 - acc: 0.8754\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2734 - acc: 0.8766\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2699 - acc: 0.8788\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2700 - acc: 0.8784\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2642 - acc: 0.8814\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2637 - acc: 0.8821\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2604 - acc: 0.8839\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2574 - acc: 0.8858\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2526 - acc: 0.8879\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2476 - acc: 0.8900\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2461 - acc: 0.8909\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2413 - acc: 0.8936\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2374 - acc: 0.8955\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2322 - acc: 0.8979\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2272 - acc: 0.8999\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2270 - acc: 0.9002\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2212 - acc: 0.9032\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2159 - acc: 0.9034\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2101 - acc: 0.9059\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2074 - acc: 0.9098\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2027 - acc: 0.9108\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2021 - acc: 0.9102\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1956 - acc: 0.9151\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1923 - acc: 0.9162\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1903 - acc: 0.9179\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1859 - acc: 0.9194\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1857 - acc: 0.9200\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1821 - acc: 0.9213\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1791 - acc: 0.9231\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1764 - acc: 0.9242\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1717 - acc: 0.9269\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1695 - acc: 0.9275\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1689 - acc: 0.9280\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1658 - acc: 0.9288\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1624 - acc: 0.9290\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1594 - acc: 0.9318\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1583 - acc: 0.9317\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1555 - acc: 0.9328\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1539 - acc: 0.9336\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1518 - acc: 0.9338\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1507 - acc: 0.9345\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1472 - acc: 0.9351\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1457 - acc: 0.9365\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1449 - acc: 0.9371\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1428 - acc: 0.9379\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1421 - acc: 0.9381\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1399 - acc: 0.9373\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1372 - acc: 0.9400\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1366 - acc: 0.9409\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1354 - acc: 0.9417\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1330 - acc: 0.9428\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1314 - acc: 0.9438\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1314 - acc: 0.9434\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1301 - acc: 0.9441\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1293 - acc: 0.9442\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1268 - acc: 0.9445\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1255 - acc: 0.9459\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1247 - acc: 0.9466\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1233 - acc: 0.9474\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1232 - acc: 0.9485\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1226 - acc: 0.9477\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1217 - acc: 0.9486\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1198 - acc: 0.9496\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1198 - acc: 0.9485\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1173 - acc: 0.9503\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1163 - acc: 0.9506\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1164 - acc: 0.9507\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1158 - acc: 0.9503\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1138 - acc: 0.9515\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1129 - acc: 0.9520\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1128 - acc: 0.9522\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1127 - acc: 0.9527\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1117 - acc: 0.9529\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1109 - acc: 0.9533\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1101 - acc: 0.9522\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1087 - acc: 0.9536\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1087 - acc: 0.9535\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1077 - acc: 0.9530\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1065 - acc: 0.9536\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1058 - acc: 0.9545\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1066 - acc: 0.9547\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1054 - acc: 0.9545\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1049 - acc: 0.9548\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1044 - acc: 0.9536\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1032 - acc: 0.9542\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1031 - acc: 0.9550\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1027 - acc: 0.9546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70     42858\n",
      "           1       0.67      0.58      0.62     23470\n",
      "           2       0.71      0.73      0.72     38450\n",
      "\n",
      "    accuracy                           0.69    104778\n",
      "   macro avg       0.69      0.68      0.68    104778\n",
      "weighted avg       0.69      0.69      0.69    104778\n",
      "\n",
      "Acur√°cia\n",
      "0.6757260421036153\n",
      "Precisao\n",
      "0.6911432568558924\n",
      "Recall\n",
      "0.6918150756838267\n",
      "F1\n",
      "0.6904283347814674\n",
      "[[30809  4286  7763]\n",
      " [ 6392 13516  3562]\n",
      " [ 7943  2345 28162]]\n",
      "TRAIN: [   0    1    3 ... 1996 1997 1999] TEST: [   2   14   15   20   24   40   42   44   53   55   57   66   70   88\n",
      "   89  101  105  108  110  121  137  139  151  154  156  157  162  163\n",
      "  164  171  175  176  177  178  182  183  184  187  188  190  194  202\n",
      "  204  209  210  213  214  223  229  235  237  239  241  245  248  249\n",
      "  251  252  256  265  270  276  281  294  300  315  324  325  328  329\n",
      "  338  345  358  361  364  365  367  371  377  386  387  388  395  408\n",
      "  409  417  428  434  444  447  449  451  455  462  465  467  474  479\n",
      "  490  498  499  506  515  517  518  520  534  536  552  560  564  570\n",
      "  572  580  582  596  598  606  607  609  612  617  623  631  635  642\n",
      "  651  662  663  669  672  674  675  689  697  698  703  708  712  716\n",
      "  722  723  727  746  748  758  774  778  779  784  787  800  810  813\n",
      "  816  818  826  828  829  833  843  850  854  857  859  868  874  875\n",
      "  880  883  884  886  891  893  897  900  901  903  909  914  919  926\n",
      "  929  933  938  942  946  947  953  955  957  963  979  987  995  996\n",
      " 1006 1012 1014 1027 1034 1039 1040 1049 1054 1059 1063 1067 1069 1074\n",
      " 1075 1078 1082 1088 1094 1119 1126 1130 1132 1134 1137 1139 1143 1145\n",
      " 1147 1148 1153 1154 1160 1173 1175 1189 1193 1198 1205 1213 1216 1224\n",
      " 1225 1236 1247 1253 1256 1264 1265 1267 1270 1274 1275 1282 1285 1288\n",
      " 1290 1292 1295 1296 1302 1309 1314 1329 1340 1349 1372 1386 1390 1391\n",
      " 1400 1405 1410 1414 1415 1417 1423 1426 1429 1433 1435 1446 1456 1457\n",
      " 1459 1463 1464 1474 1484 1485 1501 1512 1517 1519 1529 1533 1537 1538\n",
      " 1539 1542 1547 1548 1555 1556 1570 1572 1575 1601 1606 1610 1611 1612\n",
      " 1615 1617 1618 1621 1623 1625 1627 1635 1638 1643 1645 1646 1648 1650\n",
      " 1651 1653 1655 1658 1663 1666 1669 1676 1677 1682 1696 1700 1704 1710\n",
      " 1712 1717 1730 1731 1735 1736 1747 1753 1766 1770 1771 1772 1773 1780\n",
      " 1782 1783 1790 1791 1793 1796 1797 1799 1807 1809 1813 1815 1818 1819\n",
      " 1826 1831 1846 1848 1851 1855 1858 1860 1861 1866 1873 1875 1881 1882\n",
      " 1885 1886 1890 1892 1893 1901 1904 1912 1918 1932 1939 1943 1947 1950\n",
      " 1952 1959 1965 1967 1975 1982 1985 1998]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 12s 7ms/sample - loss: 0.3681 - acc: 0.7484\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3260 - acc: 0.8480\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3121 - acc: 0.8581\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3022 - acc: 0.8622\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2984 - acc: 0.8649\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2966 - acc: 0.8653\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2944 - acc: 0.8658\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2892 - acc: 0.8677\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2892 - acc: 0.8689\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2880 - acc: 0.8688\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2846 - acc: 0.8695\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2840 - acc: 0.8705\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2801 - acc: 0.8726\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2796 - acc: 0.8727\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2758 - acc: 0.8749\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2754 - acc: 0.8743\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2703 - acc: 0.8773\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2673 - acc: 0.8789\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2658 - acc: 0.8795\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2630 - acc: 0.8805\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2597 - acc: 0.8820\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2565 - acc: 0.8836\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2522 - acc: 0.8858\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2514 - acc: 0.8859\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2449 - acc: 0.8891\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2395 - acc: 0.8912\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2337 - acc: 0.8945\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2293 - acc: 0.8964\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2267 - acc: 0.8979\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2227 - acc: 0.9000\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2208 - acc: 0.9004\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2164 - acc: 0.9023\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2109 - acc: 0.9042\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2075 - acc: 0.9064\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2051 - acc: 0.9068\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2068 - acc: 0.9051\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1984 - acc: 0.9095\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1935 - acc: 0.9119\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1931 - acc: 0.9123\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1868 - acc: 0.9153\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1845 - acc: 0.9161\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1804 - acc: 0.9178\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1765 - acc: 0.9197\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1747 - acc: 0.9201\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1722 - acc: 0.9222\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1685 - acc: 0.9232\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1669 - acc: 0.9236\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1662 - acc: 0.9244\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1633 - acc: 0.9253\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1603 - acc: 0.9263\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1583 - acc: 0.9273\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1562 - acc: 0.9297\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1552 - acc: 0.9294\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1521 - acc: 0.9305\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1513 - acc: 0.9317\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1500 - acc: 0.9308\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1472 - acc: 0.9334\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1458 - acc: 0.9332\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1440 - acc: 0.9344\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1432 - acc: 0.9350\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1411 - acc: 0.9359\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1395 - acc: 0.9363\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1386 - acc: 0.9368\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1356 - acc: 0.9382\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1338 - acc: 0.9385\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1339 - acc: 0.9380\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1325 - acc: 0.9389\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1323 - acc: 0.9402\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1299 - acc: 0.9412\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1290 - acc: 0.9419\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1279 - acc: 0.9420\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1274 - acc: 0.9420\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1256 - acc: 0.9432\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1238 - acc: 0.9441\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1234 - acc: 0.9443\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1225 - acc: 0.9449\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1207 - acc: 0.9456\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1208 - acc: 0.9458\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1197 - acc: 0.9460\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1190 - acc: 0.9466\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1184 - acc: 0.9459\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1174 - acc: 0.9468\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1163 - acc: 0.9470\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1152 - acc: 0.9472\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1142 - acc: 0.9477\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1143 - acc: 0.9480\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1127 - acc: 0.9489\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1127 - acc: 0.9481\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1108 - acc: 0.9491\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1105 - acc: 0.9495\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1096 - acc: 0.9496\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1098 - acc: 0.9506\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1089 - acc: 0.9498\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1084 - acc: 0.9507\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1069 - acc: 0.9511\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1064 - acc: 0.9514\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1064 - acc: 0.9514\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1060 - acc: 0.9519\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1044 - acc: 0.9521\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1038 - acc: 0.9522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70     41161\n",
      "           1       0.64      0.57      0.60     21046\n",
      "           2       0.74      0.73      0.74     40208\n",
      "\n",
      "    accuracy                           0.69    102415\n",
      "   macro avg       0.69      0.68      0.68    102415\n",
      "weighted avg       0.69      0.69      0.69    102415\n",
      "\n",
      "Acur√°cia\n",
      "0.6750070347517282\n",
      "Precisao\n",
      "0.6943665969591968\n",
      "Recall\n",
      "0.6948982082702729\n",
      "F1\n",
      "0.6939294465960127\n",
      "[[29642  4146  7373]\n",
      " [ 6104 12016  2926]\n",
      " [ 8109  2589 29510]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   6   17   18   19   22   32   45   47   48   49   50   51   52   54\n",
      "   58   60   75   76   92   94  100  113  115  118  123  127  134  135\n",
      "  152  158  161  165  168  173  185  203  208  211  212  216  222  224\n",
      "  228  230  232  236  242  250  257  258  260  261  262  263  271  273\n",
      "  274  277  286  292  293  295  298  305  306  322  323  326  327  333\n",
      "  335  336  337  342  344  346  352  355  363  375  378  380  381  382\n",
      "  384  405  412  416  425  426  435  436  438  460  463  468  484  489\n",
      "  491  502  503  504  513  514  516  521  522  526  540  543  546  548\n",
      "  556  558  559  562  573  575  576  586  588  593  595  599  600  626\n",
      "  633  636  637  648  649  660  667  668  671  677  693  702  705  715\n",
      "  717  718  720  721  728  729  732  737  739  749  756  759  761  762\n",
      "  763  766  771  783  788  789  792  803  808  819  820  822  824  825\n",
      "  831  835  841  858  861  865  872  876  894  896  907  910  912  913\n",
      "  920  921  923  927  930  939  941  943  948  949  950  961  962  966\n",
      "  976  977  982  985  993  994 1017 1018 1029 1050 1056 1070 1081 1083\n",
      " 1090 1092 1098 1100 1102 1105 1106 1108 1114 1138 1146 1150 1151 1152\n",
      " 1155 1157 1163 1167 1169 1177 1181 1195 1197 1199 1200 1206 1207 1208\n",
      " 1210 1229 1234 1251 1254 1255 1257 1261 1262 1271 1283 1286 1294 1297\n",
      " 1298 1299 1300 1301 1306 1308 1316 1317 1319 1322 1324 1325 1328 1348\n",
      " 1351 1352 1356 1357 1370 1374 1376 1377 1383 1384 1389 1392 1396 1398\n",
      " 1403 1407 1416 1420 1427 1428 1431 1432 1437 1438 1439 1443 1450 1451\n",
      " 1453 1454 1455 1466 1467 1473 1480 1486 1488 1491 1492 1495 1503 1504\n",
      " 1507 1523 1531 1532 1540 1544 1549 1553 1554 1569 1577 1579 1585 1588\n",
      " 1600 1608 1613 1622 1629 1634 1637 1644 1660 1674 1681 1687 1689 1697\n",
      " 1698 1707 1708 1711 1713 1721 1723 1742 1744 1745 1750 1762 1763 1768\n",
      " 1776 1785 1788 1792 1798 1801 1812 1821 1827 1833 1834 1835 1844 1849\n",
      " 1859 1864 1865 1868 1871 1876 1877 1887 1891 1897 1900 1903 1906 1908\n",
      " 1910 1913 1917 1923 1927 1935 1938 1941 1945 1954 1957 1962 1964 1968\n",
      " 1969 1972 1977 1980 1983 1987 1990 1992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 12s 7ms/sample - loss: 0.3579 - acc: 0.7968\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3233 - acc: 0.8497\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3068 - acc: 0.8611\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3010 - acc: 0.8645\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2974 - acc: 0.8659\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2943 - acc: 0.8668\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2898 - acc: 0.8693\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2889 - acc: 0.8696\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2851 - acc: 0.8716\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2822 - acc: 0.8734\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2798 - acc: 0.8745\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2806 - acc: 0.8746\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2799 - acc: 0.8743\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2756 - acc: 0.8759\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2749 - acc: 0.8774\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2714 - acc: 0.8784\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2719 - acc: 0.8792\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2664 - acc: 0.8826\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2756 - acc: 0.8777\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2649 - acc: 0.8839\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2600 - acc: 0.8864\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2575 - acc: 0.8873\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2531 - acc: 0.8897\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2499 - acc: 0.8910\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2460 - acc: 0.8929\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2430 - acc: 0.8938\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2394 - acc: 0.8961\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2372 - acc: 0.8960\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2343 - acc: 0.8971\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2294 - acc: 0.8993\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2263 - acc: 0.9012\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2223 - acc: 0.9038\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2169 - acc: 0.9063\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2126 - acc: 0.9082\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2098 - acc: 0.9086\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2076 - acc: 0.9102\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2036 - acc: 0.9124\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1989 - acc: 0.9143\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1960 - acc: 0.9160\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1917 - acc: 0.9178\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1897 - acc: 0.9185\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1855 - acc: 0.9203\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1817 - acc: 0.9222\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1789 - acc: 0.9227\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1765 - acc: 0.9236\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1818 - acc: 0.9218\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1735 - acc: 0.9261\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1687 - acc: 0.9276\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1661 - acc: 0.9290\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1674 - acc: 0.9286\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1675 - acc: 0.9289\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1650 - acc: 0.9299\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1576 - acc: 0.9327\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1540 - acc: 0.9344\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1515 - acc: 0.9354\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1513 - acc: 0.9346\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1491 - acc: 0.9358\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1482 - acc: 0.9359\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1461 - acc: 0.9366\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1433 - acc: 0.9385\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1409 - acc: 0.9397\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1391 - acc: 0.9401\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1390 - acc: 0.9388\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1382 - acc: 0.9402\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1360 - acc: 0.9409\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1352 - acc: 0.9393\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1340 - acc: 0.9407\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1330 - acc: 0.9421\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1309 - acc: 0.9418\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1297 - acc: 0.9435\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1287 - acc: 0.9435\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1266 - acc: 0.9442\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1264 - acc: 0.9443\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1251 - acc: 0.9463\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1230 - acc: 0.9470\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1222 - acc: 0.9478\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1214 - acc: 0.9476\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1209 - acc: 0.9473\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1199 - acc: 0.9473\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1179 - acc: 0.9490\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1177 - acc: 0.9495\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1175 - acc: 0.9487\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1169 - acc: 0.9487\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1153 - acc: 0.9492\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1145 - acc: 0.9502\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1141 - acc: 0.9503\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1147 - acc: 0.9501\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1119 - acc: 0.9516\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1113 - acc: 0.9525\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1109 - acc: 0.9530\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1084 - acc: 0.9532\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1089 - acc: 0.9536\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1088 - acc: 0.9538\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1070 - acc: 0.9542\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1069 - acc: 0.9547\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1066 - acc: 0.9542\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1069 - acc: 0.9538\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1051 - acc: 0.9548\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1043 - acc: 0.9554\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1034 - acc: 0.9559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71     43572\n",
      "           1       0.69      0.56      0.62     24107\n",
      "           2       0.70      0.74      0.72     36454\n",
      "\n",
      "    accuracy                           0.69    104133\n",
      "   macro avg       0.69      0.68      0.68    104133\n",
      "weighted avg       0.69      0.69      0.69    104133\n",
      "\n",
      "Acur√°cia\n",
      "0.6759991594093856\n",
      "Precisao\n",
      "0.6932431626311119\n",
      "Recall\n",
      "0.6932768670834414\n",
      "F1\n",
      "0.6912276234703878\n",
      "[[31723  4135  7714]\n",
      " [ 6942 13507  3658]\n",
      " [ 7615  1876 26963]]\n",
      "TRAIN: [   0    2    4 ... 1995 1997 1998] TEST: [   1    3    7    8    9   11   16   21   25   27   33   34   62   63\n",
      "   65   67   74   80   84   87   93   98  106  111  114  116  122  126\n",
      "  130  132  133  136  141  142  146  149  166  179  180  191  192  195\n",
      "  200  205  217  221  226  227  233  240  243  267  278  282  284  287\n",
      "  288  291  296  301  302  303  314  319  340  341  373  385  392  394\n",
      "  396  398  402  404  418  419  431  448  452  453  456  459  461  464\n",
      "  466  472  473  476  477  478  485  487  492  493  496  497  500  509\n",
      "  519  527  529  535  541  550  554  565  569  577  581  589  590  591\n",
      "  597  602  603  614  618  627  629  638  640  644  645  646  650  658\n",
      "  670  673  678  679  682  685  686  688  696  707  709  710  719  736\n",
      "  738  740  745  750  754  765  770  772  776  780  785  786  797  799\n",
      "  806  809  812  814  817  821  823  840  842  845  847  855  860  887\n",
      "  898  899  904  906  908  915  931  932  934  960  964  967  969  971\n",
      "  972  974  978  980  986  989  991  999 1000 1002 1004 1010 1013 1015\n",
      " 1019 1021 1023 1024 1035 1036 1037 1061 1062 1064 1068 1073 1076 1080\n",
      " 1095 1097 1099 1104 1109 1111 1112 1113 1124 1125 1127 1140 1142 1144\n",
      " 1149 1170 1171 1178 1179 1180 1188 1191 1196 1203 1209 1211 1212 1214\n",
      " 1217 1221 1228 1239 1240 1243 1244 1246 1248 1258 1259 1263 1272 1278\n",
      " 1279 1280 1284 1289 1304 1307 1327 1331 1332 1338 1339 1344 1347 1354\n",
      " 1355 1360 1364 1365 1378 1379 1381 1385 1388 1394 1395 1397 1401 1409\n",
      " 1411 1413 1419 1422 1436 1461 1465 1468 1469 1470 1472 1475 1482 1487\n",
      " 1497 1500 1505 1508 1509 1510 1520 1521 1525 1543 1546 1559 1564 1567\n",
      " 1574 1580 1584 1594 1595 1599 1607 1614 1619 1626 1628 1632 1633 1636\n",
      " 1639 1649 1654 1657 1659 1662 1664 1665 1675 1683 1686 1701 1702 1718\n",
      " 1720 1729 1732 1739 1746 1749 1752 1755 1757 1764 1765 1774 1778 1779\n",
      " 1781 1784 1786 1787 1789 1795 1800 1804 1811 1816 1820 1823 1824 1825\n",
      " 1829 1830 1837 1838 1840 1842 1843 1847 1852 1863 1870 1884 1902 1907\n",
      " 1914 1916 1920 1921 1922 1924 1926 1928 1930 1944 1946 1951 1955 1956\n",
      " 1958 1960 1961 1973 1979 1989 1996 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 12s 7ms/sample - loss: 0.3602 - acc: 0.7888\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3230 - acc: 0.8504\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3041 - acc: 0.8625\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2983 - acc: 0.8660\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2933 - acc: 0.8680\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2927 - acc: 0.8688\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2898 - acc: 0.8701\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2895 - acc: 0.8701\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2851 - acc: 0.8725\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2829 - acc: 0.8745\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2827 - acc: 0.8743\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2809 - acc: 0.8755\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2772 - acc: 0.8780\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2788 - acc: 0.8761\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2738 - acc: 0.8785\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2712 - acc: 0.8806\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2764 - acc: 0.8780\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2710 - acc: 0.8807\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2671 - acc: 0.8829\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2622 - acc: 0.8848\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2598 - acc: 0.8864\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2570 - acc: 0.8885\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2548 - acc: 0.8890\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2596 - acc: 0.8857\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2741 - acc: 0.8785\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2772 - acc: 0.8768\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2639 - acc: 0.8846\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2568 - acc: 0.8877\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2562 - acc: 0.8882\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2519 - acc: 0.8899\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2457 - acc: 0.8933\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2440 - acc: 0.8937\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2394 - acc: 0.8961\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2357 - acc: 0.8979\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2334 - acc: 0.8988\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2313 - acc: 0.9001\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2289 - acc: 0.9008\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2261 - acc: 0.9024\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2216 - acc: 0.9046\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2222 - acc: 0.9043\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2177 - acc: 0.9063\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2158 - acc: 0.9075\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2132 - acc: 0.9084\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2099 - acc: 0.9099\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2069 - acc: 0.9112\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2045 - acc: 0.9121\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2020 - acc: 0.9133\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1998 - acc: 0.9142\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1968 - acc: 0.9157\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1937 - acc: 0.9171\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1929 - acc: 0.9171\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1924 - acc: 0.9176\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1942 - acc: 0.9169\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1931 - acc: 0.9175\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1880 - acc: 0.9192\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1878 - acc: 0.9186\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1842 - acc: 0.9214\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1788 - acc: 0.9236\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1812 - acc: 0.9225\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1773 - acc: 0.9242\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1769 - acc: 0.9241\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1768 - acc: 0.9245\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1704 - acc: 0.9273\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1667 - acc: 0.9292\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1638 - acc: 0.9301\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1629 - acc: 0.9308\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1634 - acc: 0.9306\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1595 - acc: 0.9325\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1571 - acc: 0.9333\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1566 - acc: 0.9334\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1553 - acc: 0.9339\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1562 - acc: 0.9338\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1525 - acc: 0.9354\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1507 - acc: 0.9360\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1489 - acc: 0.9374\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1479 - acc: 0.9374\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1492 - acc: 0.9371\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1462 - acc: 0.9380\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1456 - acc: 0.9386\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1436 - acc: 0.9397\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1412 - acc: 0.9403\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1396 - acc: 0.9399\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1385 - acc: 0.9413\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1383 - acc: 0.9419\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1369 - acc: 0.9425\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1355 - acc: 0.9429\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1339 - acc: 0.9433\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1340 - acc: 0.9434\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1325 - acc: 0.9444\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1305 - acc: 0.9452\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1290 - acc: 0.9460\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1288 - acc: 0.9458\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1282 - acc: 0.9462\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1258 - acc: 0.9472\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1264 - acc: 0.9469\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1262 - acc: 0.9471\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1253 - acc: 0.9474\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1249 - acc: 0.9478\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1224 - acc: 0.9488\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1210 - acc: 0.9495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69     43755\n",
      "           1       0.62      0.61      0.62     23755\n",
      "           2       0.73      0.69      0.71     38159\n",
      "\n",
      "    accuracy                           0.68    105669\n",
      "   macro avg       0.68      0.67      0.67    105669\n",
      "weighted avg       0.68      0.68      0.68    105669\n",
      "\n",
      "Acur√°cia\n",
      "0.6702889259686714\n",
      "Precisao\n",
      "0.6819291604959828\n",
      "Recall\n",
      "0.6810890611248333\n",
      "F1\n",
      "0.6810083232315308\n",
      "[[31298  5458  6999]\n",
      " [ 6503 14456  2796]\n",
      " [ 8692  3251 26216]]\n",
      "TRAIN: [   1    2    3 ... 1997 1998 1999] TEST: [   0    4    5   13   28   31   35   43   56   59   64   69   71   72\n",
      "   73   77   81   86   91   96   99  102  103  109  112  120  128  129\n",
      "  138  140  145  147  148  150  153  159  167  169  170  181  189  196\n",
      "  197  198  199  215  218  219  225  231  234  244  247  253  259  266\n",
      "  272  279  280  290  304  307  308  310  311  312  313  318  321  330\n",
      "  334  339  343  348  351  356  362  368  369  370  374  390  393  397\n",
      "  400  406  410  411  415  420  421  422  423  424  427  437  439  440\n",
      "  441  469  471  480  481  482  488  494  501  505  508  511  524  530\n",
      "  531  539  544  547  553  555  557  567  584  592  611  616  619  621\n",
      "  622  634  641  647  652  653  654  655  656  659  676  683  684  690\n",
      "  692  694  695  701  704  706  724  731  733  734  735  741  742  744\n",
      "  747  752  753  767  769  782  791  794  795  801  804  805  811  830\n",
      "  836  837  838  846  848  856  862  863  866  869  878  879  882  889\n",
      "  890  892  895  902  911  918  922  925  935  937  944  952  956  968\n",
      "  970  981  983  984  988  990  992  997  998 1001 1016 1026 1033 1042\n",
      " 1046 1048 1051 1053 1057 1060 1072 1086 1087 1091 1093 1096 1103 1107\n",
      " 1115 1117 1121 1135 1156 1159 1161 1164 1166 1174 1182 1183 1184 1185\n",
      " 1186 1202 1219 1222 1223 1227 1231 1235 1237 1238 1241 1242 1245 1250\n",
      " 1252 1260 1268 1273 1281 1303 1305 1310 1312 1315 1318 1321 1323 1330\n",
      " 1335 1337 1341 1342 1345 1346 1350 1353 1358 1366 1368 1371 1373 1375\n",
      " 1393 1399 1404 1406 1412 1418 1424 1425 1434 1442 1444 1448 1452 1460\n",
      " 1471 1476 1477 1478 1479 1481 1489 1490 1493 1496 1499 1506 1511 1513\n",
      " 1516 1518 1522 1526 1530 1535 1541 1545 1551 1552 1558 1561 1565 1568\n",
      " 1576 1578 1581 1582 1587 1590 1592 1593 1596 1597 1598 1602 1609 1616\n",
      " 1624 1630 1641 1642 1647 1652 1656 1661 1667 1670 1671 1673 1678 1680\n",
      " 1690 1692 1693 1694 1695 1699 1705 1722 1725 1726 1733 1743 1748 1754\n",
      " 1759 1760 1761 1805 1808 1814 1817 1832 1839 1845 1854 1856 1869 1872\n",
      " 1874 1879 1880 1888 1894 1896 1899 1905 1911 1940 1963 1966 1970 1974\n",
      " 1976 1978 1981 1986 1988 1993 1994 1995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 12s 7ms/sample - loss: 0.3662 - acc: 0.7987\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3341 - acc: 0.8447\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3141 - acc: 0.8582\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3078 - acc: 0.8619\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3027 - acc: 0.8648\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.3002 - acc: 0.8654\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2961 - acc: 0.8673\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2941 - acc: 0.8682\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2926 - acc: 0.8683\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2928 - acc: 0.8687\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2886 - acc: 0.8713\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2855 - acc: 0.8724\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2873 - acc: 0.8708\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2833 - acc: 0.8730\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2787 - acc: 0.8747\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2789 - acc: 0.8746\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2748 - acc: 0.8763\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2741 - acc: 0.8771\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2713 - acc: 0.8791\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2681 - acc: 0.8804\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2629 - acc: 0.8843\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2621 - acc: 0.8837\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2599 - acc: 0.8844\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2536 - acc: 0.8884\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2522 - acc: 0.8895\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2513 - acc: 0.8896\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2445 - acc: 0.8929\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2407 - acc: 0.8953\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2357 - acc: 0.8968\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2333 - acc: 0.8991\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2304 - acc: 0.9010\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2223 - acc: 0.9039\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2161 - acc: 0.9069\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2138 - acc: 0.9082\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2095 - acc: 0.9102\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2092 - acc: 0.9103\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.2033 - acc: 0.9130\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1999 - acc: 0.9145\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1983 - acc: 0.9152\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1943 - acc: 0.9170\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1894 - acc: 0.9189\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1850 - acc: 0.9211\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1827 - acc: 0.9222\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1811 - acc: 0.9230\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1775 - acc: 0.9244\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1760 - acc: 0.9250\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1726 - acc: 0.9265\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1690 - acc: 0.9276\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1653 - acc: 0.9296\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1630 - acc: 0.9307\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1601 - acc: 0.9319\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1598 - acc: 0.9322\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1561 - acc: 0.9339\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1529 - acc: 0.9352\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1518 - acc: 0.9358\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1500 - acc: 0.9366\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1500 - acc: 0.9365\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1478 - acc: 0.9375\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1465 - acc: 0.9380\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1443 - acc: 0.9391\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1443 - acc: 0.9391\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1411 - acc: 0.9406\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1393 - acc: 0.9412\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1372 - acc: 0.9422\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1357 - acc: 0.9430\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1340 - acc: 0.9437\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1340 - acc: 0.9435\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1315 - acc: 0.9446\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1303 - acc: 0.9452\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1295 - acc: 0.9452\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1281 - acc: 0.9460\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1271 - acc: 0.9467\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1260 - acc: 0.9469\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1253 - acc: 0.9470\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1237 - acc: 0.9474\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1226 - acc: 0.9481\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1215 - acc: 0.9485\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1210 - acc: 0.9489\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1201 - acc: 0.9495\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1180 - acc: 0.9495\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1172 - acc: 0.9502\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1175 - acc: 0.9498\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1166 - acc: 0.9499\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1158 - acc: 0.9506\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1158 - acc: 0.9512\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1137 - acc: 0.9517\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1126 - acc: 0.9522\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1126 - acc: 0.9526\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1105 - acc: 0.9530\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1114 - acc: 0.9533\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1102 - acc: 0.9531\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1088 - acc: 0.9541\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1081 - acc: 0.9544\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1074 - acc: 0.9548\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1070 - acc: 0.9548\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1067 - acc: 0.9550\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1059 - acc: 0.9554\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1052 - acc: 0.9553\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1047 - acc: 0.9561\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 11s 7ms/sample - loss: 0.1036 - acc: 0.9569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70     40252\n",
      "           1       0.67      0.60      0.63     22818\n",
      "           2       0.72      0.73      0.73     35743\n",
      "\n",
      "    accuracy                           0.69     98813\n",
      "   macro avg       0.69      0.68      0.69     98813\n",
      "weighted avg       0.69      0.69      0.69     98813\n",
      "\n",
      "Acur√°cia\n",
      "0.6815957363360389\n",
      "Precisao\n",
      "0.693595694040854\n",
      "Recall\n",
      "0.6940483539615233\n",
      "F1\n",
      "0.6932035124552008\n",
      "[[28875  4439  6938]\n",
      " [ 6116 13665  3037]\n",
      " [ 7344  2358 26041]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede()\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classes[train_index],\n",
    "                           previsores[test_index], classes[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_2 (Masking)          (None, 700, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 700, 200)          96800     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 700, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 700, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 700, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 700, 3)            603       \n",
      "=================================================================\n",
      "Total params: 819,803\n",
      "Trainable params: 819,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cias total\n",
      "0.8019385058318249\n",
      "Precision total\n",
      "0.8124853288891728\n",
      "Recalls total\n",
      "0.8124986326813181\n",
      "F1 total\n",
      "0.8119622556029673\n"
     ]
    }
   ],
   "source": [
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
