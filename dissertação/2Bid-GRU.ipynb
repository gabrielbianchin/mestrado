{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 700, 20)\n",
      "(2000, 700, 8)\n",
      "(2000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "previsores = base.iloc[:1400000,0:20].values\n",
    "previsores = np.reshape(previsores, (2000, 700, 20))\n",
    "print(previsores.shape)\n",
    "\n",
    "classesQ8 = base.iloc[:1400000, 20:28].values\n",
    "classesQ8 = np.reshape(classesQ8, (2000, 700, 8))\n",
    "print(classesQ8.shape)\n",
    "\n",
    "classesQ3 = base.iloc[:1400000, 28:31].values\n",
    "classesQ3 = np.reshape(classesQ3, (2000, 700, 3))\n",
    "print(classesQ3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNGRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRede(saida):\n",
    "    model = Sequential()\n",
    "  \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True), input_shape = (700, 20)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
    "    model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(saida, activation = 'softmax'))\n",
    "  \n",
    "    model.compile(optimizer = 'adam', metrics = ['acc'], loss='categorical_crossentropy')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test, saida):\n",
    "    model.fit(x_train, y_train, epochs = 100, verbose = 1)\n",
    "  \n",
    "    predicted = model.predict(x_test)\n",
    "    y_teste = []\n",
    "    predict = []\n",
    "  \n",
    "    predicted = np.reshape(predicted, (predicted.shape[0] * predicted.shape[1], saida))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0] * y_test.shape[1], saida))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0] * x_test.shape[1], 20))\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        cont = 0\n",
    "        for j in range(len(x_test[i])):\n",
    "            cont += x_test[i][j]\n",
    "        if cont != 0:\n",
    "            y_teste.append(y_test[i])\n",
    "            predict.append(predicted[i])\n",
    "    \n",
    "    y_teste = np.asarray(y_teste)\n",
    "    predict = np.asarray(predict)\n",
    "\n",
    "    predicted = predict\n",
    "    y_test = y_teste\n",
    "    \n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accu.append(balanced_accuracy_score(y_test, predicted)) \n",
    "    precisions.append(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    recalls.append(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    f1.append(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    \n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('Acur√°cia')\n",
    "    print(balanced_accuracy_score(y_test, predicted))\n",
    "    print('Precisao')\n",
    "    print(precision_score(y_test, predicted, average = 'weighted'))\n",
    "    print('Recall')\n",
    "    print(recall_score(y_test, predicted, average = 'weighted'))\n",
    "    print('F1')\n",
    "    print(f1_score(y_test, predicted, average = 'weighted'))\n",
    "    print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   2    3    4 ... 1996 1997 1998] TEST: [   0    1   14   17   20   21   22   40   45   46   51   52   58   59\n",
      "   62   63   71   82   88   93   98   99  110  113  124  128  132  133\n",
      "  142  146  156  158  161  162  166  167  170  171  175  183  186  187\n",
      "  193  194  199  202  214  222  227  228  230  233  235  239  241  242\n",
      "  247  249  253  256  258  263  267  268  271  280  292  300  304  309\n",
      "  312  323  328  331  339  343  345  349  353  354  355  359  374  379\n",
      "  387  388  399  402  404  405  408  416  422  428  429  432  433  439\n",
      "  446  453  460  462  463  465  469  470  472  476  480  487  488  489\n",
      "  515  531  540  550  578  583  588  596  601  603  605  614  616  618\n",
      "  622  625  626  630  645  651  658  662  663  668  679  691  697  717\n",
      "  721  722  735  744  747  748  751  757  765  774  778  781  782  783\n",
      "  788  792  805  823  825  829  831  839  840  843  856  858  865  877\n",
      "  883  887  899  906  907  908  927  932  940  942  944  955  956  958\n",
      "  964  979  989 1001 1002 1018 1020 1024 1025 1030 1032 1035 1037 1047\n",
      " 1050 1057 1069 1079 1084 1085 1086 1098 1102 1106 1113 1114 1115 1126\n",
      " 1127 1142 1146 1154 1166 1167 1169 1170 1173 1178 1179 1183 1184 1193\n",
      " 1197 1200 1201 1215 1219 1224 1234 1235 1236 1238 1248 1250 1251 1253\n",
      " 1254 1261 1272 1273 1287 1288 1292 1293 1298 1299 1305 1307 1308 1312\n",
      " 1315 1325 1334 1335 1336 1339 1345 1348 1351 1354 1357 1358 1359 1365\n",
      " 1373 1377 1387 1394 1400 1406 1421 1424 1427 1428 1434 1447 1457 1471\n",
      " 1480 1488 1489 1491 1495 1500 1502 1504 1510 1515 1518 1520 1525 1532\n",
      " 1537 1538 1540 1546 1549 1552 1554 1555 1558 1561 1563 1565 1566 1571\n",
      " 1584 1586 1593 1601 1615 1618 1619 1620 1636 1637 1638 1647 1659 1660\n",
      " 1663 1664 1665 1666 1686 1691 1695 1696 1697 1699 1706 1710 1713 1723\n",
      " 1726 1727 1730 1731 1732 1744 1753 1755 1770 1780 1783 1791 1792 1794\n",
      " 1797 1798 1800 1802 1805 1808 1816 1818 1820 1825 1827 1831 1833 1835\n",
      " 1837 1841 1842 1847 1854 1866 1868 1873 1874 1875 1876 1877 1878 1879\n",
      " 1885 1889 1891 1895 1901 1902 1930 1931 1935 1937 1940 1946 1953 1954\n",
      " 1960 1963 1972 1981 1985 1990 1995 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 31s 19ms/sample - loss: 0.6048 - acc: 0.1561\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5385 - acc: 0.1719\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5268 - acc: 0.1768\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5173 - acc: 0.1810\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5135 - acc: 0.1825\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5070 - acc: 0.1853\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5044 - acc: 0.1862\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5038 - acc: 0.1864\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5014 - acc: 0.1876\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4964 - acc: 0.1898\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4929 - acc: 0.1913\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4892 - acc: 0.1931\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4883 - acc: 0.1933\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4842 - acc: 0.1953\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4791 - acc: 0.1977\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4733 - acc: 0.2001\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4639 - acc: 0.2036\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4596 - acc: 0.2054\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4585 - acc: 0.2059\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4563 - acc: 0.2066\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4538 - acc: 0.2077\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4509 - acc: 0.2087\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4481 - acc: 0.2100\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4444 - acc: 0.2112\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4445 - acc: 0.2114\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4405 - acc: 0.2128\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4386 - acc: 0.2136 2s - loss: 0.\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4382 - acc: 0.2134\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4349 - acc: 0.2146\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4337 - acc: 0.2148\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4321 - acc: 0.2155\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4301 - acc: 0.2164\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4277 - acc: 0.2171\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4262 - acc: 0.2179\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4235 - acc: 0.2186\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4224 - acc: 0.2190\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4217 - acc: 0.2191\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4181 - acc: 0.2201\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4156 - acc: 0.2216\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4134 - acc: 0.2219\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4120 - acc: 0.2221\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4104 - acc: 0.2232\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4080 - acc: 0.2239\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4057 - acc: 0.2246\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4035 - acc: 0.2252\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4021 - acc: 0.2255\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3998 - acc: 0.2265\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3991 - acc: 0.2267\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3978 - acc: 0.2273\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3940 - acc: 0.2286\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3922 - acc: 0.2289\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3911 - acc: 0.2295\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3893 - acc: 0.2301\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3874 - acc: 0.2305\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3860 - acc: 0.2309\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3834 - acc: 0.2319\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3831 - acc: 0.2321\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3809 - acc: 0.2328\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3807 - acc: 0.2326\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3769 - acc: 0.2339\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3755 - acc: 0.2345\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3734 - acc: 0.2353\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3728 - acc: 0.2352\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3708 - acc: 0.2362\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3692 - acc: 0.2366\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3670 - acc: 0.2372\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3674 - acc: 0.2369\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3647 - acc: 0.2377\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3631 - acc: 0.2384\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3616 - acc: 0.2388\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3598 - acc: 0.2395\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3585 - acc: 0.2399\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3574 - acc: 0.2404\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3572 - acc: 0.2407\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3557 - acc: 0.2410\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3539 - acc: 0.2415\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3534 - acc: 0.2418\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3544 - acc: 0.2412\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3499 - acc: 0.2426\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3483 - acc: 0.2433\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3475 - acc: 0.2435\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3467 - acc: 0.2437\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3469 - acc: 0.2438\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3459 - acc: 0.2439\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3433 - acc: 0.2449\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3435 - acc: 0.2447\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3425 - acc: 0.2453\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3409 - acc: 0.2458\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3393 - acc: 0.2461\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3383 - acc: 0.2464\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3379 - acc: 0.2466\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3422 - acc: 0.2451\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3356 - acc: 0.2472\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3340 - acc: 0.2478\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 8s 5ms/sample - loss: 0.3329 - acc: 0.2482\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 7s 5ms/sample - loss: 0.3321 - acc: 0.2488\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3317 - acc: 0.2486\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3302 - acc: 0.2491\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3294 - acc: 0.2494\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3286 - acc: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1213\n",
      "           1       0.61      0.66      0.64     20725\n",
      "           2       0.32      0.16      0.21      3939\n",
      "           3       0.73      0.80      0.76     33055\n",
      "           4       0.53      0.17      0.26       702\n",
      "           5       0.44      0.57      0.50     20714\n",
      "           6       0.35      0.08      0.13      9037\n",
      "           7       0.40      0.38      0.39     11455\n",
      "\n",
      "    accuracy                           0.57    100840\n",
      "   macro avg       0.42      0.35      0.36    100840\n",
      "weighted avg       0.55      0.57      0.55    100840\n",
      "\n",
      "Acur√°cia\n",
      "0.3533836230186679\n",
      "Precisao\n",
      "0.5486815803234427\n",
      "Recall\n",
      "0.5737306624355415\n",
      "F1\n",
      "0.5491236727586929\n",
      "[[    0   275    22   151     1   623    30   111]\n",
      " [    0 13712   136  2068     8  3757   191   853]\n",
      " [    0   458   630   929     0  1180    83   659]\n",
      " [    0  1883   423 26420    58  2710   131  1430]\n",
      " [    0    79    21   340   121    84     4    53]\n",
      " [    0  3492   269  2582    18 11894   469  1990]\n",
      " [    0  1260   176  1271     7  4067   701  1555]\n",
      " [    0  1155   287  2358    14  2874   390  4377]]\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [   8   15   18   19   25   32   41   47   56   57   64   74   90   96\n",
      "   97  102  104  106  109  114  116  119  120  126  129  138  140  152\n",
      "  153  160  173  177  192  197  200  201  203  211  216  218  225  226\n",
      "  229  240  244  248  255  260  262  274  275  277  291  293  303  305\n",
      "  310  315  316  318  320  326  332  333  336  338  344  357  363  365\n",
      "  367  370  371  373  376  384  390  398  400  406  414  415  421  424\n",
      "  434  435  436  437  438  440  447  451  454  458  461  471  473  477\n",
      "  478  479  481  485  490  496  502  505  507  513  516  520  521  524\n",
      "  527  530  535  545  547  549  551  552  555  557  562  565  567  573\n",
      "  576  579  587  589  595  611  624  633  639  644  655  656  661  672\n",
      "  677  680  690  693  695  702  703  711  712  713  716  718  719  720\n",
      "  723  727  733  740  753  754  766  771  773  785  786  787  791  796\n",
      "  801  802  803  808  812  819  827  833  836  841  848  855  860  861\n",
      "  863  868  881  890  891  893  894  902  910  911  913  917  918  920\n",
      "  950  953  954  959  963  969  970  971  976  981  983  985  993  994\n",
      "  996 1003 1005 1007 1009 1014 1021 1026 1033 1040 1041 1046 1049 1051\n",
      " 1064 1068 1071 1082 1087 1088 1092 1093 1109 1112 1117 1118 1120 1122\n",
      " 1123 1124 1125 1132 1133 1135 1141 1144 1152 1158 1159 1160 1181 1182\n",
      " 1190 1196 1199 1207 1231 1245 1257 1259 1263 1269 1291 1297 1304 1306\n",
      " 1327 1330 1331 1338 1340 1341 1343 1361 1376 1379 1382 1386 1391 1396\n",
      " 1397 1402 1409 1411 1412 1429 1430 1443 1448 1458 1460 1462 1463 1464\n",
      " 1465 1474 1476 1477 1481 1484 1485 1497 1498 1506 1508 1512 1514 1521\n",
      " 1522 1524 1528 1535 1543 1547 1564 1569 1576 1577 1582 1590 1597 1604\n",
      " 1613 1625 1632 1643 1646 1649 1650 1655 1656 1661 1662 1674 1681 1682\n",
      " 1688 1693 1700 1701 1708 1712 1717 1718 1728 1737 1739 1740 1743 1746\n",
      " 1750 1752 1756 1767 1773 1777 1779 1785 1787 1796 1804 1807 1814 1817\n",
      " 1824 1832 1844 1846 1848 1851 1852 1855 1858 1867 1871 1883 1887 1892\n",
      " 1899 1900 1903 1907 1912 1913 1918 1920 1923 1924 1941 1943 1945 1948\n",
      " 1955 1958 1959 1964 1967 1969 1979 1988]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 8s 5ms/sample - loss: 0.5980 - acc: 0.1567\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5345 - acc: 0.1697\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5241 - acc: 0.1745\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5149 - acc: 0.1787\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5094 - acc: 0.1812\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5057 - acc: 0.1829\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5013 - acc: 0.1844\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4982 - acc: 0.1858\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4988 - acc: 0.1858\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4940 - acc: 0.1877\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4913 - acc: 0.1891\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4858 - acc: 0.1916\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4849 - acc: 0.1918\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4792 - acc: 0.1945\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4763 - acc: 0.1958\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4698 - acc: 0.1981\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4615 - acc: 0.2015\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4573 - acc: 0.2034\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4548 - acc: 0.2040\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4531 - acc: 0.2047\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4493 - acc: 0.2061\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4470 - acc: 0.2071\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4462 - acc: 0.2069\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4418 - acc: 0.2089\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4418 - acc: 0.2090\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4390 - acc: 0.2102\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4362 - acc: 0.2113\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4338 - acc: 0.2121\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4325 - acc: 0.2126\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4293 - acc: 0.2134\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4287 - acc: 0.2138\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4273 - acc: 0.2141\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4248 - acc: 0.2152\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4223 - acc: 0.2160\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4196 - acc: 0.2171\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4189 - acc: 0.2174\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4166 - acc: 0.2180\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.4138 - acc: 0.2192\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.4126 - acc: 0.2197\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.4095 - acc: 0.2205\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.4077 - acc: 0.2213\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.4060 - acc: 0.2219\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.4051 - acc: 0.2222\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.4025 - acc: 0.2229\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3995 - acc: 0.2239\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3979 - acc: 0.2247\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3957 - acc: 0.2253\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3941 - acc: 0.2256\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3926 - acc: 0.2262\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3915 - acc: 0.2267\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3896 - acc: 0.2274\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3865 - acc: 0.2283\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3855 - acc: 0.2281\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3863 - acc: 0.2283\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3813 - acc: 0.2299\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3808 - acc: 0.2300\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3769 - acc: 0.2314\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3759 - acc: 0.2317\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3748 - acc: 0.2320\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3726 - acc: 0.2327\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3702 - acc: 0.2337\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3693 - acc: 0.2337\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3679 - acc: 0.2343\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3668 - acc: 0.2344\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3647 - acc: 0.2353\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3629 - acc: 0.2355\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3621 - acc: 0.2359\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3607 - acc: 0.2363\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3596 - acc: 0.2367\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3580 - acc: 0.2375\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3569 - acc: 0.2379\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3549 - acc: 0.2382\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3549 - acc: 0.2383\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3527 - acc: 0.2390\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3511 - acc: 0.2395\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3502 - acc: 0.2399\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3501 - acc: 0.2397\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3489 - acc: 0.2403\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3466 - acc: 0.2408\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3453 - acc: 0.2415\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 7s 5ms/sample - loss: 0.3453 - acc: 0.2412\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3426 - acc: 0.2422\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3421 - acc: 0.2423\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3400 - acc: 0.2428\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3399 - acc: 0.2430\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3386 - acc: 0.2436\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3376 - acc: 0.2438\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3364 - acc: 0.2440\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3369 - acc: 0.2438\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3349 - acc: 0.2448\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3334 - acc: 0.2453\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3321 - acc: 0.2456\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3315 - acc: 0.2457\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3307 - acc: 0.2459\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3294 - acc: 0.2465\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3283 - acc: 0.2468\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3277 - acc: 0.2470\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.3269 - acc: 0.2473\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3259 - acc: 0.2476\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3256 - acc: 0.2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1272\n",
      "           1       0.61      0.68      0.65     22149\n",
      "           2       0.33      0.17      0.22      3840\n",
      "           3       0.74      0.81      0.77     34441\n",
      "           4       0.57      0.22      0.32       739\n",
      "           5       0.44      0.55      0.49     21012\n",
      "           6       0.34      0.08      0.13      9216\n",
      "           7       0.39      0.39      0.39     11691\n",
      "\n",
      "    accuracy                           0.58    104360\n",
      "   macro avg       0.43      0.36      0.37    104360\n",
      "weighted avg       0.55      0.58      0.56    104360\n",
      "\n",
      "Acur√°cia\n",
      "0.36166590086146255\n",
      "Precisao\n",
      "0.5537145072477215\n",
      "Recall\n",
      "0.5799060942889996\n",
      "F1\n",
      "0.555684997486796\n",
      "[[    0   324    21   151     0   628    32   116]\n",
      " [    0 15112   162  2086     3  3609   193   984]\n",
      " [    0   464   639   958     7  1010    79   683]\n",
      " [    0  2043   354 27727    90  2560   139  1528]\n",
      " [    0    62     7   407   163    56     3    41]\n",
      " [    0  3964   275  2511     8 11623   571  2060]\n",
      " [    0  1421   153  1184     4  4108   712  1634]\n",
      " [    0  1242   312  2411    12  2827   344  4543]]\n",
      "TRAIN: [   0    1    2 ... 1996 1998 1999] TEST: [   7    9   13   16   36   39   42   44   49   61   66   70   72   73\n",
      "   79   80   83   84   86   94  100  108  115  118  125  130  135  136\n",
      "  137  141  144  150  154  157  159  163  169  172  178  179  180  182\n",
      "  204  206  207  210  213  231  232  234  237  246  254  259  270  273\n",
      "  276  278  281  282  283  286  299  301  311  314  317  319  346  356\n",
      "  358  360  362  368  381  383  385  386  389  391  392  394  403  407\n",
      "  410  412  417  425  441  449  456  468  482  483  484  486  491  497\n",
      "  504  508  511  514  541  543  544  548  561  564  569  571  574  575\n",
      "  580  584  585  586  591  593  629  634  637  640  641  642  647  649\n",
      "  650  654  660  669  670  678  681  688  694  706  707  714  724  726\n",
      "  729  738  741  745  750  755  756  763  780  795  798  806  809  832\n",
      "  852  853  854  859  870  874  876  879  880  882  884  885  896  897\n",
      "  903  909  921  935  937  938  939  943  945  946  948  951  961  974\n",
      "  978  980  984  986  987  990  995  997  998 1000 1006 1011 1031 1034\n",
      " 1036 1038 1039 1042 1043 1059 1060 1067 1073 1074 1075 1078 1089 1090\n",
      " 1096 1097 1099 1103 1105 1108 1111 1116 1128 1130 1137 1139 1147 1150\n",
      " 1151 1153 1161 1165 1177 1180 1187 1188 1189 1195 1202 1208 1211 1213\n",
      " 1218 1225 1230 1237 1241 1243 1244 1249 1260 1277 1280 1283 1284 1286\n",
      " 1289 1294 1310 1316 1318 1320 1329 1332 1356 1360 1363 1366 1367 1369\n",
      " 1370 1372 1380 1389 1399 1401 1405 1410 1414 1415 1422 1436 1438 1440\n",
      " 1454 1455 1461 1466 1467 1472 1475 1483 1490 1492 1493 1494 1499 1517\n",
      " 1519 1526 1527 1530 1533 1539 1544 1553 1559 1562 1573 1574 1575 1587\n",
      " 1591 1594 1600 1602 1606 1607 1608 1610 1611 1624 1630 1644 1645 1651\n",
      " 1667 1668 1671 1672 1673 1680 1685 1687 1692 1702 1704 1709 1714 1716\n",
      " 1719 1720 1722 1724 1725 1733 1735 1736 1738 1749 1754 1757 1759 1761\n",
      " 1763 1766 1768 1771 1781 1782 1801 1806 1810 1812 1813 1823 1838 1840\n",
      " 1843 1850 1853 1857 1861 1863 1869 1870 1881 1888 1893 1896 1897 1904\n",
      " 1905 1909 1910 1911 1914 1915 1926 1928 1932 1938 1947 1949 1951 1968\n",
      " 1971 1973 1980 1982 1989 1991 1992 1997]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5980 - acc: 0.1533\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.5318 - acc: 0.1686\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.5196 - acc: 0.1740\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.5107 - acc: 0.1779\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5042 - acc: 0.1809\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5005 - acc: 0.1826\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4976 - acc: 0.1836\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4952 - acc: 0.1848\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4906 - acc: 0.1867\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4881 - acc: 0.1881\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4873 - acc: 0.1884\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4818 - acc: 0.1908\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4803 - acc: 0.1914\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4775 - acc: 0.1925\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4761 - acc: 0.1930\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4707 - acc: 0.1953\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4623 - acc: 0.1986\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4560 - acc: 0.2015\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4517 - acc: 0.2030\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4489 - acc: 0.2040\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4484 - acc: 0.2040\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4445 - acc: 0.2059\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4427 - acc: 0.2064\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4406 - acc: 0.2073\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4396 - acc: 0.2075\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4376 - acc: 0.2081\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4336 - acc: 0.2097\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4338 - acc: 0.2095\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4302 - acc: 0.2110\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4279 - acc: 0.2118\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4268 - acc: 0.2122\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4250 - acc: 0.2127\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4227 - acc: 0.2139\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4201 - acc: 0.2146\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4188 - acc: 0.2148\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4180 - acc: 0.2153\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4166 - acc: 0.2158\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4131 - acc: 0.2172\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4108 - acc: 0.2175\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4087 - acc: 0.2185\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4068 - acc: 0.2193\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4047 - acc: 0.2198\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4025 - acc: 0.2206\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4047 - acc: 0.2196\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3995 - acc: 0.2216\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3980 - acc: 0.2221\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3943 - acc: 0.2232\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3929 - acc: 0.2238\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3912 - acc: 0.2241\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3891 - acc: 0.2248\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3884 - acc: 0.2250\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3869 - acc: 0.2256\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3835 - acc: 0.2269\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3819 - acc: 0.2272\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3809 - acc: 0.2275\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3796 - acc: 0.2278\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3765 - acc: 0.2289\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3776 - acc: 0.2287\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3744 - acc: 0.2297\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3725 - acc: 0.2304\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3706 - acc: 0.2308\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3696 - acc: 0.2313\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3674 - acc: 0.2320\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3657 - acc: 0.2325\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3662 - acc: 0.2323\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3637 - acc: 0.2329\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3614 - acc: 0.2338\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3614 - acc: 0.2338\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3602 - acc: 0.2340\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3584 - acc: 0.2348\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3571 - acc: 0.2352\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3549 - acc: 0.2360 2s - loss: 0.358\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3536 - acc: 0.2363\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3527 - acc: 0.2367\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3512 - acc: 0.2370\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3499 - acc: 0.2372\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3499 - acc: 0.2374\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3477 - acc: 0.2382\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3467 - acc: 0.2384\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3453 - acc: 0.2391\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3440 - acc: 0.2394\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3428 - acc: 0.2397\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3417 - acc: 0.2403\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3411 - acc: 0.2403\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3400 - acc: 0.2408\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3388 - acc: 0.2410\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3366 - acc: 0.2418\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3361 - acc: 0.2418\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3354 - acc: 0.2422\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3351 - acc: 0.2423\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3343 - acc: 0.2425\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3324 - acc: 0.2431\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3313 - acc: 0.2435\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3299 - acc: 0.2438\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3292 - acc: 0.2444\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3286 - acc: 0.2445\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3276 - acc: 0.2447\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3258 - acc: 0.2450\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3258 - acc: 0.2451\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3240 - acc: 0.2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1297\n",
      "           1       0.64      0.69      0.66     22841\n",
      "           2       0.32      0.20      0.25      3958\n",
      "           3       0.74      0.81      0.78     35152\n",
      "           4       0.47      0.25      0.33       802\n",
      "           5       0.45      0.57      0.50     21031\n",
      "           6       0.38      0.08      0.13      9472\n",
      "           7       0.40      0.39      0.40     12154\n",
      "\n",
      "    accuracy                           0.59    106707\n",
      "   macro avg       0.42      0.38      0.38    106707\n",
      "weighted avg       0.56      0.59      0.57    106707\n",
      "\n",
      "Acur√°cia\n",
      "0.3753882741898955\n",
      "Precisao\n",
      "0.564494727661482\n",
      "Recall\n",
      "0.5895958090846899\n",
      "F1\n",
      "0.5656386043680274\n",
      "[[    0   319    28   144     2   654    17   133]\n",
      " [    0 15869   212  1964     8  3618   166  1004]\n",
      " [    0   513   808   900    16  1008    78   635]\n",
      " [    0  1845   486 28593   148  2408    92  1580]\n",
      " [    0    63     3   437   203    51     0    45]\n",
      " [    0  3671   378  2589    10 11946   499  1938]\n",
      " [    0  1341   237  1253    12  4163   753  1713]\n",
      " [    0  1265   395  2552    33  2767   400  4742]]\n",
      "TRAIN: [   0    1    2 ... 1996 1997 1999] TEST: [   6   11   23   27   28   29   33   38   48   50   53   54   55   65\n",
      "   69   76   77   78   81   87   91  101  103  107  112  117  123  139\n",
      "  143  145  147  148  155  168  176  181  184  189  191  195  198  209\n",
      "  215  220  221  238  245  250  251  252  257  261  264  269  272  285\n",
      "  287  290  294  295  296  297  298  302  306  307  308  325  335  337\n",
      "  342  347  348  351  364  369  377  380  393  395  397  401  409  418\n",
      "  419  426  431  443  444  450  459  464  466  474  475  492  493  494\n",
      "  499  501  506  509  510  512  518  523  526  529  532  533  536  553\n",
      "  556  568  570  577  590  592  598  604  606  607  608  609  610  612\n",
      "  620  623  628  632  635  638  643  652  664  665  666  667  674  685\n",
      "  686  696  698  699  700  701  705  709  710  715  728  731  732  734\n",
      "  742  743  749  752  758  760  761  769  770  776  779  789  793  794\n",
      "  797  807  811  813  814  815  817  818  821  822  824  826  828  830\n",
      "  835  845  846  847  849  857  862  867  873  898  919  922  923  924\n",
      "  925  928  929  931  936  949  967  972  973  975  977  991  992  999\n",
      " 1008 1012 1013 1019 1022 1028 1048 1053 1055 1056 1061 1063 1065 1066\n",
      " 1072 1076 1077 1080 1081 1083 1094 1100 1101 1110 1131 1134 1136 1138\n",
      " 1140 1145 1148 1149 1156 1164 1198 1203 1204 1206 1209 1210 1212 1214\n",
      " 1216 1217 1220 1222 1223 1227 1228 1232 1233 1242 1246 1247 1258 1268\n",
      " 1270 1271 1274 1275 1276 1279 1281 1302 1311 1317 1319 1321 1324 1326\n",
      " 1328 1342 1347 1350 1353 1362 1375 1381 1383 1390 1395 1398 1403 1404\n",
      " 1408 1418 1419 1425 1431 1432 1435 1444 1446 1450 1451 1453 1468 1469\n",
      " 1473 1478 1479 1496 1501 1505 1507 1509 1511 1523 1529 1531 1534 1550\n",
      " 1560 1567 1572 1578 1580 1583 1589 1592 1595 1596 1605 1614 1617 1621\n",
      " 1622 1623 1626 1641 1653 1658 1669 1670 1675 1676 1677 1679 1683 1698\n",
      " 1703 1705 1707 1711 1715 1734 1742 1747 1760 1764 1765 1774 1775 1786\n",
      " 1788 1789 1809 1811 1815 1821 1822 1826 1828 1830 1856 1862 1880 1882\n",
      " 1886 1890 1898 1906 1908 1917 1922 1925 1927 1929 1934 1936 1939 1942\n",
      " 1956 1962 1966 1977 1983 1986 1993 1998]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 7s 5ms/sample - loss: 0.6035 - acc: 0.1557\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5366 - acc: 0.1719\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5272 - acc: 0.1764\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5171 - acc: 0.1808\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5117 - acc: 0.1829\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5077 - acc: 0.1847\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5039 - acc: 0.1866\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5004 - acc: 0.1880\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4983 - acc: 0.1890\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4933 - acc: 0.1913\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4906 - acc: 0.1925\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4892 - acc: 0.1931\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4862 - acc: 0.1944\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4832 - acc: 0.1958\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4856 - acc: 0.1945\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4800 - acc: 0.1971\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4789 - acc: 0.1973\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4771 - acc: 0.1980\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4713 - acc: 0.2008\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4697 - acc: 0.2014\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4606 - acc: 0.2051\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4529 - acc: 0.2082\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4504 - acc: 0.2088\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4472 - acc: 0.2104\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4470 - acc: 0.2101\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4446 - acc: 0.2111\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4405 - acc: 0.2123\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4419 - acc: 0.2117\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4361 - acc: 0.2143\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4362 - acc: 0.2139\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4339 - acc: 0.2150\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4313 - acc: 0.2158\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4301 - acc: 0.2163\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4272 - acc: 0.2170\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4250 - acc: 0.2181\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4232 - acc: 0.2186\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4220 - acc: 0.2192\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4191 - acc: 0.2200\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4178 - acc: 0.2204\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4155 - acc: 0.2210\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4145 - acc: 0.2214\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4123 - acc: 0.2225\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4115 - acc: 0.2225\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4087 - acc: 0.2235\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4063 - acc: 0.2243\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4057 - acc: 0.2244\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4032 - acc: 0.2251\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4005 - acc: 0.2264 1s - loss: 0.3949 \n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3989 - acc: 0.2270\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3978 - acc: 0.2270\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3945 - acc: 0.2285\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3938 - acc: 0.2285\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3916 - acc: 0.2292\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3906 - acc: 0.2294\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3891 - acc: 0.2301\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3874 - acc: 0.2306\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3840 - acc: 0.2313\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3818 - acc: 0.2324\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3811 - acc: 0.2327\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3793 - acc: 0.2332\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3782 - acc: 0.2334\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3786 - acc: 0.2333\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3781 - acc: 0.2332\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3740 - acc: 0.2350\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3710 - acc: 0.2357\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3701 - acc: 0.2362\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3684 - acc: 0.2365\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3671 - acc: 0.2370\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3654 - acc: 0.2376\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3642 - acc: 0.2379\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3626 - acc: 0.2384\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3617 - acc: 0.2386\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3602 - acc: 0.2392\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3594 - acc: 0.2394\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3569 - acc: 0.2400\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3553 - acc: 0.2410\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3548 - acc: 0.2407\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3551 - acc: 0.2404\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3593 - acc: 0.2395\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3520 - acc: 0.2419\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3495 - acc: 0.2425\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3492 - acc: 0.2427\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3476 - acc: 0.2431\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3469 - acc: 0.2433\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3445 - acc: 0.2443\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3446 - acc: 0.2439\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3431 - acc: 0.2447\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3420 - acc: 0.2449\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3412 - acc: 0.2453\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3401 - acc: 0.2454\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3393 - acc: 0.2457\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3380 - acc: 0.2462\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3375 - acc: 0.2461\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3366 - acc: 0.2467\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3351 - acc: 0.2471\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3337 - acc: 0.2478\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3339 - acc: 0.2474\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3328 - acc: 0.2476\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3309 - acc: 0.2485\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3302 - acc: 0.2486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1280\n",
      "           1       0.61      0.71      0.66     21721\n",
      "           2       0.36      0.17      0.23      4130\n",
      "           3       0.74      0.82      0.78     32506\n",
      "           4       0.53      0.30      0.38       641\n",
      "           5       0.46      0.56      0.50     20587\n",
      "           6       0.36      0.08      0.13      8834\n",
      "           7       0.41      0.37      0.39     11404\n",
      "\n",
      "    accuracy                           0.59    101103\n",
      "   macro avg       0.43      0.38      0.38    101103\n",
      "weighted avg       0.56      0.59      0.56    101103\n",
      "\n",
      "Acur√°cia\n",
      "0.37631766991908217\n",
      "Precisao\n",
      "0.5573788482964762\n",
      "Recall\n",
      "0.5872328219736308\n",
      "F1\n",
      "0.5602100805680948\n",
      "[[    0   338    18   146     3   633    29   113]\n",
      " [    0 15401   142  2003    21  3190   160   804]\n",
      " [    0   609   705   937     5  1157    68   649]\n",
      " [    0  1889   342 26559   112  2187   120  1297]\n",
      " [    0    36     6   339   193    42     1    24]\n",
      " [    0  4014   314  2467    17 11580   469  1726]\n",
      " [    0  1538   149  1188     7  3865   690  1397]\n",
      " [    0  1437   303  2309     8  2718   386  4243]]\n",
      "TRAIN: [   0    1    6 ... 1997 1998 1999] TEST: [   2    3    4    5   10   12   24   26   30   31   34   35   37   43\n",
      "   60   67   68   75   85   89   92   95  105  111  121  122  127  131\n",
      "  134  149  151  164  165  174  185  188  190  196  205  208  212  217\n",
      "  219  223  224  236  243  265  266  279  284  288  289  313  321  322\n",
      "  324  327  329  330  334  340  341  350  352  361  366  372  375  378\n",
      "  382  396  411  413  420  423  427  430  442  445  448  452  455  457\n",
      "  467  495  498  500  503  517  519  522  525  528  534  537  538  539\n",
      "  542  546  554  558  559  560  563  566  572  581  582  594  597  599\n",
      "  600  602  613  615  617  619  621  627  631  636  646  648  653  657\n",
      "  659  671  673  675  676  682  683  684  687  689  692  704  708  725\n",
      "  730  736  737  739  746  759  762  764  767  768  772  775  777  784\n",
      "  790  799  800  804  810  816  820  834  837  838  842  844  850  851\n",
      "  864  866  869  871  872  875  878  886  888  889  892  895  900  901\n",
      "  904  905  912  914  915  916  926  930  933  934  941  947  952  957\n",
      "  960  962  965  966  968  982  988 1004 1010 1015 1016 1017 1023 1027\n",
      " 1029 1044 1045 1052 1054 1058 1062 1070 1091 1095 1104 1107 1119 1121\n",
      " 1129 1143 1155 1157 1162 1163 1168 1171 1172 1174 1175 1176 1185 1186\n",
      " 1191 1192 1194 1205 1221 1226 1229 1239 1240 1252 1255 1256 1262 1264\n",
      " 1265 1266 1267 1278 1282 1285 1290 1295 1296 1300 1301 1303 1309 1313\n",
      " 1314 1322 1323 1333 1337 1344 1346 1349 1352 1355 1364 1368 1371 1374\n",
      " 1378 1384 1385 1388 1392 1393 1407 1413 1416 1417 1420 1423 1426 1433\n",
      " 1437 1439 1441 1442 1445 1449 1452 1456 1459 1470 1482 1486 1487 1503\n",
      " 1513 1516 1536 1541 1542 1545 1548 1551 1556 1557 1568 1570 1579 1581\n",
      " 1585 1588 1598 1599 1603 1609 1612 1616 1627 1628 1629 1631 1633 1634\n",
      " 1635 1639 1640 1642 1648 1652 1654 1657 1678 1684 1689 1690 1694 1721\n",
      " 1729 1741 1745 1748 1751 1758 1762 1769 1772 1776 1778 1784 1790 1793\n",
      " 1795 1799 1803 1819 1829 1834 1836 1839 1845 1849 1859 1860 1864 1865\n",
      " 1872 1884 1894 1916 1919 1921 1933 1944 1950 1952 1957 1961 1965 1970\n",
      " 1974 1975 1976 1978 1984 1987 1994 1996]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5975 - acc: 0.1579\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5366 - acc: 0.1702\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5247 - acc: 0.1756\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5173 - acc: 0.1794\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5111 - acc: 0.1813\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.5090 - acc: 0.1825\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.5047 - acc: 0.1844\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4999 - acc: 0.1865\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4934 - acc: 0.1898\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4939 - acc: 0.1894\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4883 - acc: 0.1919\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4871 - acc: 0.1926\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4824 - acc: 0.1949\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4802 - acc: 0.1959\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4770 - acc: 0.1968\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4675 - acc: 0.2006\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4626 - acc: 0.2025\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4602 - acc: 0.2038\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4578 - acc: 0.2045\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4567 - acc: 0.2051\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4513 - acc: 0.2072\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4486 - acc: 0.2081\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4476 - acc: 0.2086\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4439 - acc: 0.2098\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4426 - acc: 0.2103\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4406 - acc: 0.2112\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4416 - acc: 0.2104\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4372 - acc: 0.2122\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4358 - acc: 0.2128\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4327 - acc: 0.2139\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4310 - acc: 0.2144\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4297 - acc: 0.2150\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4270 - acc: 0.2158\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4254 - acc: 0.2164\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4234 - acc: 0.2173\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4213 - acc: 0.2178\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4210 - acc: 0.2175\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4184 - acc: 0.2186\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4160 - acc: 0.2192\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4151 - acc: 0.2199\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4129 - acc: 0.2202\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4103 - acc: 0.2214\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4089 - acc: 0.2219\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4066 - acc: 0.2227\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.4057 - acc: 0.2229\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4031 - acc: 0.2239\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.4012 - acc: 0.2243\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3994 - acc: 0.2248\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3979 - acc: 0.2254\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3953 - acc: 0.2263\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3936 - acc: 0.2269\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3934 - acc: 0.2268\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3899 - acc: 0.2279\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3885 - acc: 0.2287\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3881 - acc: 0.2286\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3846 - acc: 0.2300\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3844 - acc: 0.2299\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3821 - acc: 0.2305\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3793 - acc: 0.2316\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3788 - acc: 0.2317\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3774 - acc: 0.2321\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3756 - acc: 0.2329\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3744 - acc: 0.2330\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3725 - acc: 0.2338\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3708 - acc: 0.2341\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3704 - acc: 0.2347\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3683 - acc: 0.2349\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3658 - acc: 0.2360\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3665 - acc: 0.2357\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3650 - acc: 0.2363\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3628 - acc: 0.2367\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3629 - acc: 0.2368\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3584 - acc: 0.2382\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3575 - acc: 0.2385\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3578 - acc: 0.2383\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3557 - acc: 0.2391\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3538 - acc: 0.2395\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3523 - acc: 0.2400\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3508 - acc: 0.2405\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3501 - acc: 0.2411\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3491 - acc: 0.2411\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3472 - acc: 0.2418\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3464 - acc: 0.2419\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3450 - acc: 0.2424\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3447 - acc: 0.2427\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3441 - acc: 0.2429\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3422 - acc: 0.2434\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3402 - acc: 0.2440\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3404 - acc: 0.2441\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3394 - acc: 0.2442\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3374 - acc: 0.2451\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3370 - acc: 0.2451\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3351 - acc: 0.2458\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3353 - acc: 0.2458\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3336 - acc: 0.2462\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3326 - acc: 0.2465\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3317 - acc: 0.2468\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3304 - acc: 0.2471\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3300 - acc: 0.2471\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3286 - acc: 0.2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\gabriel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1202\n",
      "           1       0.63      0.67      0.65     21496\n",
      "           2       0.29      0.18      0.22      4004\n",
      "           3       0.71      0.83      0.76     33989\n",
      "           4       0.37      0.18      0.25       633\n",
      "           5       0.46      0.52      0.49     20741\n",
      "           6       0.35      0.08      0.13      9029\n",
      "           7       0.39      0.39      0.39     11704\n",
      "\n",
      "    accuracy                           0.58    102798\n",
      "   macro avg       0.40      0.36      0.36    102798\n",
      "weighted avg       0.55      0.58      0.55    102798\n",
      "\n",
      "Acur√°cia\n",
      "0.35640734643314465\n",
      "Precisao\n",
      "0.5459662466787327\n",
      "Recall\n",
      "0.5775501468900173\n",
      "F1\n",
      "0.5515023547530675\n",
      "[[    0   275    43   214     3   525    38   104]\n",
      " [    0 14300   222  2528    26  3266   157   997]\n",
      " [    0   422   722  1215     9   889    69   678]\n",
      " [    0  1849   389 28049    90  2020   116  1476]\n",
      " [    0    44    14   360   117    52     5    41]\n",
      " [    0  3515   442  3104    34 10876   598  2172]\n",
      " [    0  1260   216  1527    16  3586   704  1720]\n",
      " [    0  1149   470  2716    20  2411   335  4603]]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_10 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 700, 8)            1608      \n",
      "=================================================================\n",
      "Total params: 256,008\n",
      "Trainable params: 256,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acur√°cias total\n",
      "[0.3533836230186679, 0.36166590086146255, 0.3753882741898955, 0.37631766991908217, 0.35640734643314465]\n",
      "0.36463256288445056\n",
      "Precision total\n",
      "[0.5486815803234427, 0.5537145072477215, 0.564494727661482, 0.5573788482964762, 0.5459662466787327]\n",
      "0.5540471820415711\n",
      "Recalls total\n",
      "[0.5737306624355415, 0.5799060942889996, 0.5895958090846899, 0.5872328219736308, 0.5775501468900173]\n",
      "0.5816031069345758\n",
      "F1 total\n",
      "[0.5491236727586929, 0.555684997486796, 0.5656386043680274, 0.5602100805680948, 0.5515023547530675]\n",
      "0.5564319419869357\n",
      "TRAIN: [   0    1    2 ... 1997 1998 1999] TEST: [  10   23   28   31   40   49   52   78   79   83   86   89   94   96\n",
      "  114  120  124  131  143  151  162  163  166  168  169  173  176  185\n",
      "  188  193  194  206  211  239  240  246  248  262  263  264  267  268\n",
      "  269  300  314  319  322  323  330  334  345  351  355  361  369  372\n",
      "  374  378  381  394  403  406  407  409  411  416  418  421  424  425\n",
      "  428  429  434  438  446  450  457  459  463  464  469  475  477  478\n",
      "  479  481  483  484  488  497  501  503  506  510  511  514  516  518\n",
      "  519  521  522  528  536  538  543  551  567  570  572  573  576  577\n",
      "  582  584  607  610  611  614  620  627  634  635  640  645  654  660\n",
      "  666  674  677  680  689  691  694  696  698  699  707  708  712  714\n",
      "  750  759  763  764  767  769  774  783  785  791  800  801  804  808\n",
      "  809  814  819  821  825  826  829  831  851  857  859  866  870  872\n",
      "  879  888  890  891  892  894  896  900  902  911  918  932  934  941\n",
      "  947  952  955  956  959  971  972  976 1002 1004 1011 1014 1015 1021\n",
      " 1025 1026 1028 1037 1039 1043 1048 1049 1052 1060 1062 1070 1073 1078\n",
      " 1088 1100 1104 1108 1109 1122 1125 1129 1139 1143 1158 1161 1165 1168\n",
      " 1170 1177 1180 1185 1187 1189 1191 1196 1201 1212 1215 1221 1222 1230\n",
      " 1231 1232 1242 1248 1252 1271 1275 1277 1285 1289 1295 1299 1305 1306\n",
      " 1307 1311 1314 1318 1324 1325 1327 1328 1334 1341 1350 1351 1355 1366\n",
      " 1370 1371 1374 1386 1388 1391 1394 1408 1409 1410 1416 1435 1438 1442\n",
      " 1443 1445 1450 1451 1454 1455 1463 1465 1474 1479 1481 1487 1501 1503\n",
      " 1504 1515 1523 1524 1525 1528 1529 1533 1534 1537 1549 1565 1566 1573\n",
      " 1580 1590 1592 1597 1599 1605 1607 1612 1617 1619 1624 1626 1633 1639\n",
      " 1646 1650 1652 1656 1658 1664 1666 1671 1672 1673 1682 1683 1685 1688\n",
      " 1697 1703 1706 1707 1710 1711 1715 1716 1726 1732 1739 1741 1750 1754\n",
      " 1758 1761 1764 1774 1779 1780 1782 1783 1786 1789 1809 1817 1823 1831\n",
      " 1843 1850 1853 1855 1856 1858 1861 1867 1878 1880 1882 1884 1885 1895\n",
      " 1899 1901 1907 1908 1915 1919 1920 1927 1928 1937 1941 1943 1948 1959\n",
      " 1963 1965 1968 1975 1977 1985 1988 1990]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 7s 5ms/sample - loss: 0.3364 - acc: 0.8406\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3112 - acc: 0.8589\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3064 - acc: 0.8619\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3007 - acc: 0.8655\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2988 - acc: 0.8665\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2959 - acc: 0.8681\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2929 - acc: 0.8699\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2928 - acc: 0.8699\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2880 - acc: 0.8725\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2876 - acc: 0.8725\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2849 - acc: 0.8735\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2854 - acc: 0.8739\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2816 - acc: 0.8754\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2819 - acc: 0.8756\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2786 - acc: 0.8766\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2775 - acc: 0.8782\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2778 - acc: 0.8777\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2762 - acc: 0.8788\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2727 - acc: 0.8803\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2681 - acc: 0.8829\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2618 - acc: 0.8860\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2581 - acc: 0.8878\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2573 - acc: 0.8885\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2592 - acc: 0.8879\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2567 - acc: 0.8887\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2546 - acc: 0.8901\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2516 - acc: 0.8917\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2495 - acc: 0.8926\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2492 - acc: 0.8925\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2468 - acc: 0.8937\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2460 - acc: 0.8941\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2442 - acc: 0.8950\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2456 - acc: 0.8945\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2432 - acc: 0.8958\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2412 - acc: 0.8962\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2395 - acc: 0.8972\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2380 - acc: 0.8979\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2365 - acc: 0.8986\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2355 - acc: 0.8991\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2351 - acc: 0.8994\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2336 - acc: 0.9000\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2313 - acc: 0.9009\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2313 - acc: 0.9008\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2288 - acc: 0.9020\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2272 - acc: 0.9027\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2257 - acc: 0.9033\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2250 - acc: 0.9038\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2237 - acc: 0.9042\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2226 - acc: 0.9048\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2207 - acc: 0.9056\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2201 - acc: 0.9059\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2185 - acc: 0.9064\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2164 - acc: 0.9073\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2153 - acc: 0.9083\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2142 - acc: 0.9087\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2134 - acc: 0.9087\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2109 - acc: 0.9102\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2098 - acc: 0.9105\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2079 - acc: 0.9115\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2060 - acc: 0.9122\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.2044 - acc: 0.9132\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2037 - acc: 0.9134\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.2038 - acc: 0.9132\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2024 - acc: 0.9137\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2000 - acc: 0.9147\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1985 - acc: 0.9154\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1968 - acc: 0.9164\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1959 - acc: 0.9166\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1949 - acc: 0.9170\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1942 - acc: 0.9175\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1926 - acc: 0.9182\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.1916 - acc: 0.9186\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1909 - acc: 0.9192\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1893 - acc: 0.9198\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1880 - acc: 0.9198\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1881 - acc: 0.9202\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1863 - acc: 0.9210\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1841 - acc: 0.9221\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1832 - acc: 0.9222\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1817 - acc: 0.9230\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1813 - acc: 0.9231\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1801 - acc: 0.9235\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1789 - acc: 0.9243\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1805 - acc: 0.9237\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1778 - acc: 0.9251\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1757 - acc: 0.9256\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1751 - acc: 0.9261\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1741 - acc: 0.9266\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1740 - acc: 0.9265\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1724 - acc: 0.9274\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1708 - acc: 0.9282\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1696 - acc: 0.9286\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1694 - acc: 0.9287\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1687 - acc: 0.9289\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1672 - acc: 0.9296\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1666 - acc: 0.9298\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1658 - acc: 0.9301\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1652 - acc: 0.9303\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1641 - acc: 0.9308\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1630 - acc: 0.9318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71     44077\n",
      "           1       0.68      0.61      0.64     23634\n",
      "           2       0.75      0.76      0.76     38928\n",
      "\n",
      "    accuracy                           0.71    106639\n",
      "   macro avg       0.71      0.70      0.70    106639\n",
      "weighted avg       0.71      0.71      0.71    106639\n",
      "\n",
      "Acur√°cia\n",
      "0.6979474552411494\n",
      "Precisao\n",
      "0.711873726087341\n",
      "Recall\n",
      "0.7123753973686925\n",
      "F1\n",
      "0.7114571025535659\n",
      "[[31945  4965  7167]\n",
      " [ 6758 14331  2545]\n",
      " [ 7520  1717 29691]]\n",
      "TRAIN: [   0    3    6 ... 1997 1998 1999] TEST: [   1    2    4    5    8   16   20   21   24   32   35   37   41   44\n",
      "   62   81   93  105  107  108  112  113  119  121  127  130  142  147\n",
      "  156  157  170  171  180  191  196  200  204  205  220  223  227  230\n",
      "  232  238  241  245  256  259  271  278  286  287  292  297  303  315\n",
      "  317  320  327  328  331  337  342  346  349  353  363  371  386  387\n",
      "  390  395  404  414  420  431  433  437  447  451  452  454  460  472\n",
      "  474  482  486  495  512  515  526  529  548  562  566  569  578  581\n",
      "  590  591  594  599  603  604  608  615  618  622  624  629  630  639\n",
      "  643  651  653  659  668  669  673  675  683  687  692  693  703  709\n",
      "  719  722  724  725  727  735  736  738  740  741  746  747  751  753\n",
      "  754  758  760  762  771  773  775  779  782  786  789  790  796  797\n",
      "  799  805  812  813  838  839  842  847  849  850  853  856  858  864\n",
      "  874  876  886  897  904  910  913  914  916  917  919  920  921  937\n",
      "  940  946  949  958  975  980  983  984  985  987  994 1008 1009 1012\n",
      " 1017 1022 1023 1030 1031 1032 1034 1040 1042 1044 1046 1051 1056 1058\n",
      " 1074 1083 1091 1095 1099 1105 1106 1111 1113 1114 1128 1134 1147 1148\n",
      " 1152 1154 1157 1159 1160 1166 1169 1172 1184 1186 1188 1192 1194 1198\n",
      " 1199 1200 1207 1219 1220 1229 1233 1235 1236 1251 1253 1255 1256 1260\n",
      " 1263 1265 1268 1269 1272 1278 1281 1284 1297 1302 1316 1323 1326 1330\n",
      " 1337 1348 1357 1359 1373 1378 1379 1380 1381 1390 1397 1398 1401 1402\n",
      " 1403 1404 1405 1406 1417 1418 1421 1423 1426 1427 1430 1431 1432 1434\n",
      " 1436 1437 1444 1457 1458 1470 1471 1473 1478 1483 1494 1495 1497 1506\n",
      " 1518 1520 1530 1535 1541 1543 1546 1550 1553 1560 1570 1572 1576 1578\n",
      " 1586 1588 1589 1608 1610 1622 1625 1629 1634 1636 1637 1638 1640 1641\n",
      " 1642 1655 1662 1678 1699 1700 1705 1714 1718 1722 1725 1733 1735 1743\n",
      " 1749 1757 1762 1763 1778 1781 1784 1788 1796 1798 1802 1807 1813 1815\n",
      " 1818 1820 1833 1834 1838 1851 1857 1862 1868 1871 1872 1874 1889 1890\n",
      " 1894 1904 1906 1910 1911 1917 1926 1929 1935 1936 1942 1945 1946 1949\n",
      " 1960 1961 1964 1967 1981 1984 1993 1995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3448 - acc: 0.8356\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3178 - acc: 0.8556\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3115 - acc: 0.8593\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3064 - acc: 0.8622\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3030 - acc: 0.8646\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3001 - acc: 0.8654\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2983 - acc: 0.8666\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2987 - acc: 0.8645\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2946 - acc: 0.8683\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2923 - acc: 0.8693\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2925 - acc: 0.8697\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2910 - acc: 0.8699\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2883 - acc: 0.8707\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2861 - acc: 0.8719\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2857 - acc: 0.8719\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2842 - acc: 0.8729\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2817 - acc: 0.8745\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2803 - acc: 0.8751\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2786 - acc: 0.8758\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2754 - acc: 0.8777\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2712 - acc: 0.8803\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2657 - acc: 0.8839\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2614 - acc: 0.8859\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2584 - acc: 0.8873\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2569 - acc: 0.8883\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2575 - acc: 0.8876\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2542 - acc: 0.8893\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2524 - acc: 0.8899\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2505 - acc: 0.8911\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2490 - acc: 0.8921\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2487 - acc: 0.8918\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2467 - acc: 0.8933\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2454 - acc: 0.8937\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2435 - acc: 0.8944\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2426 - acc: 0.8952\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2434 - acc: 0.8943\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2396 - acc: 0.8966\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2383 - acc: 0.8966\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2369 - acc: 0.8977\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2348 - acc: 0.8984\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2345 - acc: 0.8990\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2325 - acc: 0.8998 1s - loss: 0.2365 - \n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2308 - acc: 0.9006\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2302 - acc: 0.9012\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2284 - acc: 0.9016\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2271 - acc: 0.9023\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2261 - acc: 0.9027\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2245 - acc: 0.9034\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2225 - acc: 0.9041\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2215 - acc: 0.9047\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2200 - acc: 0.9050\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2197 - acc: 0.9052\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2179 - acc: 0.9067\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2152 - acc: 0.9077\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2133 - acc: 0.9083\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2125 - acc: 0.9081\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2117 - acc: 0.9083\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2105 - acc: 0.9092\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2081 - acc: 0.9097\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2071 - acc: 0.9099\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2056 - acc: 0.9106\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2040 - acc: 0.9114\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2036 - acc: 0.9114\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2014 - acc: 0.9120\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2001 - acc: 0.9129\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2000 - acc: 0.9127\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1977 - acc: 0.9138\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1971 - acc: 0.9141\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1971 - acc: 0.9140\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1940 - acc: 0.9154\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.1933 - acc: 0.9157\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1915 - acc: 0.9161\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1901 - acc: 0.9168\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.1895 - acc: 0.9172\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1882 - acc: 0.9174\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1889 - acc: 0.9171\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1869 - acc: 0.9179\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1854 - acc: 0.9183\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1843 - acc: 0.9194\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1826 - acc: 0.9199 1s - loss: 0.184\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1817 - acc: 0.9197\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1809 - acc: 0.9205\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1799 - acc: 0.9212\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1795 - acc: 0.9209\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1777 - acc: 0.9218\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1774 - acc: 0.9220\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1762 - acc: 0.9220\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1750 - acc: 0.9227\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1754 - acc: 0.9227\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1739 - acc: 0.9232\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1721 - acc: 0.9236\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1720 - acc: 0.9240\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1704 - acc: 0.9246\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1701 - acc: 0.9248\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1693 - acc: 0.9253\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1681 - acc: 0.9258\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1674 - acc: 0.9262\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1673 - acc: 0.9262\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1658 - acc: 0.9266\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1649 - acc: 0.9271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71     40989\n",
      "           1       0.69      0.59      0.64     22058\n",
      "           2       0.76      0.75      0.76     37371\n",
      "\n",
      "    accuracy                           0.71    100418\n",
      "   macro avg       0.71      0.69      0.70    100418\n",
      "weighted avg       0.71      0.71      0.71    100418\n",
      "\n",
      "Acur√°cia\n",
      "0.6942246371172912\n",
      "Precisao\n",
      "0.7119109779225922\n",
      "Recall\n",
      "0.7111971957218826\n",
      "F1\n",
      "0.7102563950640972\n",
      "[[30232  4109  6648]\n",
      " [ 6835 13084  2139]\n",
      " [ 7474  1796 28101]]\n",
      "TRAIN: [   1    2    4 ... 1997 1998 1999] TEST: [   0    3    9   13   14   15   34   36   38   42   47   48   50   54\n",
      "   56   59   60   61   67   70   74   76   85   88   92   95   97   98\n",
      "  115  116  122  125  128  132  133  134  145  152  155  161  165  167\n",
      "  174  178  186  195  201  207  210  212  218  219  222  229  233  234\n",
      "  236  237  249  251  252  257  258  266  272  276  281  283  294  298\n",
      "  309  329  332  338  339  340  344  347  354  357  360  366  376  380\n",
      "  392  393  399  400  412  413  415  417  422  426  432  436  440  441\n",
      "  449  453  458  487  499  500  507  537  539  546  553  555  556  557\n",
      "  558  559  561  565  574  575  579  586  587  589  593  597  598  601\n",
      "  602  609  613  616  617  626  633  636  637  638  641  656  658  664\n",
      "  671  679  681  684  685  688  690  701  704  713  715  716  720  721\n",
      "  726  729  737  742  748  752  755  772  784  792  793  803  806  810\n",
      "  817  828  833  835  836  837  841  846  865  867  869  871  873  881\n",
      "  883  884  887  893  895  901  905  912  922  923  924  928  938  945\n",
      "  948  954  957  961  967  970  981  988  997 1001 1005 1007 1018 1019\n",
      " 1020 1027 1033 1045 1050 1053 1055 1059 1063 1065 1072 1080 1082 1087\n",
      " 1090 1093 1094 1101 1124 1127 1130 1137 1138 1144 1146 1150 1155 1171\n",
      " 1175 1182 1190 1193 1202 1211 1213 1214 1227 1228 1234 1241 1247 1249\n",
      " 1264 1273 1274 1276 1286 1303 1309 1315 1317 1319 1320 1321 1322 1335\n",
      " 1346 1354 1358 1362 1363 1364 1365 1372 1377 1382 1384 1392 1393 1400\n",
      " 1407 1412 1414 1415 1440 1449 1453 1456 1459 1464 1466 1469 1472 1480\n",
      " 1492 1502 1508 1512 1519 1526 1527 1540 1544 1545 1552 1561 1577 1582\n",
      " 1583 1585 1593 1598 1600 1601 1604 1606 1611 1618 1623 1643 1648 1660\n",
      " 1665 1667 1668 1674 1677 1679 1680 1684 1692 1693 1694 1695 1698 1702\n",
      " 1709 1712 1717 1719 1724 1728 1729 1730 1734 1737 1742 1744 1746 1748\n",
      " 1751 1753 1755 1767 1768 1769 1773 1775 1777 1785 1791 1793 1795 1797\n",
      " 1805 1810 1816 1821 1822 1824 1826 1828 1829 1832 1836 1854 1860 1876\n",
      " 1891 1892 1893 1896 1897 1900 1914 1916 1921 1922 1923 1925 1932 1938\n",
      " 1944 1950 1953 1957 1958 1970 1973 1976]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3418 - acc: 0.8258\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3151 - acc: 0.8569\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3095 - acc: 0.8606\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3047 - acc: 0.8633\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3013 - acc: 0.8648\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3003 - acc: 0.8658\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2974 - acc: 0.8671\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2944 - acc: 0.8692\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2939 - acc: 0.8686\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2911 - acc: 0.8703\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2894 - acc: 0.8709\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2876 - acc: 0.8716\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2863 - acc: 0.8718\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2843 - acc: 0.8728\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2832 - acc: 0.8736\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2843 - acc: 0.8729\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2815 - acc: 0.8744\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2826 - acc: 0.8741\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2780 - acc: 0.8765\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2792 - acc: 0.8761\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2768 - acc: 0.8770\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2721 - acc: 0.8794\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2668 - acc: 0.8818\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2615 - acc: 0.8846\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2591 - acc: 0.8861\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2578 - acc: 0.8870\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2548 - acc: 0.8881\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2556 - acc: 0.8880\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2526 - acc: 0.8894\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2511 - acc: 0.8899\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2486 - acc: 0.8914\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2468 - acc: 0.8920\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2459 - acc: 0.8925\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2432 - acc: 0.8936\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2438 - acc: 0.8934\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2415 - acc: 0.8949\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2396 - acc: 0.8954\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2381 - acc: 0.8962\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2364 - acc: 0.8970\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2342 - acc: 0.8976\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2336 - acc: 0.8980\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2313 - acc: 0.8987\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2330 - acc: 0.8982\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2288 - acc: 0.8999\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2266 - acc: 0.9011\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2250 - acc: 0.9013\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2238 - acc: 0.9022\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2232 - acc: 0.9025\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2217 - acc: 0.9027\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2201 - acc: 0.9036\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2182 - acc: 0.9046\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2163 - acc: 0.9052\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2165 - acc: 0.9049\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2146 - acc: 0.9064\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2129 - acc: 0.9067\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2105 - acc: 0.9077\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2106 - acc: 0.9077\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2090 - acc: 0.9079\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2074 - acc: 0.9090\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2054 - acc: 0.9097\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2053 - acc: 0.9097\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2045 - acc: 0.9098\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2025 - acc: 0.9109\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2012 - acc: 0.9114\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1997 - acc: 0.9122\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1990 - acc: 0.9125\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1973 - acc: 0.9134\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1963 - acc: 0.9136\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1949 - acc: 0.9145\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1940 - acc: 0.9149\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1934 - acc: 0.9154\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1939 - acc: 0.9156\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1916 - acc: 0.9164\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1894 - acc: 0.9174\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1887 - acc: 0.9176\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1874 - acc: 0.9177\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1861 - acc: 0.9185\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1854 - acc: 0.9188\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1851 - acc: 0.9190\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1850 - acc: 0.9194\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1833 - acc: 0.9203\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1817 - acc: 0.9209\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1811 - acc: 0.9214\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1802 - acc: 0.9219\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1789 - acc: 0.9225\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1773 - acc: 0.9229\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1764 - acc: 0.9237\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1766 - acc: 0.9238\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1754 - acc: 0.9242\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1754 - acc: 0.9242\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1740 - acc: 0.9248\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1729 - acc: 0.9252\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1726 - acc: 0.9251\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1711 - acc: 0.9264\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1700 - acc: 0.9266\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1699 - acc: 0.9264\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1693 - acc: 0.9276\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1686 - acc: 0.9279\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1686 - acc: 0.9278\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1668 - acc: 0.9285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71     41458\n",
      "           1       0.69      0.61      0.64     23064\n",
      "           2       0.77      0.77      0.77     37974\n",
      "\n",
      "    accuracy                           0.72    102496\n",
      "   macro avg       0.72      0.70      0.71    102496\n",
      "weighted avg       0.72      0.72      0.72    102496\n",
      "\n",
      "Acur√°cia\n",
      "0.7028501980986426\n",
      "Precisao\n",
      "0.7181858460851157\n",
      "Recall\n",
      "0.7180280206056822\n",
      "F1\n",
      "0.7171998858841575\n",
      "[[30538  4509  6411]\n",
      " [ 6806 13986  2272]\n",
      " [ 7047  1856 29071]]\n",
      "TRAIN: [   0    1    2 ... 1995 1998 1999] TEST: [   6   11   18   19   22   25   27   29   33   39   43   46   51   53\n",
      "   64   65   66   68   69   72   82   87   90   99  100  101  102  104\n",
      "  117  123  135  136  139  140  144  148  149  150  158  159  160  164\n",
      "  177  179  182  183  189  190  192  197  198  202  203  208  209  213\n",
      "  217  224  225  231  235  242  250  260  270  273  275  279  285  289\n",
      "  291  293  299  302  304  307  308  310  311  316  324  325  326  335\n",
      "  336  343  350  352  358  359  362  367  370  375  377  379  383  384\n",
      "  389  396  397  401  402  408  419  423  427  430  435  439  445  448\n",
      "  456  462  466  468  470  471  476  490  491  492  493  494  496  498\n",
      "  504  513  517  520  527  530  534  540  541  544  545  547  550  563\n",
      "  568  585  588  595  606  619  623  631  644  648  650  652  657  661\n",
      "  672  678  682  686  697  700  710  717  723  739  744  745  749  761\n",
      "  765  766  778  780  795  798  815  818  820  822  824  830  843  844\n",
      "  848  852  855  862  875  878  885  889  903  909  915  926  927  930\n",
      "  931  933  935  943  944  950  951  966  968  969  973  977  986  990\n",
      "  991  992  993  995  998  999 1003 1010 1013 1016 1029 1036 1038 1041\n",
      " 1047 1054 1057 1061 1064 1066 1071 1077 1081 1084 1086 1089 1092 1096\n",
      " 1110 1115 1117 1121 1123 1133 1135 1141 1142 1149 1153 1162 1167 1173\n",
      " 1174 1178 1181 1183 1195 1197 1204 1206 1208 1209 1210 1216 1218 1224\n",
      " 1226 1237 1245 1254 1261 1266 1270 1279 1293 1294 1296 1301 1312 1332\n",
      " 1333 1339 1342 1347 1349 1352 1353 1368 1369 1375 1376 1387 1396 1399\n",
      " 1413 1422 1428 1429 1439 1446 1452 1461 1467 1476 1484 1485 1496 1498\n",
      " 1513 1516 1517 1521 1531 1538 1548 1551 1554 1555 1557 1562 1563 1564\n",
      " 1567 1574 1575 1579 1584 1594 1595 1596 1603 1613 1614 1615 1621 1631\n",
      " 1645 1653 1663 1669 1676 1687 1689 1701 1704 1720 1727 1731 1740 1756\n",
      " 1759 1766 1770 1776 1787 1792 1794 1799 1801 1804 1814 1825 1830 1840\n",
      " 1845 1846 1847 1848 1849 1859 1866 1870 1873 1875 1881 1888 1898 1905\n",
      " 1912 1913 1924 1930 1931 1933 1934 1939 1940 1947 1952 1962 1972 1978\n",
      " 1979 1980 1983 1989 1992 1994 1996 1997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 7s 4ms/sample - loss: 0.3410 - acc: 0.8148\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3132 - acc: 0.8583\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3091 - acc: 0.8606\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3037 - acc: 0.8639\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.2996 - acc: 0.8663\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2956 - acc: 0.8685\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2950 - acc: 0.8687\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2941 - acc: 0.8690\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2892 - acc: 0.8715\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2888 - acc: 0.8714\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2860 - acc: 0.8726\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2842 - acc: 0.8735\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2837 - acc: 0.8738\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2807 - acc: 0.8749\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2820 - acc: 0.8748\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2817 - acc: 0.8746\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2793 - acc: 0.8762\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2762 - acc: 0.8771\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2741 - acc: 0.8783\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2731 - acc: 0.8788\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2707 - acc: 0.8810\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2668 - acc: 0.8828\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2616 - acc: 0.8852\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2604 - acc: 0.8859\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2566 - acc: 0.8877\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2550 - acc: 0.8886\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2539 - acc: 0.8893\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2520 - acc: 0.8904\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2503 - acc: 0.8916\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2485 - acc: 0.8922\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2471 - acc: 0.8928\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2447 - acc: 0.8943\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2435 - acc: 0.8946\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2434 - acc: 0.8947\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2408 - acc: 0.8960\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2397 - acc: 0.8963\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2392 - acc: 0.8966\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2379 - acc: 0.8970\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2352 - acc: 0.8984\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2350 - acc: 0.8989\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2330 - acc: 0.8997\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2318 - acc: 0.8998\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2296 - acc: 0.9014\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2274 - acc: 0.9023\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2270 - acc: 0.9024\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2251 - acc: 0.9034\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2241 - acc: 0.9032\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2226 - acc: 0.9044\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2211 - acc: 0.9050\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2190 - acc: 0.9054\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2195 - acc: 0.9056\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2174 - acc: 0.9068\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2146 - acc: 0.9080\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2131 - acc: 0.9085\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2115 - acc: 0.9093\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2106 - acc: 0.9096\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2094 - acc: 0.9102\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2075 - acc: 0.9111\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2059 - acc: 0.9117\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2043 - acc: 0.9123\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2032 - acc: 0.9125\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2026 - acc: 0.9133\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2008 - acc: 0.9141\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1983 - acc: 0.9151\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1984 - acc: 0.9152\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1974 - acc: 0.9158\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1951 - acc: 0.9168\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1938 - acc: 0.9174\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1937 - acc: 0.9177\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1926 - acc: 0.9183\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1901 - acc: 0.9192\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1891 - acc: 0.9196\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1885 - acc: 0.9196\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1871 - acc: 0.9204\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1849 - acc: 0.9214\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1836 - acc: 0.9217\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1827 - acc: 0.9224\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1820 - acc: 0.9227\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1808 - acc: 0.9234\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1806 - acc: 0.9235\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1795 - acc: 0.9237\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1784 - acc: 0.9245\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1777 - acc: 0.9244\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1759 - acc: 0.9256\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1750 - acc: 0.9259\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1737 - acc: 0.9264\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1724 - acc: 0.9271\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1727 - acc: 0.9266\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1705 - acc: 0.9279\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1698 - acc: 0.9282\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1691 - acc: 0.9284\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1681 - acc: 0.9289\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1671 - acc: 0.9292\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1671 - acc: 0.9293\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1664 - acc: 0.9297\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1654 - acc: 0.9300\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1633 - acc: 0.9310\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1628 - acc: 0.9311\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1633 - acc: 0.9311\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1631 - acc: 0.9311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71     42786\n",
      "           1       0.66      0.61      0.64     22686\n",
      "           2       0.76      0.75      0.76     38768\n",
      "\n",
      "    accuracy                           0.71    104240\n",
      "   macro avg       0.70      0.70      0.70    104240\n",
      "weighted avg       0.71      0.71      0.71    104240\n",
      "\n",
      "Acur√°cia\n",
      "0.6960893227802728\n",
      "Precisao\n",
      "0.7103221309034566\n",
      "Recall\n",
      "0.71039907904835\n",
      "F1\n",
      "0.7099105107940223\n",
      "[[30996  5025  6765]\n",
      " [ 6516 13848  2322]\n",
      " [ 7567  1993 29208]]\n",
      "TRAIN: [   0    1    2 ... 1995 1996 1997] TEST: [   7   12   17   26   30   45   55   57   58   63   71   73   75   77\n",
      "   80   84   91  103  106  109  110  111  118  126  129  137  138  141\n",
      "  146  153  154  172  175  181  184  187  199  214  215  216  221  226\n",
      "  228  243  244  247  253  254  255  261  265  274  277  280  282  284\n",
      "  288  290  295  296  301  305  306  312  313  318  321  333  341  348\n",
      "  356  364  365  368  373  382  385  388  391  398  405  410  442  443\n",
      "  444  455  461  465  467  473  480  485  489  502  505  508  509  523\n",
      "  524  525  531  532  533  535  542  549  552  554  560  564  571  580\n",
      "  583  592  596  600  605  612  621  625  628  632  642  646  647  649\n",
      "  655  662  663  665  667  670  676  695  702  705  706  711  718  728\n",
      "  730  731  732  733  734  743  756  757  768  770  776  777  781  787\n",
      "  788  794  802  807  811  816  823  827  832  834  840  845  854  860\n",
      "  861  863  868  877  880  882  898  899  906  907  908  925  929  936\n",
      "  939  942  953  960  962  963  964  965  974  978  979  982  989  996\n",
      " 1000 1006 1024 1035 1067 1068 1069 1075 1076 1079 1085 1097 1098 1102\n",
      " 1103 1107 1112 1116 1118 1119 1120 1126 1131 1132 1136 1140 1145 1151\n",
      " 1156 1163 1164 1176 1179 1203 1205 1217 1223 1225 1238 1239 1240 1243\n",
      " 1244 1246 1250 1257 1258 1259 1262 1267 1280 1282 1283 1287 1288 1290\n",
      " 1291 1292 1298 1300 1304 1308 1310 1313 1329 1331 1336 1338 1340 1343\n",
      " 1344 1345 1356 1360 1361 1367 1383 1385 1389 1395 1411 1419 1420 1424\n",
      " 1425 1433 1441 1447 1448 1460 1462 1468 1475 1477 1482 1486 1488 1489\n",
      " 1490 1491 1493 1499 1500 1505 1507 1509 1510 1511 1514 1522 1532 1536\n",
      " 1539 1542 1547 1556 1558 1559 1568 1569 1571 1581 1587 1591 1602 1609\n",
      " 1616 1620 1627 1628 1630 1632 1635 1644 1647 1649 1651 1654 1657 1659\n",
      " 1661 1670 1675 1681 1686 1690 1691 1696 1708 1713 1721 1723 1736 1738\n",
      " 1745 1747 1752 1760 1765 1771 1772 1790 1800 1803 1806 1808 1811 1812\n",
      " 1819 1827 1835 1837 1839 1841 1842 1844 1852 1863 1864 1865 1869 1877\n",
      " 1879 1883 1886 1887 1902 1903 1909 1918 1951 1954 1955 1956 1966 1969\n",
      " 1971 1974 1982 1986 1987 1991 1998 1999]\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 6s 4ms/sample - loss: 0.3417 - acc: 0.8235\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3155 - acc: 0.8560\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3090 - acc: 0.8609\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3043 - acc: 0.8633\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.3012 - acc: 0.8650\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2986 - acc: 0.8665\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2980 - acc: 0.8672\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2949 - acc: 0.8676\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2928 - acc: 0.8699\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2902 - acc: 0.8706\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2872 - acc: 0.8725\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2860 - acc: 0.8732\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2850 - acc: 0.8730\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2837 - acc: 0.8742\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2852 - acc: 0.8732\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2811 - acc: 0.8746\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2790 - acc: 0.8760\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2807 - acc: 0.8750\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2771 - acc: 0.8767\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2736 - acc: 0.8788\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2702 - acc: 0.8803\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2641 - acc: 0.8840\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2604 - acc: 0.8859\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2581 - acc: 0.8868\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2571 - acc: 0.8873\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2532 - acc: 0.8893\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2532 - acc: 0.8892\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2520 - acc: 0.8895\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2495 - acc: 0.8909\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2532 - acc: 0.8892\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2469 - acc: 0.8919\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2451 - acc: 0.8926\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2439 - acc: 0.8934\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2425 - acc: 0.8939\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2416 - acc: 0.8943\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2399 - acc: 0.8947\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2385 - acc: 0.8957\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2376 - acc: 0.8963\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2371 - acc: 0.8962\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2354 - acc: 0.8972\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2335 - acc: 0.8976\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2352 - acc: 0.8970\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2309 - acc: 0.8991\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2289 - acc: 0.9000\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2270 - acc: 0.9011\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2273 - acc: 0.9007\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2254 - acc: 0.9016\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2243 - acc: 0.9021\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2225 - acc: 0.9032\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2209 - acc: 0.9037\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2195 - acc: 0.9049\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2176 - acc: 0.9053\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2165 - acc: 0.9059\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2162 - acc: 0.9063\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2140 - acc: 0.9075\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2133 - acc: 0.9078\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2149 - acc: 0.9071\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2114 - acc: 0.9090\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2087 - acc: 0.9102\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2079 - acc: 0.9105\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2076 - acc: 0.9109\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2065 - acc: 0.9115\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2044 - acc: 0.9123\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2019 - acc: 0.9132\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2009 - acc: 0.9139\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.2009 - acc: 0.9141\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1993 - acc: 0.9148\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1982 - acc: 0.9153\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1968 - acc: 0.9158\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1968 - acc: 0.9159\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1944 - acc: 0.9168\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1941 - acc: 0.9166\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1923 - acc: 0.9176\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1909 - acc: 0.9185\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1908 - acc: 0.9183\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1899 - acc: 0.9185\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1876 - acc: 0.9200\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1863 - acc: 0.9202\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1853 - acc: 0.9205\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1848 - acc: 0.9206\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1834 - acc: 0.9215\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 6s 3ms/sample - loss: 0.1823 - acc: 0.9220\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1821 - acc: 0.9225\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1812 - acc: 0.9225\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1814 - acc: 0.9229\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1791 - acc: 0.9235\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1781 - acc: 0.9239\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1764 - acc: 0.9246\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1758 - acc: 0.9250\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1757 - acc: 0.9249\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1746 - acc: 0.9252\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1729 - acc: 0.9264\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1714 - acc: 0.9269\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1712 - acc: 0.9267\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1703 - acc: 0.9273\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1700 - acc: 0.9271\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1691 - acc: 0.9276\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1680 - acc: 0.9282\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1669 - acc: 0.9287\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 5s 3ms/sample - loss: 0.1660 - acc: 0.9291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71     42288\n",
      "           1       0.66      0.60      0.63     23754\n",
      "           2       0.76      0.73      0.75     35973\n",
      "\n",
      "    accuracy                           0.70    102015\n",
      "   macro avg       0.70      0.69      0.69    102015\n",
      "weighted avg       0.70      0.70      0.70    102015\n",
      "\n",
      "Acur√°cia\n",
      "0.6899601196902697\n",
      "Precisao\n",
      "0.7042514093711377\n",
      "Recall\n",
      "0.7034161642895652\n",
      "F1\n",
      "0.702866814490894\n",
      "[[31169  5068  6051]\n",
      " [ 7241 14299  2214]\n",
      " [ 7528  2154 26291]]\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_20 (Bidirectio (None, 700, 200)          73200     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_21 (Bidirectio (None, 700, 200)          181200    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 700, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 700, 3)            603       \n",
      "=================================================================\n",
      "Total params: 255,003\n",
      "Trainable params: 255,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Acur√°cias total\n",
      "[0.6979474552411494, 0.6942246371172912, 0.7028501980986426, 0.6960893227802728, 0.6899601196902697]\n",
      "0.6962143465855253\n",
      "Precision total\n",
      "[0.711873726087341, 0.7119109779225922, 0.7181858460851157, 0.7103221309034566, 0.7042514093711377]\n",
      "0.7113088180739287\n",
      "Recalls total\n",
      "[0.7123753973686925, 0.7111971957218826, 0.7180280206056822, 0.71039907904835, 0.7034161642895652]\n",
      "0.7110831714068344\n",
      "F1 total\n",
      "[0.7114571025535659, 0.7102563950640972, 0.7171998858841575, 0.7099105107940223, 0.702866814490894]\n",
      "0.7103381417573474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(8)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ8[train_index],\n",
    "                           previsores[test_index], classesQ8[test_index], 8)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())\n",
    "\n",
    "accu = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in kf.split(previsores):\n",
    "    model = None\n",
    "    model = criarRede(3)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train_and_evaluate_model(model, previsores[train_index], classesQ3[train_index],\n",
    "                           previsores[test_index], classesQ3[test_index], 3)\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "print('Acur√°cias total')\n",
    "print(accu)\n",
    "accu = np.array(accu)\n",
    "print(accu.mean())\n",
    "print('Precision total')\n",
    "print(precisions)\n",
    "precisions = np.array(precisions)\n",
    "print(precisions.mean())\n",
    "print('Recalls total')\n",
    "print(recalls)\n",
    "recalls = np.array(recalls)\n",
    "print(recalls.mean())\n",
    "print('F1 total')\n",
    "print(f1)\n",
    "f1 = np.array(f1)\n",
    "print(f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
